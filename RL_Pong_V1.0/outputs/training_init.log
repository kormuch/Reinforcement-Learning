
======================================================================
INITIALIZING TRAINING COMPONENTS
======================================================================

✓ Creating environment...
  Court: 160×192
  Paddle: 2×12
  CPU Difficulty: medium

✓ Creating agent (PolicyGradient)...
  Input Size: 16
  Hidden Size: 128
  Output Size: 3
  Learning Rate: 0.0015
  Discount Factor: 0.99

✓ Creating trainer (PolicyGradient)...
  Max Episodes: 20000
  Batch Size: 5
  Running Reward Decay: 0.99

✓ Creating heatmap recorder...
  Grid Resolution: 20×24
  Court Size: 160×192

✓ Creating training orchestrator...
  Experiment: exp_001
  Orchestrator will handle:
    - Training pipeline
    - Analytics logging
    - Heatmap recording
    - Model evaluation
    - Automatic saving
✓ Analytics initialized
  Timestamp: 20251117_041401
  Output dir: outputs\exp_001_20251117_041401\recorded_data
  All files saved as: 20251117_041401*

✓ Found existing training data: outputs\exp_001_20251117_041401\recorded_data\20251117_041401.csv
  Continuing from previous run...

======================================================================
STARTING TRAINING
======================================================================

======================================================================
TRAINING ORCHESTRATOR - UNIFIED PIPELINE
======================================================================
Experiment: exp_001
Timestamp: 20251117_041401
Output Root Directory: outputs\exp_001_20251117_041401/
Output Sub-Directories:
  - Models: outputs\exp_001_20251117_041401\saved_models/
  - Analytics: outputs\exp_001_20251117_041401\recorded_data/
  - Heatmaps: outputs\exp_001_20251117_041401\recorded_data\heatmaps/
Heatmap Recording: ✓ ENABLED

✓ Starting trainer...

============================================================
TRAINING PONG AGENT
============================================================
Agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
Learning Rate: 0.0015
Discount Factor: 0.99
Max Episodes: 20000
RMSprop Decay: 0.99
Running Reward Decay: 0.99
Reward Structure: Score=20.0, Hit=0.02, Loss=-1.0
Win Reward: 5000.0, Loss Penalty: -0.0
Heatmap Recording: ENABLED
Episodes per heatmap epoch: 200
============================================================

Episode  100 | Reward:  -20.46 | Running Avg:   -8.88 | Best:   39.68 | Length: 2832
  ✓ Heatmap epoch saved (episodes 1-200)
Episode  200 | Reward:   -0.22 | Running Avg:    0.46 | Best:   59.88 | Length: 3550
Episode  300 | Reward:   59.80 | Running Avg:    6.73 | Best:   79.94 | Length: 3780
  ✓ Heatmap epoch saved (episodes 201-400)
Episode  400 | Reward:  -20.20 | Running Avg:   10.13 | Best:   99.88 | Length: 3708
Episode  500 | Reward:   59.92 | Running Avg:   14.75 | Best:   99.88 | Length: 4176
  ✓ Heatmap epoch saved (episodes 401-600)
Episode  600 | Reward:  199.60 | Running Avg:   21.46 | Best:  199.60 | Length: 3689
Episode  700 | Reward:   20.14 | Running Avg:   36.47 | Best:  199.60 | Length: 4774
  ✓ Heatmap epoch saved (episodes 601-800)
Episode  800 | Reward:   79.86 | Running Avg:   53.86 | Best:  199.60 | Length: 3858
Episode  900 | Reward:   59.90 | Running Avg:   59.43 | Best:  199.60 | Length: 4149
  ✓ Heatmap epoch saved (episodes 801-1000)
Episode 1000 | Reward:  199.88 | Running Avg:   69.03 | Best:  199.88 | Length: 4018
Episode 1100 | Reward:   59.86 | Running Avg:   79.35 | Best:  199.88 | Length: 3840
  ✓ Heatmap epoch saved (episodes 1001-1200)
Episode 1200 | Reward:  119.82 | Running Avg:   96.44 | Best:  219.88 | Length: 3810
Episode 1300 | Reward:  139.92 | Running Avg:  105.31 | Best:  219.88 | Length: 4028
  ✓ Heatmap epoch saved (episodes 1201-1400)
Episode 1400 | Reward:  160.00 | Running Avg:  109.02 | Best:  239.84 | Length: 4408
Episode 1500 | Reward:   79.84 | Running Avg:  116.53 | Best:  259.94 | Length: 3946
  ✓ Heatmap epoch saved (episodes 1401-1600)
Episode 1600 | Reward:  139.92 | Running Avg:  128.79 | Best:  259.94 | Length: 4251
Episode 1700 | Reward:   80.06 | Running Avg:  133.02 | Best:  259.94 | Length: 4761
  ✓ Heatmap epoch saved (episodes 1601-1800)
Episode 1800 | Reward:   99.80 | Running Avg:  131.70 | Best:  259.94 | Length: 3710
Episode 1900 | Reward:   20.06 | Running Avg:  141.04 | Best:  259.94 | Length: 4567
  ✓ Heatmap epoch saved (episodes 1801-2000)
Episode 2000 | Reward:  139.96 | Running Avg:  142.11 | Best:  260.06 | Length: 4190
Episode 2100 | Reward:  139.92 | Running Avg:  146.02 | Best:  339.90 | Length: 4111
  ✓ Heatmap epoch saved (episodes 2001-2200)
Episode 2200 | Reward:  160.08 | Running Avg:  149.87 | Best:  339.90 | Length: 4534
Episode 2300 | Reward:  179.98 | Running Avg:  159.88 | Best:  339.90 | Length: 4164
  ✓ Heatmap epoch saved (episodes 2201-2400)
Episode 2400 | Reward:  179.84 | Running Avg:  175.53 | Best:  339.90 | Length: 3780
Episode 2500 | Reward:  259.98 | Running Avg:  187.74 | Best:  339.90 | Length: 4318
  ✓ Heatmap epoch saved (episodes 2401-2600)
Episode 2600 | Reward:  239.86 | Running Avg:  198.76 | Best:  339.90 | Length: 3963
Episode 2700 | Reward:  219.94 | Running Avg:  207.87 | Best:  360.02 | Length: 4115
  ✓ Heatmap epoch saved (episodes 2601-2800)
Episode 2800 | Reward:  219.94 | Running Avg:  208.06 | Best:  360.02 | Length: 4191
Episode 2900 | Reward:  299.84 | Running Avg:  217.81 | Best:  360.02 | Length: 4006
  ✓ Heatmap epoch saved (episodes 2801-3000)
Episode 3000 | Reward:  179.92 | Running Avg:  220.12 | Best:  360.02 | Length: 4103
Episode 3100 | Reward:  200.12 | Running Avg:  227.51 | Best:  360.02 | Length: 4743
  ✓ Heatmap epoch saved (episodes 3001-3200)
Episode 3200 | Reward:  279.96 | Running Avg:  231.65 | Best:  360.02 | Length: 4286
Episode 3300 | Reward:  139.66 | Running Avg:  232.14 | Best:  360.02 | Length: 3306
  ✓ Heatmap epoch saved (episodes 3201-3400)
Episode 3400 | Reward:  279.96 | Running Avg:  233.05 | Best:  360.02 | Length: 4296
Episode 3500 | Reward:  240.00 | Running Avg:  238.72 | Best:  360.02 | Length: 4298
  ✓ Heatmap epoch saved (episodes 3401-3600)
Episode 3600 | Reward:  260.00 | Running Avg:  245.81 | Best:  360.02 | Length: 4312
Episode 3700 | Reward:  260.00 | Running Avg:  250.99 | Best:  360.02 | Length: 4058
  ✓ Heatmap epoch saved (episodes 3601-3800)
Episode 3800 | Reward:  300.00 | Running Avg:  251.75 | Best:  360.02 | Length: 4471
Episode 3900 | Reward:  239.76 | Running Avg:  256.56 | Best:  380.10 | Length: 3692
  ✓ Heatmap epoch saved (episodes 3801-4000)
Episode 4000 | Reward:  259.88 | Running Avg:  264.29 | Best:  380.10 | Length: 3995
Episode 4100 | Reward:  340.00 | Running Avg:  272.97 | Best:  380.10 | Length: 4273
  ✓ Heatmap epoch saved (episodes 4001-4200)
Episode 4200 | Reward:  279.92 | Running Avg:  281.05 | Best:  380.10 | Length: 4305
Episode 4300 | Reward:  300.08 | Running Avg:  284.58 | Best:  380.10 | Length: 4467
  ✓ Heatmap epoch saved (episodes 4201-4400)
Episode 4400 | Reward:  359.88 | Running Avg:  291.05 | Best:  380.10 | Length: 4316
Episode 4500 | Reward:  240.04 | Running Avg:  295.88 | Best:  380.10 | Length: 4351
  ✓ Heatmap epoch saved (episodes 4401-4600)
Episode 4600 | Reward:  320.04 | Running Avg:  294.08 | Best:  380.10 | Length: 4372
Episode 4700 | Reward:  319.92 | Running Avg:  299.32 | Best:  380.10 | Length: 4445
  ✓ Heatmap epoch saved (episodes 4601-4800)
Episode 4800 | Reward:  299.98 | Running Avg:  296.84 | Best:  380.10 | Length: 4127
Episode 4900 | Reward:  279.96 | Running Avg:  301.37 | Best:  380.10 | Length: 4096
  ✓ Heatmap epoch saved (episodes 4801-5000)
Episode 5000 | Reward:  260.04 | Running Avg:  308.28 | Best:  380.16 | Length: 4396
Episode 5100 | Reward:  320.06 | Running Avg:  336.77 | Best: 5401.02 | Length: 4707
  ✓ Heatmap epoch saved (episodes 5001-5200)
Episode 5200 | Reward:  279.92 | Running Avg:  346.72 | Best: 5401.10 | Length: 3971
Episode 5300 | Reward:  340.00 | Running Avg:  329.83 | Best: 5401.10 | Length: 4478
  ✓ Heatmap epoch saved (episodes 5201-5400)
Episode 5400 | Reward:  299.92 | Running Avg:  348.87 | Best: 5401.10 | Length: 4345
Episode 5500 | Reward:  300.02 | Running Avg:  373.66 | Best: 5401.10 | Length: 4600
  ✓ Heatmap epoch saved (episodes 5401-5600)
Episode 5600 | Reward:  360.02 | Running Avg:  363.02 | Best: 5401.10 | Length: 4652
Episode 5700 | Reward:  300.04 | Running Avg:  334.35 | Best: 5401.10 | Length: 4334
  ✓ Heatmap epoch saved (episodes 5601-5800)
Episode 5800 | Reward:  319.94 | Running Avg:  350.88 | Best: 5401.10 | Length: 4176
Episode 5900 | Reward:  319.94 | Running Avg:  329.95 | Best: 5401.10 | Length: 4242
  ✓ Heatmap epoch saved (episodes 5801-6000)
Episode 6000 | Reward:  300.04 | Running Avg:  324.03 | Best: 5401.10 | Length: 4330
Episode 6100 | Reward:  319.96 | Running Avg:  408.56 | Best: 5401.12 | Length: 4102
  ✓ Heatmap epoch saved (episodes 6001-6200)
Episode 6200 | Reward:  320.00 | Running Avg:  451.30 | Best: 5401.12 | Length: 4445
Episode 6300 | Reward:  259.80 | Running Avg:  405.27 | Best: 5401.12 | Length: 4006
  ✓ Heatmap epoch saved (episodes 6201-6400)
Episode 6400 | Reward:  360.16 | Running Avg:  419.31 | Best: 5401.12 | Length: 4635
Episode 6500 | Reward:  359.92 | Running Avg:  418.26 | Best: 5401.12 | Length: 4316
  ✓ Heatmap epoch saved (episodes 6401-6600)
Episode 6600 | Reward:  320.00 | Running Avg:  404.86 | Best: 5401.12 | Length: 4234
Episode 6700 | Reward:  319.94 | Running Avg:  358.60 | Best: 5401.12 | Length: 4309
  ✓ Heatmap epoch saved (episodes 6601-6800)
Episode 6800 | Reward:  360.00 | Running Avg:  341.00 | Best: 5401.12 | Length: 4312
Episode 6900 | Reward:  320.02 | Running Avg:  334.16 | Best: 5401.12 | Length: 4572
  ✓ Heatmap epoch saved (episodes 6801-7000)
Episode 7000 | Reward:  279.98 | Running Avg:  368.96 | Best: 5401.12 | Length: 4283
Episode 7100 | Reward:  380.02 | Running Avg:  386.34 | Best: 5401.12 | Length: 4616
  ✓ Heatmap epoch saved (episodes 7001-7200)
Episode 7200 | Reward:  319.88 | Running Avg:  392.26 | Best: 5401.12 | Length: 4238
Episode 7300 | Reward:  260.04 | Running Avg:  420.65 | Best: 5401.12 | Length: 4536
  ✓ Heatmap epoch saved (episodes 7201-7400)
Episode 7400 | Reward:  319.92 | Running Avg:  424.85 | Best: 5401.12 | Length: 4241
Episode 7500 | Reward:  319.98 | Running Avg:  416.02 | Best: 5401.12 | Length: 4581
  ✓ Heatmap epoch saved (episodes 7401-7600)
Episode 7600 | Reward:  340.02 | Running Avg:  410.45 | Best: 5401.12 | Length: 4342
Episode 7700 | Reward:  339.94 | Running Avg:  394.19 | Best: 5401.12 | Length: 4280
  ✓ Heatmap epoch saved (episodes 7601-7800)
Episode 7800 | Reward:  279.98 | Running Avg:  389.54 | Best: 5401.12 | Length: 4302
Episode 7900 | Reward:  280.08 | Running Avg:  392.61 | Best: 5401.12 | Length: 4410
  ✓ Heatmap epoch saved (episodes 7801-8000)
Episode 8000 | Reward:  359.92 | Running Avg:  400.03 | Best: 5401.12 | Length: 4316
Episode 8100 | Reward:  320.04 | Running Avg:  557.56 | Best: 5401.12 | Length: 4502
  ✓ Heatmap epoch saved (episodes 8001-8200)
Episode 8200 | Reward:  339.98 | Running Avg:  538.15 | Best: 5401.12 | Length: 4548
Episode 8300 | Reward:  359.92 | Running Avg:  464.49 | Best: 5401.12 | Length: 4387
  ✓ Heatmap epoch saved (episodes 8201-8400)
Episode 8400 | Reward: 5401.02 | Running Avg:  431.43 | Best: 5401.12 | Length: 4544
Episode 8500 | Reward:  360.06 | Running Avg:  464.99 | Best: 5401.12 | Length: 4444
  ✓ Heatmap epoch saved (episodes 8401-8600)
Episode 8600 | Reward:  380.00 | Running Avg:  551.19 | Best: 5401.12 | Length: 4487
Episode 8700 | Reward:  319.94 | Running Avg:  437.31 | Best: 5401.12 | Length: 4242
  ✓ Heatmap epoch saved (episodes 8601-8800)
Episode 8800 | Reward:  300.18 | Running Avg:  550.47 | Best: 5401.12 | Length: 4727
Episode 8900 | Reward:  360.04 | Running Avg:  549.84 | Best: 5401.12 | Length: 4651
  ✓ Heatmap epoch saved (episodes 8801-9000)
Episode 9000 | Reward:  299.92 | Running Avg:  527.94 | Best: 5401.12 | Length: 4135
Episode 9100 | Reward:  340.02 | Running Avg:  543.42 | Best: 5401.12 | Length: 4411
  ✓ Heatmap epoch saved (episodes 9001-9200)
Episode 9200 | Reward:  280.10 | Running Avg:  684.06 | Best: 5401.12 | Length: 4747
Episode 9300 | Reward:  319.96 | Running Avg:  504.07 | Best: 5401.12 | Length: 4306
  ✓ Heatmap epoch saved (episodes 9201-9400)
Episode 9400 | Reward:  320.02 | Running Avg:  420.87 | Best: 5401.12 | Length: 4166
Episode 9500 | Reward:  360.08 | Running Avg:  534.16 | Best: 5401.12 | Length: 4512
  ✓ Heatmap epoch saved (episodes 9401-9600)
Episode 9600 | Reward:  299.96 | Running Avg:  640.49 | Best: 5401.14 | Length: 4407
Episode 9700 | Reward:  359.98 | Running Avg:  750.92 | Best: 5401.14 | Length: 4313
  ✓ Heatmap epoch saved (episodes 9601-9800)
Episode 9800 | Reward:  360.06 | Running Avg:  741.24 | Best: 5401.14 | Length: 4309
Episode 9900 | Reward:  320.08 | Running Avg:  663.82 | Best: 5401.14 | Length: 4505
  ✓ Heatmap epoch saved (episodes 9801-10000)
Episode 10000 | Reward:  319.98 | Running Avg:  570.33 | Best: 5401.16 | Length: 4446
Episode 10100 | Reward:  319.94 | Running Avg:  597.18 | Best: 5401.16 | Length: 4233
  ✓ Heatmap epoch saved (episodes 10001-10200)
Episode 10200 | Reward:  240.08 | Running Avg:  605.74 | Best: 5401.16 | Length: 4565
Episode 10300 | Reward:  280.00 | Running Avg:  462.78 | Best: 5401.16 | Length: 4161
  ✓ Heatmap epoch saved (episodes 10201-10400)
Episode 10400 | Reward:  360.04 | Running Avg:  579.39 | Best: 5401.16 | Length: 4381
Episode 10500 | Reward:  359.94 | Running Avg:  667.91 | Best: 5401.16 | Length: 4386
  ✓ Heatmap epoch saved (episodes 10401-10600)
Episode 10600 | Reward:  340.04 | Running Avg:  755.03 | Best: 5401.16 | Length: 4677
Episode 10700 | Reward:  360.04 | Running Avg:  785.85 | Best: 5401.16 | Length: 4445
  ✓ Heatmap epoch saved (episodes 10601-10800)
Episode 10800 | Reward:  340.00 | Running Avg:  773.20 | Best: 5401.16 | Length: 4407
Episode 10900 | Reward:  359.90 | Running Avg:  806.03 | Best: 5401.16 | Length: 4384
  ✓ Heatmap epoch saved (episodes 10801-11000)
Episode 11000 | Reward:  360.04 | Running Avg:  898.71 | Best: 5401.16 | Length: 4445
Episode 11100 | Reward:  340.00 | Running Avg:  719.31 | Best: 5401.16 | Length: 4343
  ✓ Heatmap epoch saved (episodes 11001-11200)
Episode 11200 | Reward:  299.96 | Running Avg:  865.84 | Best: 5401.16 | Length: 3996
Episode 11300 | Reward:  360.06 | Running Avg:  563.81 | Best: 5401.16 | Length: 4508
  ✓ Heatmap epoch saved (episodes 11201-11400)
Episode 11400 | Reward:  260.02 | Running Avg:  377.89 | Best: 5401.16 | Length: 4259
Episode 11500 | Reward:  380.02 | Running Avg:  346.25 | Best: 5401.16 | Length: 4415
  ✓ Heatmap epoch saved (episodes 11401-11600)
Episode 11600 | Reward:  159.76 | Running Avg:  341.55 | Best: 5401.16 | Length: 3262
Episode 11700 | Reward:  259.86 | Running Avg:  267.02 | Best: 5401.16 | Length: 4056
  ✓ Heatmap epoch saved (episodes 11601-11800)
Episode 11800 | Reward:  339.92 | Running Avg:  410.15 | Best: 5401.16 | Length: 4414
Episode 11900 | Reward:  340.02 | Running Avg:  796.04 | Best: 5401.16 | Length: 4342
  ✓ Heatmap epoch saved (episodes 11801-12000)
Episode 12000 | Reward:  360.06 | Running Avg:  817.76 | Best: 5401.16 | Length: 4380
Episode 12100 | Reward:  340.00 | Running Avg:  832.98 | Best: 5401.16 | Length: 4343
  ✓ Heatmap epoch saved (episodes 12001-12200)
Episode 12200 | Reward:  359.92 | Running Avg:  813.31 | Best: 5401.16 | Length: 4314
Episode 12300 | Reward:  360.08 | Running Avg: 1020.78 | Best: 5401.16 | Length: 4649
  ✓ Heatmap epoch saved (episodes 12201-12400)
Episode 12400 | Reward:  380.02 | Running Avg:  894.55 | Best: 5401.16 | Length: 4621
Episode 12500 | Reward: 5400.98 | Running Avg:  952.45 | Best: 5401.16 | Length: 4546
  ✓ Heatmap epoch saved (episodes 12401-12600)
Episode 12600 | Reward:  359.90 | Running Avg:  985.33 | Best: 5401.18 | Length: 4452
Episode 12700 | Reward:  319.92 | Running Avg:  972.02 | Best: 5401.18 | Length: 4102
  ✓ Heatmap epoch saved (episodes 12601-12800)
Episode 12800 | Reward:  340.00 | Running Avg:  896.12 | Best: 5401.18 | Length: 4204
Episode 12900 | Reward:  359.96 | Running Avg: 1014.02 | Best: 5401.18 | Length: 4449
  ✓ Heatmap epoch saved (episodes 12801-13000)
Episode 13000 | Reward: 5401.02 | Running Avg: 1175.01 | Best: 5401.18 | Length: 4544
Episode 13100 | Reward:  380.02 | Running Avg:  898.75 | Best: 5401.18 | Length: 4415
  ✓ Heatmap epoch saved (episodes 13001-13200)
Episode 13200 | Reward:  360.06 | Running Avg: 1136.18 | Best: 5401.18 | Length: 4515
Episode 13300 | Reward:  319.96 | Running Avg:  873.08 | Best: 5401.20 | Length: 4312
  ✓ Heatmap epoch saved (episodes 13201-13400)
Episode 13400 | Reward:  360.06 | Running Avg: 1021.90 | Best: 5401.20 | Length: 4515
Episode 13500 | Reward:  359.96 | Running Avg:  918.76 | Best: 5401.20 | Length: 4449
  ✓ Heatmap epoch saved (episodes 13401-13600)
Episode 13600 | Reward:  319.94 | Running Avg: 1059.76 | Best: 5401.20 | Length: 4372
Episode 13700 | Reward:  380.02 | Running Avg:  897.21 | Best: 5401.20 | Length: 4415
  ✓ Heatmap epoch saved (episodes 13601-13800)
Episode 13800 | Reward: 5401.10 | Running Avg: 1032.11 | Best: 5401.20 | Length: 4540
Episode 13900 | Reward:  379.98 | Running Avg: 1004.66 | Best: 5401.20 | Length: 4417
  ✓ Heatmap epoch saved (episodes 13801-14000)
Episode 14000 | Reward:  380.04 | Running Avg: 1298.73 | Best: 5401.20 | Length: 4620
Episode 14100 | Reward:  320.06 | Running Avg: 1548.32 | Best: 5401.20 | Length: 4577
  ✓ Heatmap epoch saved (episodes 14001-14200)
Episode 14200 | Reward:  360.12 | Running Avg: 1271.94 | Best: 5401.20 | Length: 4647
Episode 14300 | Reward: 5401.00 | Running Avg: 1225.97 | Best: 5401.20 | Length: 4545
  ✓ Heatmap epoch saved (episodes 14201-14400)
Episode 14400 | Reward:  359.94 | Running Avg: 1326.88 | Best: 5401.20 | Length: 4315
Episode 14500 | Reward: 5401.06 | Running Avg: 1355.04 | Best: 5401.22 | Length: 4542
  ✓ Heatmap epoch saved (episodes 14401-14600)
Episode 14600 | Reward:  380.08 | Running Avg: 1342.60 | Best: 5401.22 | Length: 4483
Episode 14700 | Reward:  359.96 | Running Avg: 1615.65 | Best: 5401.22 | Length: 4449
  ✓ Heatmap epoch saved (episodes 14601-14800)
Episode 14800 | Reward: 5401.02 | Running Avg: 1790.88 | Best: 5401.22 | Length: 4544
Episode 14900 | Reward:  340.00 | Running Avg: 1477.02 | Best: 5401.22 | Length: 4204
  ✓ Heatmap epoch saved (episodes 14801-15000)
Episode 15000 | Reward:  380.02 | Running Avg: 1218.77 | Best: 5401.22 | Length: 4415
Episode 15100 | Reward:  360.00 | Running Avg:  949.66 | Best: 5401.22 | Length: 4442
  ✓ Heatmap epoch saved (episodes 15001-15200)
Episode 15200 | Reward:  360.04 | Running Avg: 1208.76 | Best: 5401.22 | Length: 4646
Episode 15300 | Reward: 5401.08 | Running Avg: 1132.09 | Best: 5401.22 | Length: 4541
  ✓ Heatmap epoch saved (episodes 15201-15400)
Episode 15400 | Reward:  359.98 | Running Avg: 1089.69 | Best: 5401.22 | Length: 4443
Episode 15500 | Reward: 5401.04 | Running Avg: 1163.18 | Best: 5401.22 | Length: 4543
  ✓ Heatmap epoch saved (episodes 15401-15600)
Episode 15600 | Reward: 5401.10 | Running Avg: 1261.84 | Best: 5401.22 | Length: 4540
Episode 15700 | Reward:  340.06 | Running Avg: 1234.55 | Best: 5401.22 | Length: 4340
  ✓ Heatmap epoch saved (episodes 15601-15800)
Episode 15800 | Reward:  340.14 | Running Avg: 1531.26 | Best: 5401.22 | Length: 4672
Episode 15900 | Reward:  379.98 | Running Avg: 1622.86 | Best: 5401.22 | Length: 4486
  ✓ Heatmap epoch saved (episodes 15801-16000)
Episode 16000 | Reward:  319.86 | Running Avg: 1390.40 | Best: 5401.22 | Length: 4107
Episode 16100 | Reward:  360.02 | Running Avg: 1375.97 | Best: 5401.22 | Length: 4311
  ✓ Heatmap epoch saved (episodes 16001-16200)
Episode 16200 | Reward:  360.00 | Running Avg: 1312.00 | Best: 5401.22 | Length: 4312
Episode 16300 | Reward:  380.04 | Running Avg: 1305.83 | Best: 5401.22 | Length: 4615
  ✓ Heatmap epoch saved (episodes 16201-16400)
Episode 16400 | Reward:  380.04 | Running Avg: 1520.34 | Best: 5401.22 | Length: 4414
Episode 16500 | Reward:  339.88 | Running Avg: 1576.46 | Best: 5401.22 | Length: 4210
  ✓ Heatmap epoch saved (episodes 16401-16600)
Episode 16600 | Reward:  380.06 | Running Avg: 1244.38 | Best: 5401.22 | Length: 4413
Episode 16700 | Reward: 5401.10 | Running Avg: 1075.28 | Best: 5401.22 | Length: 4540
  ✓ Heatmap epoch saved (episodes 16601-16800)
Episode 16800 | Reward:  380.04 | Running Avg: 1340.22 | Best: 5401.22 | Length: 4485
Episode 16900 | Reward:  360.04 | Running Avg: 1486.45 | Best: 5401.22 | Length: 4514
  ✓ Heatmap epoch saved (episodes 16801-17000)
Episode 17000 | Reward:  379.98 | Running Avg: 1491.84 | Best: 5401.22 | Length: 4417
Episode 17100 | Reward:  300.04 | Running Avg: 1381.17 | Best: 5401.22 | Length: 4533
  ✓ Heatmap epoch saved (episodes 17001-17200)
Episode 17200 | Reward:  379.98 | Running Avg: 1419.91 | Best: 5401.22 | Length: 4417
Episode 17300 | Reward:  339.92 | Running Avg: 1113.84 | Best: 5401.22 | Length: 4212
  ✓ Heatmap epoch saved (episodes 17201-17400)
Episode 17400 | Reward:  359.96 | Running Avg: 1170.35 | Best: 5401.22 | Length: 4449
Episode 17500 | Reward:  380.10 | Running Avg: 1128.26 | Best: 5401.22 | Length: 4480
  ✓ Heatmap epoch saved (episodes 17401-17600)
Episode 17600 | Reward:  299.84 | Running Avg: 1105.79 | Best: 5401.22 | Length: 4069
Episode 17700 | Reward: 5401.10 | Running Avg: 1234.91 | Best: 5401.22 | Length: 4540
  ✓ Heatmap epoch saved (episodes 17601-17800)
Episode 17800 | Reward:  360.04 | Running Avg:  791.03 | Best: 5401.22 | Length: 4516
Episode 17900 | Reward:  359.92 | Running Avg:  993.02 | Best: 5401.22 | Length: 4316
  ✓ Heatmap epoch saved (episodes 17801-18000)
Episode 18000 | Reward:  299.94 | Running Avg: 1175.92 | Best: 5401.22 | Length: 4342
Episode 18100 | Reward:  380.08 | Running Avg: 1123.10 | Best: 5401.22 | Length: 4483
  ✓ Heatmap epoch saved (episodes 18001-18200)
Episode 18200 | Reward:  379.96 | Running Avg: 1089.63 | Best: 5401.22 | Length: 4418
Episode 18300 | Reward:  360.02 | Running Avg:  926.92 | Best: 5401.22 | Length: 4517
  ✓ Heatmap epoch saved (episodes 18201-18400)
Episode 18400 | Reward: 5400.98 | Running Avg: 1055.94 | Best: 5401.22 | Length: 4546
Episode 18500 | Reward: 5401.08 | Running Avg:  887.57 | Best: 5401.22 | Length: 4541
  ✓ Heatmap epoch saved (episodes 18401-18600)
Episode 18600 | Reward:  339.98 | Running Avg: 1028.30 | Best: 5401.22 | Length: 4205
Episode 18700 | Reward:  380.12 | Running Avg: 1582.36 | Best: 5401.22 | Length: 4611
  ✓ Heatmap epoch saved (episodes 18601-18800)
Episode 18800 | Reward:  360.06 | Running Avg: 1171.72 | Best: 5401.22 | Length: 4309
Episode 18900 | Reward: 5401.14 | Running Avg: 1237.75 | Best: 5401.22 | Length: 4538
  ✓ Heatmap epoch saved (episodes 18801-19000)
Episode 19000 | Reward:  380.10 | Running Avg: 1345.72 | Best: 5401.22 | Length: 4411
Episode 19100 | Reward: 5401.04 | Running Avg: 1641.57 | Best: 5401.22 | Length: 4543
  ✓ Heatmap epoch saved (episodes 19001-19200)
Episode 19200 | Reward:  379.98 | Running Avg: 1533.06 | Best: 5401.22 | Length: 4417
Episode 19300 | Reward:  380.00 | Running Avg: 1570.14 | Best: 5401.22 | Length: 4416
  ✓ Heatmap epoch saved (episodes 19201-19400)
Episode 19400 | Reward:  359.98 | Running Avg: 1458.83 | Best: 5401.22 | Length: 4384
Episode 19500 | Reward:  359.96 | Running Avg: 1590.04 | Best: 5401.22 | Length: 4444
  ✓ Heatmap epoch saved (episodes 19401-19600)
Episode 19600 | Reward:  340.02 | Running Avg: 1809.07 | Best: 5401.22 | Length: 4272
Episode 19700 | Reward:  360.04 | Running Avg: 1918.63 | Best: 5401.22 | Length: 4509
  ✓ Heatmap epoch saved (episodes 19601-19800)
Episode 19800 | Reward:  379.98 | Running Avg: 1695.66 | Best: 5401.22 | Length: 4486
Episode 19900 | Reward:  360.04 | Running Avg: 1538.80 | Best: 5401.22 | Length: 4514
  ✓ Heatmap epoch saved (episodes 19801-20000)
Episode 20000 | Reward:  340.04 | Running Avg: 1211.01 | Best: 5401.22 | Length: 4408

============================================================
TRAINING COMPLETE
Final Running Average: 1211.01
Best Episode Reward: 5401.22
Total heatmap epochs: 100
============================================================


✓ Logging training data to analytics...

✓ Evaluating...

============================================================
EVALUATING TRAINED AGENT (10 episodes)
============================================================

Eval Episode  1: Reward= 339.92, Player=18, CPU=21, Length=4208
Eval Episode  2: Reward= 359.92, Player=19, CPU=21, Length=4314
Eval Episode  3: Reward= 380.04, Player=20, CPU=21, Length=4414
Eval Episode  4: Reward=5401.10, Player=21, CPU=20, Length=4540
Eval Episode  5: Reward= 360.02, Player=19, CPU=21, Length=4378
Eval Episode  6: Reward= 380.08, Player=20, CPU=21, Length=4412
Eval Episode  7: Reward= 380.08, Player=20, CPU=21, Length=4481
Eval Episode  8: Reward= 360.04, Player=19, CPU=21, Length=4377
Eval Episode  9: Reward=5401.00, Player=21, CPU=20, Length=4545
Eval Episode 10: Reward= 379.94, Player=20, CPU=21, Length=4488

============================================================
Mean Reward: 1374.21 ± 2013.46
Reward Range: [339.92, 5401.10]
Win Rate: 20.0%
Mean Episode Length: 4416 steps
============================================================


✓ Logging evaluation data to analytics...

✓ Saving current model to models\exp_001.npz...
✓ Agent parameters saved to 'models\exp_001.npz'
✓ Saving timestamped backup to outputs\exp_001_20251117_041401\saved_models\exp_001_20251117_041401.npz...
✓ Agent parameters saved to 'outputs\exp_001_20251117_041401\saved_models\exp_001_20251117_041401.npz'

✓ Saving configuration to outputs\exp_001_20251117_041401\saved_models\exp_001_20251117_041401_config.json...

✓ Saving analytics summary...

✓ Summary saved to outputs\exp_001_20251117_041401\recorded_data\20251117_041401_summary.txt
============================================================
TRAINING SUMMARY
============================================================
Timestamp: 20251117_041401

TRAINING RESULTS
------------------------------------------------------------
Total episodes trained: 20000
Final running average reward: 644.52
Best episode reward: 5401.22
Worst episode reward: -20.60
Mean episode reward: 713.56
Std episode reward: 1397.11

EVALUATION METRICS
------------------------------------------------------------
Win rate: 8.1%
Total wins: 1625 / 20000
Mean episode length: 4341 steps
Mean player score: 16.4
Mean CPU score: 20.9

REWARD COMPONENTS (Average)
------------------------------------------------------------
Score reward: +330.18
Hit reward: +0.9850
Loss penalty: -20.92

ACTION DISTRIBUTION
------------------------------------------------------------
N/A

HYPERPARAMETERS
------------------------------------------------------------
timestamp: 20251117_041401
experiment_name: exp_001
continued_from_episode: 0
environment: {'width': 160, 'height': 192, 'max_score': 21, 'cpu_difficulty': 'medium'}
agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
training: {'max_episodes': 20000, 'batch_size': 5, 'running_reward_decay': 0.99, 'print_frequency': 100}
rewards: {'ball_hit': 0.02, 'score': 20.0, 'opponent_score': -1.0, 'win': 5000.0, 'loss': -0.0}
training_results: {'final_running_average': 1211.0132608235676, 'best_episode_reward': 5401.219999999999, 'total_episodes_trained': 20000, 'total_episodes_cumulative': 20000}
evaluation_results: {'mean_reward': 1374.214, 'std_reward': 2013.4566959544968, 'win_rate': 0.2, 'eval_episodes': 10}
heatmap_data: {'recording_enabled': True, 'heatmap_file': 'exp_001_20251117_041401_heatmap.json', 'epochs_collected': 100}

============================================================

✓ Generating analytics visualizations...

✓ Generating plots...
Warning: Skipping action distribution plot. No action data was logged during training/evaluation.
✓ All plots saved to outputs\exp_001_20251117_041401\recorded_data/ with prefix 20251117_041401

✓ Saving heatmap data to outputs\exp_001_20251117_041401\recorded_data\heatmaps\exp_001_20251117_041401_heatmap.json...
✓ Exported heatmap data to outputs\exp_001_20251117_041401\recorded_data\heatmaps\exp_001_20251117_041401_heatmap.json

✓ Exporting heatmaps as PNG images to outputs\exp_001_20251117_041401\recorded_data\heatmaps\heatmap_images/
  ✓ Saved: epoch_0_ball_position.png
  ✓ Saved: epoch_0_player_scores.png
  ✓ Saved: epoch_0_cpu_scores.png
  ✓ Saved: epoch_0_player_paddle.png
  ✓ Saved: epoch_0_cpu_paddle.png
  ✓ Saved: epoch_0_action_stay.png
  ✓ Saved: epoch_0_action_up.png
  ✓ Saved: epoch_0_action_down.png
  ✓ Saved: epoch_1_ball_position.png
  ✓ Saved: epoch_1_player_scores.png
  ✓ Saved: epoch_1_cpu_scores.png
  ✓ Saved: epoch_1_player_paddle.png
  ✓ Saved: epoch_1_cpu_paddle.png
  ✓ Saved: epoch_1_action_stay.png
  ✓ Saved: epoch_1_action_up.png
  ✓ Saved: epoch_1_action_down.png
  ✓ Saved: epoch_2_ball_position.png
  ✓ Saved: epoch_2_player_scores.png
  ✓ Saved: epoch_2_cpu_scores.png
  ✓ Saved: epoch_2_player_paddle.png
  ✓ Saved: epoch_2_cpu_paddle.png
  ✓ Saved: epoch_2_action_stay.png
  ✓ Saved: epoch_2_action_up.png
  ✓ Saved: epoch_2_action_down.png
  ✓ Saved: epoch_3_ball_position.png
  ✓ Saved: epoch_3_player_scores.png
  ✓ Saved: epoch_3_cpu_scores.png
  ✓ Saved: epoch_3_player_paddle.png
  ✓ Saved: epoch_3_cpu_paddle.png
  ✓ Saved: epoch_3_action_stay.png
  ✓ Saved: epoch_3_action_up.png
  ✓ Saved: epoch_3_action_down.png
  ✓ Saved: epoch_4_ball_position.png
  ✓ Saved: epoch_4_player_scores.png
  ✓ Saved: epoch_4_cpu_scores.png
  ✓ Saved: epoch_4_player_paddle.png
  ✓ Saved: epoch_4_cpu_paddle.png
  ✓ Saved: epoch_4_action_stay.png
  ✓ Saved: epoch_4_action_up.png
  ✓ Saved: epoch_4_action_down.png
  ✓ Saved: epoch_5_ball_position.png
  ✓ Saved: epoch_5_player_scores.png
  ✓ Saved: epoch_5_cpu_scores.png
  ✓ Saved: epoch_5_player_paddle.png
  ✓ Saved: epoch_5_cpu_paddle.png
  ✓ Saved: epoch_5_action_stay.png
  ✓ Saved: epoch_5_action_up.png
  ✓ Saved: epoch_5_action_down.png
  ✓ Saved: epoch_6_ball_position.png
  ✓ Saved: epoch_6_player_scores.png
  ✓ Saved: epoch_6_cpu_scores.png
  ✓ Saved: epoch_6_player_paddle.png
  ✓ Saved: epoch_6_cpu_paddle.png
  ✓ Saved: epoch_6_action_stay.png
  ✓ Saved: epoch_6_action_up.png
  ✓ Saved: epoch_6_action_down.png
  ✓ Saved: epoch_7_ball_position.png
  ✓ Saved: epoch_7_player_scores.png
  ✓ Saved: epoch_7_cpu_scores.png
  ✓ Saved: epoch_7_player_paddle.png
  ✓ Saved: epoch_7_cpu_paddle.png
  ✓ Saved: epoch_7_action_stay.png
  ✓ Saved: epoch_7_action_up.png
  ✓ Saved: epoch_7_action_down.png
  ✓ Saved: epoch_8_ball_position.png
  ✓ Saved: epoch_8_player_scores.png
  ✓ Saved: epoch_8_cpu_scores.png
  ✓ Saved: epoch_8_player_paddle.png
  ✓ Saved: epoch_8_cpu_paddle.png
  ✓ Saved: epoch_8_action_stay.png
  ✓ Saved: epoch_8_action_up.png
  ✓ Saved: epoch_8_action_down.png
  ✓ Saved: epoch_9_ball_position.png
  ✓ Saved: epoch_9_player_scores.png
  ✓ Saved: epoch_9_cpu_scores.png
  ✓ Saved: epoch_9_player_paddle.png
  ✓ Saved: epoch_9_cpu_paddle.png
  ✓ Saved: epoch_9_action_stay.png
  ✓ Saved: epoch_9_action_up.png
  ✓ Saved: epoch_9_action_down.png
  ✓ Saved: epoch_10_ball_position.png
  ✓ Saved: epoch_10_player_scores.png
  ✓ Saved: epoch_10_cpu_scores.png
  ✓ Saved: epoch_10_player_paddle.png
  ✓ Saved: epoch_10_cpu_paddle.png
  ✓ Saved: epoch_10_action_stay.png
  ✓ Saved: epoch_10_action_up.png
  ✓ Saved: epoch_10_action_down.png
  ✓ Saved: epoch_11_ball_position.png
  ✓ Saved: epoch_11_player_scores.png
  ✓ Saved: epoch_11_cpu_scores.png
  ✓ Saved: epoch_11_player_paddle.png
  ✓ Saved: epoch_11_cpu_paddle.png
  ✓ Saved: epoch_11_action_stay.png
  ✓ Saved: epoch_11_action_up.png
  ✓ Saved: epoch_11_action_down.png
  ✓ Saved: epoch_12_ball_position.png
  ✓ Saved: epoch_12_player_scores.png
  ✓ Saved: epoch_12_cpu_scores.png
  ✓ Saved: epoch_12_player_paddle.png
  ✓ Saved: epoch_12_cpu_paddle.png
  ✓ Saved: epoch_12_action_stay.png
  ✓ Saved: epoch_12_action_up.png
  ✓ Saved: epoch_12_action_down.png
  ✓ Saved: epoch_13_ball_position.png
  ✓ Saved: epoch_13_player_scores.png
  ✓ Saved: epoch_13_cpu_scores.png
  ✓ Saved: epoch_13_player_paddle.png
  ✓ Saved: epoch_13_cpu_paddle.png
  ✓ Saved: epoch_13_action_stay.png
  ✓ Saved: epoch_13_action_up.png
  ✓ Saved: epoch_13_action_down.png
  ✓ Saved: epoch_14_ball_position.png
  ✓ Saved: epoch_14_player_scores.png
  ✓ Saved: epoch_14_cpu_scores.png
  ✓ Saved: epoch_14_player_paddle.png
  ✓ Saved: epoch_14_cpu_paddle.png
  ✓ Saved: epoch_14_action_stay.png
  ✓ Saved: epoch_14_action_up.png
  ✓ Saved: epoch_14_action_down.png
  ✓ Saved: epoch_15_ball_position.png
  ✓ Saved: epoch_15_player_scores.png
  ✓ Saved: epoch_15_cpu_scores.png
  ✓ Saved: epoch_15_player_paddle.png
  ✓ Saved: epoch_15_cpu_paddle.png
  ✓ Saved: epoch_15_action_stay.png
  ✓ Saved: epoch_15_action_up.png
  ✓ Saved: epoch_15_action_down.png
  ✓ Saved: epoch_16_ball_position.png
  ✓ Saved: epoch_16_player_scores.png
  ✓ Saved: epoch_16_cpu_scores.png
  ✓ Saved: epoch_16_player_paddle.png
  ✓ Saved: epoch_16_cpu_paddle.png
  ✓ Saved: epoch_16_action_stay.png
  ✓ Saved: epoch_16_action_up.png
  ✓ Saved: epoch_16_action_down.png
  ✓ Saved: epoch_17_ball_position.png
  ✓ Saved: epoch_17_player_scores.png
  ✓ Saved: epoch_17_cpu_scores.png
  ✓ Saved: epoch_17_player_paddle.png
  ✓ Saved: epoch_17_cpu_paddle.png
  ✓ Saved: epoch_17_action_stay.png
  ✓ Saved: epoch_17_action_up.png
  ✓ Saved: epoch_17_action_down.png
  ✓ Saved: epoch_18_ball_position.png
  ✓ Saved: epoch_18_player_scores.png
  ✓ Saved: epoch_18_cpu_scores.png
  ✓ Saved: epoch_18_player_paddle.png
  ✓ Saved: epoch_18_cpu_paddle.png
  ✓ Saved: epoch_18_action_stay.png
  ✓ Saved: epoch_18_action_up.png
  ✓ Saved: epoch_18_action_down.png
  ✓ Saved: epoch_19_ball_position.png
  ✓ Saved: epoch_19_player_scores.png
  ✓ Saved: epoch_19_cpu_scores.png
  ✓ Saved: epoch_19_player_paddle.png
  ✓ Saved: epoch_19_cpu_paddle.png
  ✓ Saved: epoch_19_action_stay.png
  ✓ Saved: epoch_19_action_up.png
  ✓ Saved: epoch_19_action_down.png
  ✓ Saved: epoch_20_ball_position.png
  ✓ Saved: epoch_20_player_scores.png
  ✓ Saved: epoch_20_cpu_scores.png
  ✓ Saved: epoch_20_player_paddle.png
  ✓ Saved: epoch_20_cpu_paddle.png
  ✓ Saved: epoch_20_action_stay.png
  ✓ Saved: epoch_20_action_up.png
  ✓ Saved: epoch_20_action_down.png
  ✓ Saved: epoch_21_ball_position.png
  ✓ Saved: epoch_21_player_scores.png
  ✓ Saved: epoch_21_cpu_scores.png
  ✓ Saved: epoch_21_player_paddle.png
  ✓ Saved: epoch_21_cpu_paddle.png
  ✓ Saved: epoch_21_action_stay.png
  ✓ Saved: epoch_21_action_up.png
  ✓ Saved: epoch_21_action_down.png
  ✓ Saved: epoch_22_ball_position.png
  ✓ Saved: epoch_22_player_scores.png
  ✓ Saved: epoch_22_cpu_scores.png
  ✓ Saved: epoch_22_player_paddle.png
  ✓ Saved: epoch_22_cpu_paddle.png
  ✓ Saved: epoch_22_action_stay.png
  ✓ Saved: epoch_22_action_up.png
  ✓ Saved: epoch_22_action_down.png
  ✓ Saved: epoch_23_ball_position.png
  ✓ Saved: epoch_23_player_scores.png
  ✓ Saved: epoch_23_cpu_scores.png
  ✓ Saved: epoch_23_player_paddle.png
  ✓ Saved: epoch_23_cpu_paddle.png
  ✓ Saved: epoch_23_action_stay.png
  ✓ Saved: epoch_23_action_up.png
  ✓ Saved: epoch_23_action_down.png
  ✓ Saved: epoch_24_ball_position.png
  ✓ Saved: epoch_24_player_scores.png
  ✓ Saved: epoch_24_cpu_scores.png
  ✓ Saved: epoch_24_player_paddle.png
  ✓ Saved: epoch_24_cpu_paddle.png
  ✓ Saved: epoch_24_action_stay.png
  ✓ Saved: epoch_24_action_up.png
  ✓ Saved: epoch_24_action_down.png
  ✓ Saved: epoch_25_ball_position.png
  ✓ Saved: epoch_25_player_scores.png
  ✓ Saved: epoch_25_cpu_scores.png
  ✓ Saved: epoch_25_player_paddle.png
  ✓ Saved: epoch_25_cpu_paddle.png
  ✓ Saved: epoch_25_action_stay.png
  ✓ Saved: epoch_25_action_up.png
  ✓ Saved: epoch_25_action_down.png
  ✓ Saved: epoch_26_ball_position.png
  ✓ Saved: epoch_26_player_scores.png
  ✓ Saved: epoch_26_cpu_scores.png
  ✓ Saved: epoch_26_player_paddle.png
  ✓ Saved: epoch_26_cpu_paddle.png
  ✓ Saved: epoch_26_action_stay.png
  ✓ Saved: epoch_26_action_up.png
  ✓ Saved: epoch_26_action_down.png
  ✓ Saved: epoch_27_ball_position.png
  ✓ Saved: epoch_27_player_scores.png
  ✓ Saved: epoch_27_cpu_scores.png
  ✓ Saved: epoch_27_player_paddle.png
  ✓ Saved: epoch_27_cpu_paddle.png
  ✓ Saved: epoch_27_action_stay.png
  ✓ Saved: epoch_27_action_up.png
  ✓ Saved: epoch_27_action_down.png
  ✓ Saved: epoch_28_ball_position.png
  ✓ Saved: epoch_28_player_scores.png
  ✓ Saved: epoch_28_cpu_scores.png
  ✓ Saved: epoch_28_player_paddle.png
  ✓ Saved: epoch_28_cpu_paddle.png
  ✓ Saved: epoch_28_action_stay.png
  ✓ Saved: epoch_28_action_up.png
  ✓ Saved: epoch_28_action_down.png
  ✓ Saved: epoch_29_ball_position.png
  ✓ Saved: epoch_29_player_scores.png
  ✓ Saved: epoch_29_cpu_scores.png
  ✓ Saved: epoch_29_player_paddle.png
  ✓ Saved: epoch_29_cpu_paddle.png
  ✓ Saved: epoch_29_action_stay.png
  ✓ Saved: epoch_29_action_up.png
  ✓ Saved: epoch_29_action_down.png
  ✓ Saved: epoch_30_ball_position.png
  ✓ Saved: epoch_30_player_scores.png
  ✓ Saved: epoch_30_cpu_scores.png
  ✓ Saved: epoch_30_player_paddle.png
  ✓ Saved: epoch_30_cpu_paddle.png
  ✓ Saved: epoch_30_action_stay.png
  ✓ Saved: epoch_30_action_up.png
  ✓ Saved: epoch_30_action_down.png
  ✓ Saved: epoch_31_ball_position.png
  ✓ Saved: epoch_31_player_scores.png
  ✓ Saved: epoch_31_cpu_scores.png
  ✓ Saved: epoch_31_player_paddle.png
  ✓ Saved: epoch_31_cpu_paddle.png
  ✓ Saved: epoch_31_action_stay.png
  ✓ Saved: epoch_31_action_up.png
  ✓ Saved: epoch_31_action_down.png
  ✓ Saved: epoch_32_ball_position.png
  ✓ Saved: epoch_32_player_scores.png
  ✓ Saved: epoch_32_cpu_scores.png
  ✓ Saved: epoch_32_player_paddle.png
  ✓ Saved: epoch_32_cpu_paddle.png
  ✓ Saved: epoch_32_action_stay.png
  ✓ Saved: epoch_32_action_up.png
  ✓ Saved: epoch_32_action_down.png
  ✓ Saved: epoch_33_ball_position.png
  ✓ Saved: epoch_33_player_scores.png
  ✓ Saved: epoch_33_cpu_scores.png
  ✓ Saved: epoch_33_player_paddle.png
  ✓ Saved: epoch_33_cpu_paddle.png
  ✓ Saved: epoch_33_action_stay.png
  ✓ Saved: epoch_33_action_up.png
  ✓ Saved: epoch_33_action_down.png
  ✓ Saved: epoch_34_ball_position.png
  ✓ Saved: epoch_34_player_scores.png
  ✓ Saved: epoch_34_cpu_scores.png
  ✓ Saved: epoch_34_player_paddle.png
  ✓ Saved: epoch_34_cpu_paddle.png
  ✓ Saved: epoch_34_action_stay.png
  ✓ Saved: epoch_34_action_up.png
  ✓ Saved: epoch_34_action_down.png
  ✓ Saved: epoch_35_ball_position.png
  ✓ Saved: epoch_35_player_scores.png
  ✓ Saved: epoch_35_cpu_scores.png
  ✓ Saved: epoch_35_player_paddle.png
  ✓ Saved: epoch_35_cpu_paddle.png
  ✓ Saved: epoch_35_action_stay.png
  ✓ Saved: epoch_35_action_up.png
  ✓ Saved: epoch_35_action_down.png
  ✓ Saved: epoch_36_ball_position.png
  ✓ Saved: epoch_36_player_scores.png
  ✓ Saved: epoch_36_cpu_scores.png
  ✓ Saved: epoch_36_player_paddle.png
  ✓ Saved: epoch_36_cpu_paddle.png
  ✓ Saved: epoch_36_action_stay.png
  ✓ Saved: epoch_36_action_up.png
  ✓ Saved: epoch_36_action_down.png
  ✓ Saved: epoch_37_ball_position.png
  ✓ Saved: epoch_37_player_scores.png
  ✓ Saved: epoch_37_cpu_scores.png
  ✓ Saved: epoch_37_player_paddle.png
  ✓ Saved: epoch_37_cpu_paddle.png
  ✓ Saved: epoch_37_action_stay.png
  ✓ Saved: epoch_37_action_up.png
  ✓ Saved: epoch_37_action_down.png
  ✓ Saved: epoch_38_ball_position.png
  ✓ Saved: epoch_38_player_scores.png
  ✓ Saved: epoch_38_cpu_scores.png
  ✓ Saved: epoch_38_player_paddle.png
  ✓ Saved: epoch_38_cpu_paddle.png
  ✓ Saved: epoch_38_action_stay.png
  ✓ Saved: epoch_38_action_up.png
  ✓ Saved: epoch_38_action_down.png
  ✓ Saved: epoch_39_ball_position.png
  ✓ Saved: epoch_39_player_scores.png
  ✓ Saved: epoch_39_cpu_scores.png
  ✓ Saved: epoch_39_player_paddle.png
  ✓ Saved: epoch_39_cpu_paddle.png
  ✓ Saved: epoch_39_action_stay.png
  ✓ Saved: epoch_39_action_up.png
  ✓ Saved: epoch_39_action_down.png
  ✓ Saved: epoch_40_ball_position.png
  ✓ Saved: epoch_40_player_scores.png
  ✓ Saved: epoch_40_cpu_scores.png
  ✓ Saved: epoch_40_player_paddle.png
  ✓ Saved: epoch_40_cpu_paddle.png
  ✓ Saved: epoch_40_action_stay.png
  ✓ Saved: epoch_40_action_up.png
  ✓ Saved: epoch_40_action_down.png
  ✓ Saved: epoch_41_ball_position.png
  ✓ Saved: epoch_41_player_scores.png
  ✓ Saved: epoch_41_cpu_scores.png
  ✓ Saved: epoch_41_player_paddle.png
  ✓ Saved: epoch_41_cpu_paddle.png
  ✓ Saved: epoch_41_action_stay.png
  ✓ Saved: epoch_41_action_up.png
  ✓ Saved: epoch_41_action_down.png
  ✓ Saved: epoch_42_ball_position.png
  ✓ Saved: epoch_42_player_scores.png
  ✓ Saved: epoch_42_cpu_scores.png
  ✓ Saved: epoch_42_player_paddle.png
  ✓ Saved: epoch_42_cpu_paddle.png
  ✓ Saved: epoch_42_action_stay.png
  ✓ Saved: epoch_42_action_up.png
  ✓ Saved: epoch_42_action_down.png
  ✓ Saved: epoch_43_ball_position.png
  ✓ Saved: epoch_43_player_scores.png
  ✓ Saved: epoch_43_cpu_scores.png
  ✓ Saved: epoch_43_player_paddle.png
  ✓ Saved: epoch_43_cpu_paddle.png
  ✓ Saved: epoch_43_action_stay.png
  ✓ Saved: epoch_43_action_up.png
  ✓ Saved: epoch_43_action_down.png
  ✓ Saved: epoch_44_ball_position.png
  ✓ Saved: epoch_44_player_scores.png
  ✓ Saved: epoch_44_cpu_scores.png
  ✓ Saved: epoch_44_player_paddle.png
  ✓ Saved: epoch_44_cpu_paddle.png
  ✓ Saved: epoch_44_action_stay.png
  ✓ Saved: epoch_44_action_up.png
  ✓ Saved: epoch_44_action_down.png
  ✓ Saved: epoch_45_ball_position.png
  ✓ Saved: epoch_45_player_scores.png
  ✓ Saved: epoch_45_cpu_scores.png
  ✓ Saved: epoch_45_player_paddle.png
  ✓ Saved: epoch_45_cpu_paddle.png
  ✓ Saved: epoch_45_action_stay.png
  ✓ Saved: epoch_45_action_up.png
  ✓ Saved: epoch_45_action_down.png
  ✓ Saved: epoch_46_ball_position.png
  ✓ Saved: epoch_46_player_scores.png
  ✓ Saved: epoch_46_cpu_scores.png
  ✓ Saved: epoch_46_player_paddle.png
  ✓ Saved: epoch_46_cpu_paddle.png
  ✓ Saved: epoch_46_action_stay.png
  ✓ Saved: epoch_46_action_up.png
  ✓ Saved: epoch_46_action_down.png
  ✓ Saved: epoch_47_ball_position.png
  ✓ Saved: epoch_47_player_scores.png
  ✓ Saved: epoch_47_cpu_scores.png
  ✓ Saved: epoch_47_player_paddle.png
  ✓ Saved: epoch_47_cpu_paddle.png
  ✓ Saved: epoch_47_action_stay.png
  ✓ Saved: epoch_47_action_up.png
  ✓ Saved: epoch_47_action_down.png
  ✓ Saved: epoch_48_ball_position.png
  ✓ Saved: epoch_48_player_scores.png
  ✓ Saved: epoch_48_cpu_scores.png
  ✓ Saved: epoch_48_player_paddle.png
  ✓ Saved: epoch_48_cpu_paddle.png
  ✓ Saved: epoch_48_action_stay.png
  ✓ Saved: epoch_48_action_up.png
  ✓ Saved: epoch_48_action_down.png
  ✓ Saved: epoch_49_ball_position.png
  ✓ Saved: epoch_49_player_scores.png
  ✓ Saved: epoch_49_cpu_scores.png
  ✓ Saved: epoch_49_player_paddle.png
  ✓ Saved: epoch_49_cpu_paddle.png
  ✓ Saved: epoch_49_action_stay.png
  ✓ Saved: epoch_49_action_up.png
  ✓ Saved: epoch_49_action_down.png
  ✓ Saved: epoch_50_ball_position.png
  ✓ Saved: epoch_50_player_scores.png
  ✓ Saved: epoch_50_cpu_scores.png
  ✓ Saved: epoch_50_player_paddle.png
  ✓ Saved: epoch_50_cpu_paddle.png
  ✓ Saved: epoch_50_action_stay.png
  ✓ Saved: epoch_50_action_up.png
  ✓ Saved: epoch_50_action_down.png
  ✓ Saved: epoch_51_ball_position.png
  ✓ Saved: epoch_51_player_scores.png
  ✓ Saved: epoch_51_cpu_scores.png
  ✓ Saved: epoch_51_player_paddle.png
  ✓ Saved: epoch_51_cpu_paddle.png
  ✓ Saved: epoch_51_action_stay.png
  ✓ Saved: epoch_51_action_up.png
  ✓ Saved: epoch_51_action_down.png
  ✓ Saved: epoch_52_ball_position.png
  ✓ Saved: epoch_52_player_scores.png
  ✓ Saved: epoch_52_cpu_scores.png
  ✓ Saved: epoch_52_player_paddle.png
  ✓ Saved: epoch_52_cpu_paddle.png
  ✓ Saved: epoch_52_action_stay.png
  ✓ Saved: epoch_52_action_up.png
  ✓ Saved: epoch_52_action_down.png
  ✓ Saved: epoch_53_ball_position.png
  ✓ Saved: epoch_53_player_scores.png
  ✓ Saved: epoch_53_cpu_scores.png
  ✓ Saved: epoch_53_player_paddle.png
  ✓ Saved: epoch_53_cpu_paddle.png
  ✓ Saved: epoch_53_action_stay.png
  ✓ Saved: epoch_53_action_up.png
  ✓ Saved: epoch_53_action_down.png
  ✓ Saved: epoch_54_ball_position.png
  ✓ Saved: epoch_54_player_scores.png
  ✓ Saved: epoch_54_cpu_scores.png
  ✓ Saved: epoch_54_player_paddle.png
  ✓ Saved: epoch_54_cpu_paddle.png
  ✓ Saved: epoch_54_action_stay.png
  ✓ Saved: epoch_54_action_up.png
  ✓ Saved: epoch_54_action_down.png
  ✓ Saved: epoch_55_ball_position.png
  ✓ Saved: epoch_55_player_scores.png
  ✓ Saved: epoch_55_cpu_scores.png
  ✓ Saved: epoch_55_player_paddle.png
  ✓ Saved: epoch_55_cpu_paddle.png
  ✓ Saved: epoch_55_action_stay.png
  ✓ Saved: epoch_55_action_up.png
  ✓ Saved: epoch_55_action_down.png
  ✓ Saved: epoch_56_ball_position.png
  ✓ Saved: epoch_56_player_scores.png
  ✓ Saved: epoch_56_cpu_scores.png
  ✓ Saved: epoch_56_player_paddle.png
  ✓ Saved: epoch_56_cpu_paddle.png
  ✓ Saved: epoch_56_action_stay.png
  ✓ Saved: epoch_56_action_up.png
  ✓ Saved: epoch_56_action_down.png
  ✓ Saved: epoch_57_ball_position.png
  ✓ Saved: epoch_57_player_scores.png
  ✓ Saved: epoch_57_cpu_scores.png
  ✓ Saved: epoch_57_player_paddle.png
  ✓ Saved: epoch_57_cpu_paddle.png
  ✓ Saved: epoch_57_action_stay.png
  ✓ Saved: epoch_57_action_up.png
  ✓ Saved: epoch_57_action_down.png
  ✓ Saved: epoch_58_ball_position.png
  ✓ Saved: epoch_58_player_scores.png
  ✓ Saved: epoch_58_cpu_scores.png
  ✓ Saved: epoch_58_player_paddle.png
  ✓ Saved: epoch_58_cpu_paddle.png
  ✓ Saved: epoch_58_action_stay.png
  ✓ Saved: epoch_58_action_up.png
  ✓ Saved: epoch_58_action_down.png
  ✓ Saved: epoch_59_ball_position.png
  ✓ Saved: epoch_59_player_scores.png
  ✓ Saved: epoch_59_cpu_scores.png
  ✓ Saved: epoch_59_player_paddle.png
  ✓ Saved: epoch_59_cpu_paddle.png
  ✓ Saved: epoch_59_action_stay.png
  ✓ Saved: epoch_59_action_up.png
  ✓ Saved: epoch_59_action_down.png
  ✓ Saved: epoch_60_ball_position.png
  ✓ Saved: epoch_60_player_scores.png
  ✓ Saved: epoch_60_cpu_scores.png
  ✓ Saved: epoch_60_player_paddle.png
  ✓ Saved: epoch_60_cpu_paddle.png
  ✓ Saved: epoch_60_action_stay.png
  ✓ Saved: epoch_60_action_up.png
  ✓ Saved: epoch_60_action_down.png
  ✓ Saved: epoch_61_ball_position.png
  ✓ Saved: epoch_61_player_scores.png
  ✓ Saved: epoch_61_cpu_scores.png
  ✓ Saved: epoch_61_player_paddle.png
  ✓ Saved: epoch_61_cpu_paddle.png
  ✓ Saved: epoch_61_action_stay.png
  ✓ Saved: epoch_61_action_up.png
  ✓ Saved: epoch_61_action_down.png
  ✓ Saved: epoch_62_ball_position.png
  ✓ Saved: epoch_62_player_scores.png
  ✓ Saved: epoch_62_cpu_scores.png
  ✓ Saved: epoch_62_player_paddle.png
  ✓ Saved: epoch_62_cpu_paddle.png
  ✓ Saved: epoch_62_action_stay.png
  ✓ Saved: epoch_62_action_up.png
  ✓ Saved: epoch_62_action_down.png
  ✓ Saved: epoch_63_ball_position.png
  ✓ Saved: epoch_63_player_scores.png
  ✓ Saved: epoch_63_cpu_scores.png
  ✓ Saved: epoch_63_player_paddle.png
  ✓ Saved: epoch_63_cpu_paddle.png
  ✓ Saved: epoch_63_action_stay.png
  ✓ Saved: epoch_63_action_up.png
  ✓ Saved: epoch_63_action_down.png
  ✓ Saved: epoch_64_ball_position.png
  ✓ Saved: epoch_64_player_scores.png
  ✓ Saved: epoch_64_cpu_scores.png
  ✓ Saved: epoch_64_player_paddle.png
  ✓ Saved: epoch_64_cpu_paddle.png
  ✓ Saved: epoch_64_action_stay.png
  ✓ Saved: epoch_64_action_up.png
  ✓ Saved: epoch_64_action_down.png
  ✓ Saved: epoch_65_ball_position.png
  ✓ Saved: epoch_65_player_scores.png
  ✓ Saved: epoch_65_cpu_scores.png
  ✓ Saved: epoch_65_player_paddle.png
  ✓ Saved: epoch_65_cpu_paddle.png
  ✓ Saved: epoch_65_action_stay.png
  ✓ Saved: epoch_65_action_up.png
  ✓ Saved: epoch_65_action_down.png
  ✓ Saved: epoch_66_ball_position.png
  ✓ Saved: epoch_66_player_scores.png
  ✓ Saved: epoch_66_cpu_scores.png
  ✓ Saved: epoch_66_player_paddle.png
  ✓ Saved: epoch_66_cpu_paddle.png
  ✓ Saved: epoch_66_action_stay.png
  ✓ Saved: epoch_66_action_up.png
  ✓ Saved: epoch_66_action_down.png
  ✓ Saved: epoch_67_ball_position.png
  ✓ Saved: epoch_67_player_scores.png
  ✓ Saved: epoch_67_cpu_scores.png
  ✓ Saved: epoch_67_player_paddle.png
  ✓ Saved: epoch_67_cpu_paddle.png
  ✓ Saved: epoch_67_action_stay.png
  ✓ Saved: epoch_67_action_up.png
  ✓ Saved: epoch_67_action_down.png
  ✓ Saved: epoch_68_ball_position.png
  ✓ Saved: epoch_68_player_scores.png
  ✓ Saved: epoch_68_cpu_scores.png
  ✓ Saved: epoch_68_player_paddle.png
  ✓ Saved: epoch_68_cpu_paddle.png
  ✓ Saved: epoch_68_action_stay.png
  ✓ Saved: epoch_68_action_up.png
  ✓ Saved: epoch_68_action_down.png
  ✓ Saved: epoch_69_ball_position.png
  ✓ Saved: epoch_69_player_scores.png
  ✓ Saved: epoch_69_cpu_scores.png
  ✓ Saved: epoch_69_player_paddle.png
  ✓ Saved: epoch_69_cpu_paddle.png
  ✓ Saved: epoch_69_action_stay.png
  ✓ Saved: epoch_69_action_up.png
  ✓ Saved: epoch_69_action_down.png
  ✓ Saved: epoch_70_ball_position.png
  ✓ Saved: epoch_70_player_scores.png
  ✓ Saved: epoch_70_cpu_scores.png
  ✓ Saved: epoch_70_player_paddle.png
  ✓ Saved: epoch_70_cpu_paddle.png
  ✓ Saved: epoch_70_action_stay.png
  ✓ Saved: epoch_70_action_up.png
  ✓ Saved: epoch_70_action_down.png
  ✓ Saved: epoch_71_ball_position.png
  ✓ Saved: epoch_71_player_scores.png
  ✓ Saved: epoch_71_cpu_scores.png
  ✓ Saved: epoch_71_player_paddle.png
  ✓ Saved: epoch_71_cpu_paddle.png
  ✓ Saved: epoch_71_action_stay.png
  ✓ Saved: epoch_71_action_up.png
  ✓ Saved: epoch_71_action_down.png
  ✓ Saved: epoch_72_ball_position.png
  ✓ Saved: epoch_72_player_scores.png
  ✓ Saved: epoch_72_cpu_scores.png
  ✓ Saved: epoch_72_player_paddle.png
  ✓ Saved: epoch_72_cpu_paddle.png
  ✓ Saved: epoch_72_action_stay.png
  ✓ Saved: epoch_72_action_up.png
  ✓ Saved: epoch_72_action_down.png
  ✓ Saved: epoch_73_ball_position.png
  ✓ Saved: epoch_73_player_scores.png
  ✓ Saved: epoch_73_cpu_scores.png
  ✓ Saved: epoch_73_player_paddle.png
  ✓ Saved: epoch_73_cpu_paddle.png
  ✓ Saved: epoch_73_action_stay.png
  ✓ Saved: epoch_73_action_up.png
  ✓ Saved: epoch_73_action_down.png
  ✓ Saved: epoch_74_ball_position.png
  ✓ Saved: epoch_74_player_scores.png
  ✓ Saved: epoch_74_cpu_scores.png
  ✓ Saved: epoch_74_player_paddle.png
  ✓ Saved: epoch_74_cpu_paddle.png
  ✓ Saved: epoch_74_action_stay.png
  ✓ Saved: epoch_74_action_up.png
  ✓ Saved: epoch_74_action_down.png
  ✓ Saved: epoch_75_ball_position.png
  ✓ Saved: epoch_75_player_scores.png
  ✓ Saved: epoch_75_cpu_scores.png
  ✓ Saved: epoch_75_player_paddle.png
  ✓ Saved: epoch_75_cpu_paddle.png
  ✓ Saved: epoch_75_action_stay.png
  ✓ Saved: epoch_75_action_up.png
  ✓ Saved: epoch_75_action_down.png
  ✓ Saved: epoch_76_ball_position.png
  ✓ Saved: epoch_76_player_scores.png
  ✓ Saved: epoch_76_cpu_scores.png
  ✓ Saved: epoch_76_player_paddle.png
  ✓ Saved: epoch_76_cpu_paddle.png
  ✓ Saved: epoch_76_action_stay.png
  ✓ Saved: epoch_76_action_up.png
  ✓ Saved: epoch_76_action_down.png
  ✓ Saved: epoch_77_ball_position.png
  ✓ Saved: epoch_77_player_scores.png
  ✓ Saved: epoch_77_cpu_scores.png
  ✓ Saved: epoch_77_player_paddle.png
  ✓ Saved: epoch_77_cpu_paddle.png
  ✓ Saved: epoch_77_action_stay.png
  ✓ Saved: epoch_77_action_up.png
  ✓ Saved: epoch_77_action_down.png
  ✓ Saved: epoch_78_ball_position.png
  ✓ Saved: epoch_78_player_scores.png
  ✓ Saved: epoch_78_cpu_scores.png
  ✓ Saved: epoch_78_player_paddle.png
  ✓ Saved: epoch_78_cpu_paddle.png
  ✓ Saved: epoch_78_action_stay.png
  ✓ Saved: epoch_78_action_up.png
  ✓ Saved: epoch_78_action_down.png
  ✓ Saved: epoch_79_ball_position.png
  ✓ Saved: epoch_79_player_scores.png
  ✓ Saved: epoch_79_cpu_scores.png
  ✓ Saved: epoch_79_player_paddle.png
  ✓ Saved: epoch_79_cpu_paddle.png
  ✓ Saved: epoch_79_action_stay.png
  ✓ Saved: epoch_79_action_up.png
  ✓ Saved: epoch_79_action_down.png
  ✓ Saved: epoch_80_ball_position.png
  ✓ Saved: epoch_80_player_scores.png
  ✓ Saved: epoch_80_cpu_scores.png
  ✓ Saved: epoch_80_player_paddle.png
  ✓ Saved: epoch_80_cpu_paddle.png
  ✓ Saved: epoch_80_action_stay.png
  ✓ Saved: epoch_80_action_up.png
  ✓ Saved: epoch_80_action_down.png
  ✓ Saved: epoch_81_ball_position.png
  ✓ Saved: epoch_81_player_scores.png
  ✓ Saved: epoch_81_cpu_scores.png
  ✓ Saved: epoch_81_player_paddle.png
  ✓ Saved: epoch_81_cpu_paddle.png
  ✓ Saved: epoch_81_action_stay.png
  ✓ Saved: epoch_81_action_up.png
  ✓ Saved: epoch_81_action_down.png
  ✓ Saved: epoch_82_ball_position.png
  ✓ Saved: epoch_82_player_scores.png
  ✓ Saved: epoch_82_cpu_scores.png
  ✓ Saved: epoch_82_player_paddle.png
  ✓ Saved: epoch_82_cpu_paddle.png
  ✓ Saved: epoch_82_action_stay.png
  ✓ Saved: epoch_82_action_up.png
  ✓ Saved: epoch_82_action_down.png
  ✓ Saved: epoch_83_ball_position.png
  ✓ Saved: epoch_83_player_scores.png
  ✓ Saved: epoch_83_cpu_scores.png
  ✓ Saved: epoch_83_player_paddle.png
  ✓ Saved: epoch_83_cpu_paddle.png
  ✓ Saved: epoch_83_action_stay.png
  ✓ Saved: epoch_83_action_up.png
  ✓ Saved: epoch_83_action_down.png
  ✓ Saved: epoch_84_ball_position.png
  ✓ Saved: epoch_84_player_scores.png
  ✓ Saved: epoch_84_cpu_scores.png
  ✓ Saved: epoch_84_player_paddle.png
  ✓ Saved: epoch_84_cpu_paddle.png
  ✓ Saved: epoch_84_action_stay.png
  ✓ Saved: epoch_84_action_up.png
  ✓ Saved: epoch_84_action_down.png
  ✓ Saved: epoch_85_ball_position.png
  ✓ Saved: epoch_85_player_scores.png
  ✓ Saved: epoch_85_cpu_scores.png
  ✓ Saved: epoch_85_player_paddle.png
  ✓ Saved: epoch_85_cpu_paddle.png
  ✓ Saved: epoch_85_action_stay.png
  ✓ Saved: epoch_85_action_up.png
  ✓ Saved: epoch_85_action_down.png
  ✓ Saved: epoch_86_ball_position.png
  ✓ Saved: epoch_86_player_scores.png
  ✓ Saved: epoch_86_cpu_scores.png
  ✓ Saved: epoch_86_player_paddle.png
  ✓ Saved: epoch_86_cpu_paddle.png
  ✓ Saved: epoch_86_action_stay.png
  ✓ Saved: epoch_86_action_up.png
  ✓ Saved: epoch_86_action_down.png
  ✓ Saved: epoch_87_ball_position.png
  ✓ Saved: epoch_87_player_scores.png
  ✓ Saved: epoch_87_cpu_scores.png
  ✓ Saved: epoch_87_player_paddle.png
  ✓ Saved: epoch_87_cpu_paddle.png
  ✓ Saved: epoch_87_action_stay.png
  ✓ Saved: epoch_87_action_up.png
  ✓ Saved: epoch_87_action_down.png
  ✓ Saved: epoch_88_ball_position.png
  ✓ Saved: epoch_88_player_scores.png
  ✓ Saved: epoch_88_cpu_scores.png
  ✓ Saved: epoch_88_player_paddle.png
  ✓ Saved: epoch_88_cpu_paddle.png
  ✓ Saved: epoch_88_action_stay.png
  ✓ Saved: epoch_88_action_up.png
  ✓ Saved: epoch_88_action_down.png
  ✓ Saved: epoch_89_ball_position.png
  ✓ Saved: epoch_89_player_scores.png
  ✓ Saved: epoch_89_cpu_scores.png
  ✓ Saved: epoch_89_player_paddle.png
  ✓ Saved: epoch_89_cpu_paddle.png
  ✓ Saved: epoch_89_action_stay.png
  ✓ Saved: epoch_89_action_up.png
  ✓ Saved: epoch_89_action_down.png
  ✓ Saved: epoch_90_ball_position.png
  ✓ Saved: epoch_90_player_scores.png
  ✓ Saved: epoch_90_cpu_scores.png
  ✓ Saved: epoch_90_player_paddle.png
  ✓ Saved: epoch_90_cpu_paddle.png
  ✓ Saved: epoch_90_action_stay.png
  ✓ Saved: epoch_90_action_up.png
  ✓ Saved: epoch_90_action_down.png
  ✓ Saved: epoch_91_ball_position.png
  ✓ Saved: epoch_91_player_scores.png
  ✓ Saved: epoch_91_cpu_scores.png
  ✓ Saved: epoch_91_player_paddle.png
  ✓ Saved: epoch_91_cpu_paddle.png
  ✓ Saved: epoch_91_action_stay.png
  ✓ Saved: epoch_91_action_up.png
  ✓ Saved: epoch_91_action_down.png
  ✓ Saved: epoch_92_ball_position.png
  ✓ Saved: epoch_92_player_scores.png
  ✓ Saved: epoch_92_cpu_scores.png
  ✓ Saved: epoch_92_player_paddle.png
  ✓ Saved: epoch_92_cpu_paddle.png
  ✓ Saved: epoch_92_action_stay.png
  ✓ Saved: epoch_92_action_up.png
  ✓ Saved: epoch_92_action_down.png
  ✓ Saved: epoch_93_ball_position.png
  ✓ Saved: epoch_93_player_scores.png
  ✓ Saved: epoch_93_cpu_scores.png
  ✓ Saved: epoch_93_player_paddle.png
  ✓ Saved: epoch_93_cpu_paddle.png
  ✓ Saved: epoch_93_action_stay.png
  ✓ Saved: epoch_93_action_up.png
  ✓ Saved: epoch_93_action_down.png
  ✓ Saved: epoch_94_ball_position.png
  ✓ Saved: epoch_94_player_scores.png
  ✓ Saved: epoch_94_cpu_scores.png
  ✓ Saved: epoch_94_player_paddle.png
  ✓ Saved: epoch_94_cpu_paddle.png
  ✓ Saved: epoch_94_action_stay.png
  ✓ Saved: epoch_94_action_up.png
  ✓ Saved: epoch_94_action_down.png
  ✓ Saved: epoch_95_ball_position.png
  ✓ Saved: epoch_95_player_scores.png
  ✓ Saved: epoch_95_cpu_scores.png
  ✓ Saved: epoch_95_player_paddle.png
  ✓ Saved: epoch_95_cpu_paddle.png
  ✓ Saved: epoch_95_action_stay.png
  ✓ Saved: epoch_95_action_up.png
  ✓ Saved: epoch_95_action_down.png
  ✓ Saved: epoch_96_ball_position.png
  ✓ Saved: epoch_96_player_scores.png
  ✓ Saved: epoch_96_cpu_scores.png
  ✓ Saved: epoch_96_player_paddle.png
  ✓ Saved: epoch_96_cpu_paddle.png
  ✓ Saved: epoch_96_action_stay.png
  ✓ Saved: epoch_96_action_up.png
  ✓ Saved: epoch_96_action_down.png
  ✓ Saved: epoch_97_ball_position.png
  ✓ Saved: epoch_97_player_scores.png
  ✓ Saved: epoch_97_cpu_scores.png
  ✓ Saved: epoch_97_player_paddle.png
  ✓ Saved: epoch_97_cpu_paddle.png
  ✓ Saved: epoch_97_action_stay.png
  ✓ Saved: epoch_97_action_up.png
  ✓ Saved: epoch_97_action_down.png
  ✓ Saved: epoch_98_ball_position.png
  ✓ Saved: epoch_98_player_scores.png
  ✓ Saved: epoch_98_cpu_scores.png
  ✓ Saved: epoch_98_player_paddle.png
  ✓ Saved: epoch_98_cpu_paddle.png
  ✓ Saved: epoch_98_action_stay.png
  ✓ Saved: epoch_98_action_up.png
  ✓ Saved: epoch_98_action_down.png
  ✓ Saved: epoch_99_ball_position.png
  ✓ Saved: epoch_99_player_scores.png
  ✓ Saved: epoch_99_cpu_scores.png
  ✓ Saved: epoch_99_player_paddle.png
  ✓ Saved: epoch_99_cpu_paddle.png
  ✓ Saved: epoch_99_action_stay.png
  ✓ Saved: epoch_99_action_up.png
  ✓ Saved: epoch_99_action_down.png
  ✓ Saved: temporal_progression.png (4×100 grid)

✓ Heatmap PNG export complete!
  Total images: 100 epochs × 8 types
  Location: outputs\exp_001_20251117_041401\recorded_data\heatmaps\heatmap_images/

============================================================
HEATMAP DATA SUMMARY
============================================================
Total Epochs: 100
Total Episodes Recorded: 20000
Total Frames Recorded: 86,859,059
Grid Resolution: 20×24
Court Size: 160×192

Performance Progression (across epochs):
Epoch    Episodes     Player Wins     CPU Wins        Win %       
------------------------------------------------------------
0        200          0               0                      0.0%
1        200          0               0                      0.0%
2        200          0               0                      0.0%
3        200          0               0                      0.0%
4        200          0               0                      0.0%
5        200          0               0                      0.0%
6        200          0               0                      0.0%
7        200          0               0                      0.0%
8        200          0               0                      0.0%
9        200          0               0                      0.0%
10       200          0               0                      0.0%
11       200          0               0                      0.0%
12       200          0               0                      0.0%
13       200          0               0                      0.0%
14       200          0               0                      0.0%
15       200          0               0                      0.0%
16       200          0               0                      0.0%
17       200          0               0                      0.0%
18       200          0               0                      0.0%
19       200          0               0                      0.0%
20       200          0               0                      0.0%
21       200          0               0                      0.0%
22       200          0               0                      0.0%
23       200          0               0                      0.0%
24       200          0               0                      0.0%
25       200          0               0                      0.0%
26       200          0               0                      0.0%
27       200          0               0                      0.0%
28       200          0               0                      0.0%
29       200          0               0                      0.0%
30       200          0               0                      0.0%
31       200          0               0                      0.0%
32       200          0               0                      0.0%
33       200          0               0                      0.0%
34       200          0               0                      0.0%
35       200          0               0                      0.0%
36       200          0               0                      0.0%
37       200          0               0                      0.0%
38       200          0               0                      0.0%
39       200          0               0                      0.0%
40       200          0               0                      0.0%
41       200          0               0                      0.0%
42       200          0               0                      0.0%
43       200          0               0                      0.0%
44       200          0               0                      0.0%
45       200          0               0                      0.0%
46       200          0               0                      0.0%
47       200          0               0                      0.0%
48       200          0               0                      0.0%
49       200          0               0                      0.0%
50       200          0               0                      0.0%
51       200          0               0                      0.0%
52       200          0               0                      0.0%
53       200          0               0                      0.0%
54       200          0               0                      0.0%
55       200          0               0                      0.0%
56       200          0               0                      0.0%
57       200          0               0                      0.0%
58       200          0               0                      0.0%
59       200          0               0                      0.0%
60       200          0               0                      0.0%
61       200          0               0                      0.0%
62       200          0               0                      0.0%
63       200          0               0                      0.0%
64       200          0               0                      0.0%
65       200          0               0                      0.0%
66       200          0               0                      0.0%
67       200          0               0                      0.0%
68       200          0               0                      0.0%
69       200          0               0                      0.0%
70       200          0               0                      0.0%
71       200          0               0                      0.0%
72       200          0               0                      0.0%
73       200          0               0                      0.0%
74       200          0               0                      0.0%
75       200          0               0                      0.0%
76       200          0               0                      0.0%
77       200          0               0                      0.0%
78       200          0               0                      0.0%
79       200          0               0                      0.0%
80       200          0               0                      0.0%
81       200          0               0                      0.0%
82       200          0               0                      0.0%
83       200          0               0                      0.0%
84       200          0               0                      0.0%
85       200          0               0                      0.0%
86       200          0               0                      0.0%
87       200          0               0                      0.0%
88       200          0               0                      0.0%
89       200          0               0                      0.0%
90       200          0               0                      0.0%
91       200          0               0                      0.0%
92       200          0               0                      0.0%
93       200          0               0                      0.0%
94       200          0               0                      0.0%
95       200          0               0                      0.0%
96       200          0               0                      0.0%
97       200          0               0                      0.0%
98       200          0               0                      0.0%
99       200          0               0                      0.0%
============================================================

======================================================================
TRAINING COMPLETE
Total Training Time: 15:59:19.020443
======================================================================

✓ All results saved to: outputs\exp_001_20251117_041401/

  Models (outputs\exp_001_20251117_041401\saved_models/):
    - Model: exp_001_20251117_041401.npz
    - Config: exp_001_20251117_041401_config.json
    - Log: exp_001_20251117_041401.log

  Analytics (outputs\exp_001_20251117_041401\recorded_data/):
    - Training CSV: 20251117_041401.csv
    - Evaluation CSV: 20251117_041401_eval.csv
    - Summary: 20251117_041401_summary.txt
    - Plots (10): 20251117_041401_0*.png

  Heatmaps (outputs\exp_001_20251117_041401\recorded_data\heatmaps/):
    - Heatmap Data: exp_001_20251117_041401_heatmap.json
    - Epochs: 100
    - Frames: 86,859,059
======================================================================


======================================================================
TRAINING COMPLETE
======================================================================

✓ Results saved to: outputs\exp_001_20251117_041401/
  - Model: model.npz
  - Config: config_used.json
  - Metrics: training.csv, evaluation.csv
  - Heatmap: heatmap.json
  - Log: training.log

======================================================================
INITIALIZING TRAINING COMPONENTS
======================================================================

✓ Creating environment...
  Court: 160×192
  Paddle: 2×12
  CPU Difficulty: medium

✓ Creating agent (PolicyGradient)...
  Input Size: 16
  Hidden Size: 128
  Output Size: 3
  Learning Rate: 0.0015
  Discount Factor: 0.99

✓ Creating trainer (PolicyGradient)...
  Max Episodes: 1000
  Batch Size: 5
  Running Reward Decay: 0.99

✓ Creating heatmap recorder...
  Grid Resolution: 20×24
  Court Size: 160×192

✓ Creating training orchestrator...
  Experiment: featuretest_1
  Orchestrator will handle:
    - Training pipeline
    - Analytics logging
    - Heatmap recording
    - Model evaluation
    - Automatic saving
✓ Analytics initialized
  Timestamp: 20251129_154045
  Output dir: outputs\featuretest_1_20251129_154045\recorded_data
  All files saved as: 20251129_154045*

✓ Found existing training data: outputs\featuretest_1_20251129_154045\recorded_data\20251129_154045.csv
  Continuing from previous run...

======================================================================
STARTING TRAINING
======================================================================

======================================================================
TRAINING ORCHESTRATOR - UNIFIED PIPELINE
======================================================================
Experiment: featuretest_1
Timestamp: 20251129_154045
Output Root Directory: outputs\featuretest_1_20251129_154045/
Output Sub-Directories:
  - Models: outputs\featuretest_1_20251129_154045\saved_models/
  - Analytics: outputs\featuretest_1_20251129_154045\recorded_data/
  - Heatmaps: outputs\featuretest_1_20251129_154045\recorded_data\heatmaps/
  - Collision Analysis: outputs\featuretest_1_20251129_154045\recorded_data\collision_analysis/
Heatmap Recording: ✓ ENABLED
Collision Analysis: ✓ ENABLED

✓ Starting trainer...

============================================================
TRAINING PONG AGENT
============================================================
Agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
Learning Rate: 0.0015
Discount Factor: 0.99
Max Episodes: 1000
RMSprop Decay: 0.99
Running Reward Decay: 0.99
Reward Structure: Score=20.0, Hit=0.02, Loss=-1.0
Win Reward: 5000.0, Loss Penalty: -0.0
Heatmap Recording: ENABLED
Episodes per heatmap epoch: 200
Collision Analysis: ENABLED
Episodes per collision epoch: 200
============================================================

Episode  100 | Reward:  -20.36 | Running Avg:  -10.43 | Best:   -0.26 | Length: 3255
  ✓ Heatmap epoch saved (episodes 1-200)
  ✓ Collision epoch 0 saved
Episode  200 | Reward:  -20.40 | Running Avg:   -9.64 | Best:   19.68 | Length: 2973
Episode  300 | Reward:  -20.32 | Running Avg:   -6.17 | Best:   59.66 | Length: 3310
  ✓ Heatmap epoch saved (episodes 201-400)
  ✓ Collision epoch 1 saved
Episode  400 | Reward:   19.96 | Running Avg:    4.26 | Best:   79.88 | Length: 4277
Episode  500 | Reward:   39.86 | Running Avg:   12.47 | Best:   79.90 | Length: 3969
  ✓ Heatmap epoch saved (episodes 401-600)
  ✓ Collision epoch 2 saved
Episode  600 | Reward:   59.86 | Running Avg:   17.75 | Best:  119.78 | Length: 3943
Episode  700 | Reward:   40.08 | Running Avg:   19.89 | Best:  119.86 | Length: 4582
  ✓ Heatmap epoch saved (episodes 601-800)
  ✓ Collision epoch 3 saved
Episode  800 | Reward:   19.92 | Running Avg:   24.30 | Best:  119.86 | Length: 4028
Episode  900 | Reward:    0.12 | Running Avg:   24.39 | Best:  119.86 | Length: 4642
  ✓ Heatmap epoch saved (episodes 801-1000)
  ✓ Collision epoch 4 saved
Episode 1000 | Reward:   39.76 | Running Avg:   33.45 | Best:  119.86 | Length: 3561

============================================================
TRAINING COMPLETE
Final Running Average: 33.45
Best Episode Reward: 119.86
Total heatmap epochs: 5
Total collision epochs: 5
============================================================


✓ Logging training data to analytics...

✓ Evaluating...

============================================================
EVALUATING TRAINED AGENT (10 episodes)
============================================================

Eval Episode  1: Reward=  59.68, Player= 4, CPU=21, Length=3417
Eval Episode  2: Reward=  79.96, Player= 5, CPU=21, Length=4223
Eval Episode  3: Reward=  79.92, Player= 5, CPU=21, Length=4101
Eval Episode  4: Reward=  79.74, Player= 5, CPU=21, Length=3492
Eval Episode  5: Reward=  19.84, Player= 2, CPU=21, Length=3856
Eval Episode  6: Reward=  80.02, Player= 5, CPU=21, Length=4523
Eval Episode  7: Reward=  -0.12, Player= 1, CPU=21, Length=3906
Eval Episode  8: Reward=  59.94, Player= 4, CPU=21, Length=4235
Eval Episode  9: Reward=  -0.22, Player= 1, CPU=21, Length=3690
Eval Episode 10: Reward=  20.02, Player= 2, CPU=21, Length=4320

============================================================
Mean Reward: 47.88 ± 32.51
Reward Range: [-0.22, 80.02]
Win Rate: 0.0%
Mean Episode Length: 3976 steps
============================================================


✓ Logging evaluation data to analytics...

✓ Saving current model to models\featuretest_1.npz...
✓ Agent parameters saved to 'models\featuretest_1.npz'
✓ Saving timestamped backup to outputs\featuretest_1_20251129_154045\saved_models\featuretest_1_20251129_154045.npz...
✓ Agent parameters saved to 'outputs\featuretest_1_20251129_154045\saved_models\featuretest_1_20251129_154045.npz'

✓ Saving configuration to outputs\featuretest_1_20251129_154045\saved_models\featuretest_1_20251129_154045_config.json...

✓ Saving analytics summary...

✓ Summary saved to outputs\featuretest_1_20251129_154045\recorded_data\20251129_154045_summary.txt
============================================================
TRAINING SUMMARY
============================================================
Timestamp: 20251129_154045

TRAINING RESULTS
------------------------------------------------------------
Total episodes trained: 1000
Final running average reward: 45.11
Best episode reward: 119.86
Worst episode reward: -20.60
Mean episode reward: 12.16
Std episode reward: 28.74

EVALUATION METRICS
------------------------------------------------------------
Win rate: 0.0%
Total wins: 0 / 1000
Mean episode length: 3761 steps
Mean player score: 1.6
Mean CPU score: 21.0

REWARD COMPONENTS (Average)
------------------------------------------------------------
Score reward: +43.35
Hit reward: +0.8207
Loss penalty: -21.00

ACTION DISTRIBUTION
------------------------------------------------------------
N/A

HYPERPARAMETERS
------------------------------------------------------------
timestamp: 20251129_154045
experiment_name: featuretest_1
continued_from_episode: 0
environment: {'width': 160, 'height': 192, 'max_score': 21, 'cpu_difficulty': 'medium'}
agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
training: {'max_episodes': 1000, 'batch_size': 5, 'running_reward_decay': 0.99, 'print_frequency': 100}
rewards: {'ball_hit': 0.02, 'score': 20.0, 'opponent_score': -1.0, 'win': 5000.0, 'loss': -0.0}
training_results: {'final_running_average': 33.450825574843336, 'best_episode_reward': 119.85999999999994, 'total_episodes_trained': 1000, 'total_episodes_cumulative': 1000}
evaluation_results: {'mean_reward': 47.87799999999999, 'std_reward': 32.50914019164457, 'win_rate': 0.0, 'eval_episodes': 10}
heatmap_data: {'recording_enabled': True, 'heatmap_file': 'featuretest_1_20251129_154045_heatmap.json', 'epochs_collected': 5}
collision_data: {'recording_enabled': True, 'epochs_collected': 5, 'total_collisions': 11274}

============================================================

✓ Generating analytics visualizations...

✓ Generating plots...
Warning: Skipping action distribution plot. No action data was logged during training/evaluation.
✓ All plots saved to outputs\featuretest_1_20251129_154045\recorded_data/ with prefix 20251129_154045

✓ Saving heatmap data to outputs\featuretest_1_20251129_154045\recorded_data\heatmaps\featuretest_1_20251129_154045_heatmap.json...
✓ Exported heatmap data to outputs\featuretest_1_20251129_154045\recorded_data\heatmaps\featuretest_1_20251129_154045_heatmap.json

✓ Exporting heatmaps as PNG images to outputs\featuretest_1_20251129_154045\recorded_data\heatmaps\heatmap_images/
  ✓ Saved: epoch_0_ball_position.png
  ✓ Saved: epoch_0_player_scores.png
  ✓ Saved: epoch_0_cpu_scores.png
  ✓ Saved: epoch_0_player_paddle.png
  ✓ Saved: epoch_0_cpu_paddle.png
  ✓ Saved: epoch_0_action_stay.png
  ✓ Saved: epoch_0_action_up.png
  ✓ Saved: epoch_0_action_down.png
  ✓ Saved: epoch_1_ball_position.png
  ✓ Saved: epoch_1_player_scores.png
  ✓ Saved: epoch_1_cpu_scores.png
  ✓ Saved: epoch_1_player_paddle.png
  ✓ Saved: epoch_1_cpu_paddle.png
  ✓ Saved: epoch_1_action_stay.png
  ✓ Saved: epoch_1_action_up.png
  ✓ Saved: epoch_1_action_down.png
  ✓ Saved: epoch_2_ball_position.png
  ✓ Saved: epoch_2_player_scores.png
  ✓ Saved: epoch_2_cpu_scores.png
  ✓ Saved: epoch_2_player_paddle.png
  ✓ Saved: epoch_2_cpu_paddle.png
  ✓ Saved: epoch_2_action_stay.png
  ✓ Saved: epoch_2_action_up.png
  ✓ Saved: epoch_2_action_down.png
  ✓ Saved: epoch_3_ball_position.png
  ✓ Saved: epoch_3_player_scores.png
  ✓ Saved: epoch_3_cpu_scores.png
  ✓ Saved: epoch_3_player_paddle.png
  ✓ Saved: epoch_3_cpu_paddle.png
  ✓ Saved: epoch_3_action_stay.png
  ✓ Saved: epoch_3_action_up.png
  ✓ Saved: epoch_3_action_down.png
  ✓ Saved: epoch_4_ball_position.png
  ✓ Saved: epoch_4_player_scores.png
  ✓ Saved: epoch_4_cpu_scores.png
  ✓ Saved: epoch_4_player_paddle.png
  ✓ Saved: epoch_4_cpu_paddle.png
  ✓ Saved: epoch_4_action_stay.png
  ✓ Saved: epoch_4_action_up.png
  ✓ Saved: epoch_4_action_down.png
  ✓ Saved: temporal_progression.png (4×5 grid)

✓ Heatmap PNG export complete!
  Total images: 5 epochs × 8 types
  Location: outputs\featuretest_1_20251129_154045\recorded_data\heatmaps\heatmap_images/

============================================================
HEATMAP DATA SUMMARY
============================================================
Total Epochs: 5
Total Episodes Recorded: 1000
Total Frames Recorded: 3,801,201
Grid Resolution: 20×24
Court Size: 160×192

Performance Progression (across epochs):
Epoch    Episodes     Player Wins     CPU Wins        Win %       
------------------------------------------------------------
0        200          0               0                      0.0%
1        200          0               0                      0.0%
2        200          0               0                      0.0%
3        200          0               0                      0.0%
4        200          0               0                      0.0%
============================================================

✓ Saving collision analysis to outputs\featuretest_1_20251129_154045\recorded_data\collision_analysis...
======================================================================
PADDLE COLLISION ANALYSIS REPORT
======================================================================

SUMMARY STATISTICS
----------------------------------------------------------------------
Total Epochs Analyzed: 5
Total Collisions Recorded: 11274

EDGE HIT PROGRESSION
----------------------------------------------------------------------
Initial Edge Hit Rate: 60.1%
Final Edge Hit Rate: 57.0%
Improvement: +-3.1 percentage points

BOUNCE ANGLE PROGRESSION
----------------------------------------------------------------------
Initial Average Angle: 44.6°
Final Average Angle: 42.0°
Improvement: +-2.5°

INTERPRETATION
----------------------------------------------------------------------
Edge hits increased from 60.1% to 57.0%, demonstrating the agent
learned to exploit the progressive angle system. Higher edge hit rates
produce steeper bounce angles, making returns harder to defend.

Average bounce angle increased from 44.6° to
42.0°, confirming strategic use of steep
trajectories for offensive advantage.

======================================================================

✓ Report saved to outputs\featuretest_1_20251129_154045\recorded_data\collision_analysis\collision_report.txt

======================================================================
INITIALIZING TRAINING COMPONENTS
======================================================================

✓ Creating environment...
  Court: 160×192
  Paddle: 2×12
  CPU Difficulty: medium

✓ Creating agent (PolicyGradient)...
  Input Size: 16
  Hidden Size: 128
  Output Size: 3
  Learning Rate: 0.0015
  Discount Factor: 0.99

✓ Creating trainer (PolicyGradient)...
  Max Episodes: 200
  Batch Size: 5
  Running Reward Decay: 0.99

✓ Creating heatmap recorder...
  Grid Resolution: 20×24
  Court Size: 160×192

✓ Creating training orchestrator...
  Experiment: featuretest_1
  Orchestrator will handle:
    - Training pipeline
    - Analytics logging
    - Heatmap recording
    - Model evaluation
    - Automatic saving
✓ Analytics initialized
  Timestamp: 20251129_161827
  Output dir: outputs\featuretest_1_20251129_161827\recorded_data
  All files saved as: 20251129_161827*

✓ Found existing training data: outputs\featuretest_1_20251129_161827\recorded_data\20251129_161827.csv
  Continuing from previous run...

======================================================================
STARTING TRAINING
======================================================================

======================================================================
TRAINING ORCHESTRATOR - UNIFIED PIPELINE
======================================================================
Experiment: featuretest_1
Timestamp: 20251129_161827
Output Root Directory: outputs\featuretest_1_20251129_161827/
Output Sub-Directories:
  - Models: outputs\featuretest_1_20251129_161827\saved_models/
  - Analytics: outputs\featuretest_1_20251129_161827\recorded_data/
  - Collision Analysis: outputs\featuretest_1_20251129_161827\recorded_data\collision_analysis/
Heatmap Recording: ✗ DISABLED
Collision Analysis: ✓ ENABLED

✓ Starting trainer...

============================================================
TRAINING PONG AGENT
============================================================
Agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
Learning Rate: 0.0015
Discount Factor: 0.99
Max Episodes: 200
RMSprop Decay: 0.99
Running Reward Decay: 0.99
Reward Structure: Score=20.0, Hit=0.02, Loss=-1.0
Win Reward: 5000.0, Loss Penalty: -0.0
Heatmap Recording: DISABLED
Collision Analysis: ENABLED
Episodes per collision epoch: 200
============================================================

Episode  100 | Reward:  -20.22 | Running Avg:   -4.68 | Best:   39.80 | Length: 3615
  ✓ Collision epoch 0 saved
Episode  200 | Reward:   -0.28 | Running Avg:    6.87 | Best:   79.90 | Length: 3507

============================================================
TRAINING COMPLETE
Final Running Average: 6.87
Best Episode Reward: 79.90
Total collision epochs: 1
============================================================


✓ Logging training data to analytics...

✓ Evaluating...

============================================================
EVALUATING TRAINED AGENT (10 episodes)
============================================================

Eval Episode  1: Reward=  19.80, Player= 2, CPU=21, Length=3801
Eval Episode  2: Reward= -20.14, Player= 0, CPU=21, Length=3817
Eval Episode  3: Reward=  19.90, Player= 2, CPU=21, Length=4035
Eval Episode  4: Reward=  -0.00, Player= 1, CPU=21, Length=4424
Eval Episode  5: Reward=  -0.04, Player= 1, CPU=21, Length=4180
Eval Episode  6: Reward= -20.18, Player= 0, CPU=21, Length=3754
Eval Episode  7: Reward=  19.86, Player= 2, CPU=21, Length=3929
Eval Episode  8: Reward=  -0.02, Player= 1, CPU=21, Length=4161
Eval Episode  9: Reward= -20.06, Player= 0, CPU=21, Length=4103
Eval Episode 10: Reward=  19.98, Player= 2, CPU=21, Length=4430

============================================================
Mean Reward: 1.91 ± 16.61
Reward Range: [-20.18, 19.98]
Win Rate: 0.0%
Mean Episode Length: 4063 steps
============================================================


✓ Logging evaluation data to analytics...

✓ Saving current model to models\featuretest_1.npz...
✓ Agent parameters saved to 'models\featuretest_1.npz'
✓ Saving timestamped backup to outputs\featuretest_1_20251129_161827\saved_models\featuretest_1_20251129_161827.npz...
✓ Agent parameters saved to 'outputs\featuretest_1_20251129_161827\saved_models\featuretest_1_20251129_161827.npz'

✓ Saving configuration to outputs\featuretest_1_20251129_161827\saved_models\featuretest_1_20251129_161827_config.json...

✓ Saving analytics summary...

✓ Summary saved to outputs\featuretest_1_20251129_161827\recorded_data\20251129_161827_summary.txt
============================================================
TRAINING SUMMARY
============================================================
Timestamp: 20251129_161827

TRAINING RESULTS
------------------------------------------------------------
Total episodes trained: 200
Final running average reward: 20.06
Best episode reward: 79.90
Worst episode reward: -20.60
Mean episode reward: 1.49
Std episode reward: 21.34

EVALUATION METRICS
------------------------------------------------------------
Win rate: 0.0%
Total wins: 0 / 200
Mean episode length: 3333 steps
Mean player score: 1.1
Mean CPU score: 21.0

REWARD COMPONENTS (Average)
------------------------------------------------------------
Score reward: +33.80
Hit reward: +0.6905
Loss penalty: -21.00

ACTION DISTRIBUTION
------------------------------------------------------------
N/A

HYPERPARAMETERS
------------------------------------------------------------
timestamp: 20251129_161827
experiment_name: featuretest_1
continued_from_episode: 0
environment: {'width': 160, 'height': 192, 'max_score': 21, 'cpu_difficulty': 'medium'}
agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
training: {'max_episodes': 200, 'batch_size': 5, 'running_reward_decay': 0.99, 'print_frequency': 100}
rewards: {'ball_hit': 0.02, 'score': 20.0, 'opponent_score': -1.0, 'win': 5000.0, 'loss': -0.0}
training_results: {'final_running_average': 6.865731864488114, 'best_episode_reward': 79.90000000000005, 'total_episodes_trained': 200, 'total_episodes_cumulative': 200}
evaluation_results: {'mean_reward': 1.9099999999999866, 'std_reward': 16.61459177951718, 'win_rate': 0.0, 'eval_episodes': 10}
heatmap_data: {'recording_enabled': False, 'heatmap_file': None, 'epochs_collected': 0}
collision_data: {'recording_enabled': True, 'epochs_collected': 1, 'total_collisions': 1523}

============================================================

✓ Generating analytics visualizations...

✓ Generating plots...
Warning: Skipping action distribution plot. No action data was logged during training/evaluation.
✓ All plots saved to outputs\featuretest_1_20251129_161827\recorded_data/ with prefix 20251129_161827

✓ Saving collision analysis to outputs\featuretest_1_20251129_161827\recorded_data\collision_analysis...
======================================================================
PADDLE COLLISION ANALYSIS REPORT
======================================================================

SUMMARY STATISTICS
----------------------------------------------------------------------
Total Epochs Analyzed: 1
Total Collisions Recorded: 1523

EDGE HIT PROGRESSION
----------------------------------------------------------------------
Initial Edge Hit Rate: 60.9%
Final Edge Hit Rate: 60.9%
Improvement: +0.0 percentage points

BOUNCE ANGLE PROGRESSION
----------------------------------------------------------------------
Initial Average Angle: 44.6°
Final Average Angle: 44.6°
Improvement: +0.0°

INTERPRETATION
----------------------------------------------------------------------
Edge hits increased from 60.9% to 60.9%, demonstrating the agent
learned to exploit the progressive angle system. Higher edge hit rates
produce steeper bounce angles, making returns harder to defend.

Average bounce angle increased from 44.6° to
44.6°, confirming strategic use of steep
trajectories for offensive advantage.

======================================================================

✓ Report saved to outputs\featuretest_1_20251129_161827\recorded_data\collision_analysis\collision_report.txt
✓ Detailed statistics saved to outputs\featuretest_1_20251129_161827\recorded_data\collision_analysis\collision_statistics.json

✓ Generating collision analysis figures...
⚠ Not enough epochs for collision distribution plot

======================================================================
INITIALIZING TRAINING COMPONENTS
======================================================================

✓ Creating environment...
  Court: 160×192
  Paddle: 2×12
  CPU Difficulty: medium

✓ Creating agent (PolicyGradient)...
  Input Size: 16
  Hidden Size: 128
  Output Size: 3
  Learning Rate: 0.0015
  Discount Factor: 0.99

✓ Creating trainer (PolicyGradient)...
  Max Episodes: 200
  Batch Size: 5
  Running Reward Decay: 0.99

✓ Creating heatmap recorder...
  Grid Resolution: 20×24
  Court Size: 160×192

✓ Creating training orchestrator...
  Experiment: featuretest_1
  Orchestrator will handle:
    - Training pipeline
    - Analytics logging
    - Heatmap recording
    - Model evaluation
    - Automatic saving
✓ Analytics initialized
  Timestamp: 20251129_162747
  Output dir: outputs\featuretest_1_20251129_162747\recorded_data
  All files saved as: 20251129_162747*

✓ Found existing training data: outputs\featuretest_1_20251129_162747\recorded_data\20251129_162747.csv
  Continuing from previous run...

======================================================================
STARTING TRAINING
======================================================================

======================================================================
TRAINING ORCHESTRATOR - UNIFIED PIPELINE
======================================================================
Experiment: featuretest_1
Timestamp: 20251129_162747
Output Root Directory: outputs\featuretest_1_20251129_162747/
Output Sub-Directories:
  - Models: outputs\featuretest_1_20251129_162747\saved_models/
  - Analytics: outputs\featuretest_1_20251129_162747\recorded_data/
  - Collision Analysis: outputs\featuretest_1_20251129_162747\recorded_data\collision_analysis/
Heatmap Recording: ✗ DISABLED
Collision Analysis: ✓ ENABLED

✓ Starting trainer...

============================================================
TRAINING PONG AGENT
============================================================
Agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
Learning Rate: 0.0015
Discount Factor: 0.99
Max Episodes: 200
RMSprop Decay: 0.99
Running Reward Decay: 0.99
Reward Structure: Score=20.0, Hit=0.02, Loss=-1.0
Win Reward: 5000.0, Loss Penalty: -0.0
Heatmap Recording: DISABLED
Collision Analysis: ENABLED
Episodes per collision epoch: 200
============================================================

Episode  100 | Reward:   19.78 | Running Avg:  -14.48 | Best:   59.42 | Length: 3556
  ✓ Collision epoch 0 saved
Episode  200 | Reward:  -20.30 | Running Avg:   -2.17 | Best:  119.44 | Length: 3392

============================================================
TRAINING COMPLETE
Final Running Average: -2.17
Best Episode Reward: 119.44
Total collision epochs: 1
============================================================


✓ Logging training data to analytics...

✓ Evaluating...

============================================================
EVALUATING TRAINED AGENT (10 episodes)
============================================================

Eval Episode  1: Reward= -20.26, Player= 0, CPU=21, Length=3501
Eval Episode  2: Reward=  -0.18, Player= 1, CPU=21, Length=3732
Eval Episode  3: Reward=  19.58, Player= 2, CPU=21, Length=2964
Eval Episode  4: Reward= -20.20, Player= 0, CPU=21, Length=3745
Eval Episode  5: Reward=  -0.38, Player= 1, CPU=21, Length=3183
Eval Episode  6: Reward=  -0.24, Player= 1, CPU=21, Length=3577
Eval Episode  7: Reward=  -0.24, Player= 1, CPU=21, Length=3602
Eval Episode  8: Reward= -20.28, Player= 0, CPU=21, Length=3431
Eval Episode  9: Reward=  -0.20, Player= 1, CPU=21, Length=3571
Eval Episode 10: Reward= -20.30, Player= 0, CPU=21, Length=3240

============================================================
Mean Reward: -6.27 ± 12.78
Reward Range: [-20.30, 19.58]
Win Rate: 0.0%
Mean Episode Length: 3455 steps
============================================================


✓ Logging evaluation data to analytics...

✓ Saving current model to models\featuretest_1.npz...
✓ Agent parameters saved to 'models\featuretest_1.npz'
✓ Saving timestamped backup to outputs\featuretest_1_20251129_162747\saved_models\featuretest_1_20251129_162747.npz...
✓ Agent parameters saved to 'outputs\featuretest_1_20251129_162747\saved_models\featuretest_1_20251129_162747.npz'

✓ Saving configuration to outputs\featuretest_1_20251129_162747\saved_models\featuretest_1_20251129_162747_config.json...

✓ Saving analytics summary...

✓ Summary saved to outputs\featuretest_1_20251129_162747\recorded_data\20251129_162747_summary.txt
============================================================
TRAINING SUMMARY
============================================================
Timestamp: 20251129_162747

TRAINING RESULTS
------------------------------------------------------------
Total episodes trained: 200
Final running average reward: 6.65
Best episode reward: 119.44
Worst episode reward: -20.60
Mean episode reward: -3.78
Std episode reward: 22.31

EVALUATION METRICS
------------------------------------------------------------
Win rate: 0.0%
Total wins: 0 / 200
Mean episode length: 3110 steps
Mean player score: 0.8
Mean CPU score: 21.0

REWARD COMPONENTS (Average)
------------------------------------------------------------
Score reward: +34.23
Hit reward: +0.6202
Loss penalty: -21.00

ACTION DISTRIBUTION
------------------------------------------------------------
N/A

HYPERPARAMETERS
------------------------------------------------------------
timestamp: 20251129_162747
experiment_name: featuretest_1
continued_from_episode: 0
environment: {'width': 160, 'height': 192, 'max_score': 21, 'cpu_difficulty': 'medium'}
agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
training: {'max_episodes': 200, 'batch_size': 5, 'running_reward_decay': 0.99, 'print_frequency': 100}
rewards: {'ball_hit': 0.02, 'score': 20.0, 'opponent_score': -1.0, 'win': 5000.0, 'loss': -0.0}
training_results: {'final_running_average': -2.171042742982965, 'best_episode_reward': 119.43999999999997, 'total_episodes_trained': 200, 'total_episodes_cumulative': 200}
evaluation_results: {'mean_reward': -6.270000000000011, 'std_reward': 12.776757804701473, 'win_rate': 0.0, 'eval_episodes': 10}
heatmap_data: {'recording_enabled': False, 'heatmap_file': None, 'epochs_collected': 0}
collision_data: {'recording_enabled': True, 'epochs_collected': 1, 'total_collisions': 1124}

============================================================

✓ Generating analytics visualizations...

✓ Generating plots...
Warning: Skipping action distribution plot. No action data was logged during training/evaluation.
✓ All plots saved to outputs\featuretest_1_20251129_162747\recorded_data/ with prefix 20251129_162747

✓ Saving collision analysis to outputs\featuretest_1_20251129_162747\recorded_data\collision_analysis...
======================================================================
PADDLE COLLISION ANALYSIS REPORT
======================================================================

SUMMARY STATISTICS
----------------------------------------------------------------------
Total Epochs Analyzed: 1
Total Collisions Recorded: 1124

EDGE HIT PROGRESSION
----------------------------------------------------------------------
Initial Edge Hit Rate: 60.8%
Final Edge Hit Rate: 60.8%
Improvement: +0.0 percentage points

BOUNCE ANGLE PROGRESSION
----------------------------------------------------------------------
Initial Average Angle: 45.3°
Final Average Angle: 45.3°
Improvement: +0.0°

INTERPRETATION
----------------------------------------------------------------------
Edge hits increased from 60.8% to 60.8%, demonstrating the agent
learned to exploit the progressive angle system. Higher edge hit rates
produce steeper bounce angles, making returns harder to defend.

Average bounce angle increased from 45.3° to
45.3°, confirming strategic use of steep
trajectories for offensive advantage.

======================================================================

✓ Report saved to outputs\featuretest_1_20251129_162747\recorded_data\collision_analysis\collision_report.txt
✓ Detailed statistics saved to outputs\featuretest_1_20251129_162747\recorded_data\collision_analysis\collision_statistics.json

✓ Generating collision analysis figures...
⚠ Not enough epochs for collision distribution plot

======================================================================
INITIALIZING TRAINING COMPONENTS
======================================================================

✓ Creating environment...
  Court: 160×192
  Paddle: 2×12
  CPU Difficulty: medium

✓ Creating agent (PolicyGradient)...
  Input Size: 16
  Hidden Size: 128
  Output Size: 3
  Learning Rate: 0.0015
  Discount Factor: 0.99

✓ Creating trainer (PolicyGradient)...
  Max Episodes: 10
  Batch Size: 5
  Running Reward Decay: 0.99

✓ Creating heatmap recorder...
  Grid Resolution: 20×24
  Court Size: 160×192

✓ Creating training orchestrator...
  Experiment: featuretest_1
  Orchestrator will handle:
    - Training pipeline
    - Analytics logging
    - Heatmap recording
    - Model evaluation
    - Automatic saving
✓ Analytics initialized
  Timestamp: 20251129_164234
  Output dir: outputs\featuretest_1_20251129_164234\recorded_data
  All files saved as: 20251129_164234*

✓ Found existing training data: outputs\featuretest_1_20251129_164234\recorded_data\20251129_164234.csv
  Continuing from previous run...

======================================================================
STARTING TRAINING
======================================================================

======================================================================
TRAINING ORCHESTRATOR - UNIFIED PIPELINE
======================================================================
Experiment: featuretest_1
Timestamp: 20251129_164234
Output Root Directory: outputs\featuretest_1_20251129_164234/
Output Sub-Directories:
  - Models: outputs\featuretest_1_20251129_164234\saved_models/
  - Analytics: outputs\featuretest_1_20251129_164234\recorded_data/
  - Collision Analysis: outputs\featuretest_1_20251129_164234\recorded_data\collision_analysis/
Heatmap Recording: ✗ DISABLED
Collision Analysis: ✓ ENABLED

✓ Starting trainer...

============================================================
TRAINING PONG AGENT
============================================================
Agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
Learning Rate: 0.0015
Discount Factor: 0.99
Max Episodes: 10
RMSprop Decay: 0.99
Running Reward Decay: 0.99
Reward Structure: Score=20.0, Hit=0.02, Loss=-1.0
Win Reward: 5000.0, Loss Penalty: -0.0
Heatmap Recording: DISABLED
Collision Analysis: ENABLED
Episodes per collision epoch: 200
============================================================


============================================================
TRAINING COMPLETE
Final Running Average: -19.72
Best Episode Reward: 19.60
Total collision epochs: 0
============================================================


✓ Logging training data to analytics...

✓ Evaluating...

============================================================
EVALUATING TRAINED AGENT (10 episodes)
============================================================

Eval Episode  1: Reward= -20.60, Player= 0, CPU=21, Length=2354
Eval Episode  2: Reward= -20.50, Player= 0, CPU=21, Length=2689
Eval Episode  3: Reward= -20.50, Player= 0, CPU=21, Length=2613
Eval Episode  4: Reward= -20.52, Player= 0, CPU=21, Length=2607
Eval Episode  5: Reward= -20.54, Player= 0, CPU=21, Length=2542
Eval Episode  6: Reward= -20.50, Player= 0, CPU=21, Length=2595
Eval Episode  7: Reward= -20.52, Player= 0, CPU=21, Length=2633
Eval Episode  8: Reward=  39.60, Player= 3, CPU=21, Length=3025
Eval Episode  9: Reward= -20.56, Player= 0, CPU=21, Length=2474
Eval Episode 10: Reward= -20.58, Player= 0, CPU=21, Length=2408

============================================================
Mean Reward: -14.52 ± 18.04
Reward Range: [-20.60, 39.60]
Win Rate: 0.0%
Mean Episode Length: 2594 steps
============================================================


✓ Logging evaluation data to analytics...

✓ Saving current model to models\featuretest_1.npz...
✓ Agent parameters saved to 'models\featuretest_1.npz'
✓ Saving timestamped backup to outputs\featuretest_1_20251129_164234\saved_models\featuretest_1_20251129_164234.npz...
✓ Agent parameters saved to 'outputs\featuretest_1_20251129_164234\saved_models\featuretest_1_20251129_164234.npz'

✓ Saving configuration to outputs\featuretest_1_20251129_164234\saved_models\featuretest_1_20251129_164234_config.json...

✓ Saving analytics summary...

✓ Summary saved to outputs\featuretest_1_20251129_164234\recorded_data\20251129_164234_summary.txt
============================================================
TRAINING SUMMARY
============================================================
Timestamp: 20251129_164234

TRAINING RESULTS
------------------------------------------------------------
Total episodes trained: 10
Final running average reward: -17.34
Best episode reward: 19.60
Worst episode reward: -20.60
Mean episode reward: -12.49
Std episode reward: 13.31

EVALUATION METRICS
------------------------------------------------------------
Win rate: 0.0%
Total wins: 0 / 10
Mean episode length: 2686 steps
Mean player score: 0.4
Mean CPU score: 21.0

REWARD COMPONENTS (Average)
------------------------------------------------------------
Score reward: +26.67
Hit reward: +0.5060
Loss penalty: -21.00

ACTION DISTRIBUTION
------------------------------------------------------------
N/A

HYPERPARAMETERS
------------------------------------------------------------
timestamp: 20251129_164234
experiment_name: featuretest_1
continued_from_episode: 0
environment: {'width': 160, 'height': 192, 'max_score': 21, 'cpu_difficulty': 'medium'}
agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
training: {'max_episodes': 10, 'batch_size': 5, 'running_reward_decay': 0.99, 'print_frequency': 100}
rewards: {'ball_hit': 0.02, 'score': 20.0, 'opponent_score': -1.0, 'win': 5000.0, 'loss': -0.0}
training_results: {'final_running_average': -19.718570869058656, 'best_episode_reward': 19.59999999999999, 'total_episodes_trained': 10, 'total_episodes_cumulative': 10}
evaluation_results: {'mean_reward': -14.522000000000006, 'std_reward': 18.040697214908306, 'win_rate': 0.0, 'eval_episodes': 10}
heatmap_data: {'recording_enabled': False, 'heatmap_file': None, 'epochs_collected': 0}
collision_data: {'recording_enabled': True, 'epochs_collected': 0, 'total_collisions': 0}

============================================================

✓ Generating analytics visualizations...

✓ Generating plots...
Warning: Skipping action distribution plot. No action data was logged during training/evaluation.
✓ All plots saved to outputs\featuretest_1_20251129_164234\recorded_data/ with prefix 20251129_164234

✓ Saving collision analysis to outputs\featuretest_1_20251129_164234\recorded_data\collision_analysis...

======================================================================
INITIALIZING TRAINING COMPONENTS
======================================================================

✓ Creating environment...
  Court: 160×192
  Paddle: 2×12
  CPU Difficulty: medium

✓ Creating agent (PolicyGradient)...
  Input Size: 16
  Hidden Size: 128
  Output Size: 3
  Learning Rate: 0.0015
  Discount Factor: 0.99

✓ Creating trainer (PolicyGradient)...
  Max Episodes: 200
  Batch Size: 5
  Running Reward Decay: 0.99

✓ Creating heatmap recorder...
  Grid Resolution: 20×24
  Court Size: 160×192

✓ Creating training orchestrator...
  Experiment: featuretest_1
  Orchestrator will handle:
    - Training pipeline
    - Analytics logging
    - Heatmap recording
    - Model evaluation
    - Automatic saving
✓ Analytics initialized
  Timestamp: 20251129_164316
  Output dir: outputs\featuretest_1_20251129_164316\recorded_data
  All files saved as: 20251129_164316*

✓ Found existing training data: outputs\featuretest_1_20251129_164316\recorded_data\20251129_164316.csv
  Continuing from previous run...

======================================================================
STARTING TRAINING
======================================================================

======================================================================
TRAINING ORCHESTRATOR - UNIFIED PIPELINE
======================================================================
Experiment: featuretest_1
Timestamp: 20251129_164316
Output Root Directory: outputs\featuretest_1_20251129_164316/
Output Sub-Directories:
  - Models: outputs\featuretest_1_20251129_164316\saved_models/
  - Analytics: outputs\featuretest_1_20251129_164316\recorded_data/
  - Collision Analysis: outputs\featuretest_1_20251129_164316\recorded_data\collision_analysis/
Heatmap Recording: ✗ DISABLED
Collision Analysis: ✓ ENABLED

✓ Starting trainer...

============================================================
TRAINING PONG AGENT
============================================================
Agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
Learning Rate: 0.0015
Discount Factor: 0.99
Max Episodes: 200
RMSprop Decay: 0.99
Running Reward Decay: 0.99
Reward Structure: Score=20.0, Hit=0.02, Loss=-1.0
Win Reward: 5000.0, Loss Penalty: -0.0
Heatmap Recording: DISABLED
Collision Analysis: ENABLED
Episodes per collision epoch: 200
============================================================

Episode  100 | Reward:  -20.58 | Running Avg:  -20.41 | Best:   -0.36 | Length: 2410
  ✓ Collision epoch 0 saved
Episode  200 | Reward:  -20.60 | Running Avg:  -19.88 | Best:   -0.36 | Length: 2354

============================================================
TRAINING COMPLETE
Final Running Average: -19.88
Best Episode Reward: -0.36
Total collision epochs: 1
============================================================


✓ Logging training data to analytics...

✓ Evaluating...

============================================================
EVALUATING TRAINED AGENT (10 episodes)
============================================================

Eval Episode  1: Reward= -20.58, Player= 0, CPU=21, Length=2416
Eval Episode  2: Reward= -20.60, Player= 0, CPU=21, Length=2346
Eval Episode  3: Reward= -20.60, Player= 0, CPU=21, Length=2344
Eval Episode  4: Reward= -20.60, Player= 0, CPU=21, Length=2352
Eval Episode  5: Reward=  -0.58, Player= 1, CPU=21, Length=2451
Eval Episode  6: Reward= -20.60, Player= 0, CPU=21, Length=2350
Eval Episode  7: Reward= -20.58, Player= 0, CPU=21, Length=2412
Eval Episode  8: Reward= -20.58, Player= 0, CPU=21, Length=2424
Eval Episode  9: Reward= -20.60, Player= 0, CPU=21, Length=2348
Eval Episode 10: Reward= -20.60, Player= 0, CPU=21, Length=2342

============================================================
Mean Reward: -18.59 ± 6.00
Reward Range: [-20.60, -0.58]
Win Rate: 0.0%
Mean Episode Length: 2378 steps
============================================================


✓ Logging evaluation data to analytics...

✓ Saving current model to models\featuretest_1.npz...
✓ Agent parameters saved to 'models\featuretest_1.npz'
✓ Saving timestamped backup to outputs\featuretest_1_20251129_164316\saved_models\featuretest_1_20251129_164316.npz...
✓ Agent parameters saved to 'outputs\featuretest_1_20251129_164316\saved_models\featuretest_1_20251129_164316.npz'

✓ Saving configuration to outputs\featuretest_1_20251129_164316\saved_models\featuretest_1_20251129_164316_config.json...

✓ Saving analytics summary...

✓ Summary saved to outputs\featuretest_1_20251129_164316\recorded_data\20251129_164316_summary.txt
============================================================
TRAINING SUMMARY
============================================================
Timestamp: 20251129_164316

TRAINING RESULTS
------------------------------------------------------------
Total episodes trained: 200
Final running average reward: -19.02
Best episode reward: -0.36
Worst episode reward: -20.60
Mean episode reward: -19.99
Std episode reward: 3.42

EVALUATION METRICS
------------------------------------------------------------
Win rate: 0.0%
Total wins: 0 / 200
Mean episode length: 2397 steps
Mean player score: 0.0
Mean CPU score: 21.0

REWARD COMPONENTS (Average)
------------------------------------------------------------
Score reward: +20.00
Hit reward: +0.4147
Loss penalty: -21.00

ACTION DISTRIBUTION
------------------------------------------------------------
N/A

HYPERPARAMETERS
------------------------------------------------------------
timestamp: 20251129_164316
experiment_name: featuretest_1
continued_from_episode: 0
environment: {'width': 160, 'height': 192, 'max_score': 21, 'cpu_difficulty': 'medium'}
agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
training: {'max_episodes': 200, 'batch_size': 5, 'running_reward_decay': 0.99, 'print_frequency': 100}
rewards: {'ball_hit': 0.02, 'score': 20.0, 'opponent_score': -1.0, 'win': 5000.0, 'loss': -0.0}
training_results: {'final_running_average': -19.877156614657544, 'best_episode_reward': -0.3600000000000083, 'total_episodes_trained': 200, 'total_episodes_cumulative': 200}
evaluation_results: {'mean_reward': -18.592000000000006, 'std_reward': 6.004006662221486, 'win_rate': 0.0, 'eval_episodes': 10}
heatmap_data: {'recording_enabled': False, 'heatmap_file': None, 'epochs_collected': 0}
collision_data: {'recording_enabled': True, 'epochs_collected': 1, 'total_collisions': 32}

============================================================

✓ Generating analytics visualizations...

✓ Generating plots...
Warning: Skipping action distribution plot. No action data was logged during training/evaluation.
✓ All plots saved to outputs\featuretest_1_20251129_164316\recorded_data/ with prefix 20251129_164316

✓ Saving collision analysis to outputs\featuretest_1_20251129_164316\recorded_data\collision_analysis...
======================================================================
PADDLE COLLISION ANALYSIS REPORT
======================================================================

SUMMARY STATISTICS
----------------------------------------------------------------------
Total Epochs Analyzed: 1
Total Collisions Recorded: 32

EDGE HIT PROGRESSION
----------------------------------------------------------------------
Initial Edge Hit Rate: 53.1%
Final Edge Hit Rate: 53.1%
Improvement: +0.0 percentage points

BOUNCE ANGLE PROGRESSION
----------------------------------------------------------------------
Initial Average Angle: 42.1°
Final Average Angle: 42.1°
Improvement: +0.0°

INTERPRETATION
----------------------------------------------------------------------
Edge hits increased from 53.1% to 53.1%, demonstrating the agent
learned to exploit the progressive angle system. Higher edge hit rates
produce steeper bounce angles, making returns harder to defend.

Average bounce angle increased from 42.1° to
42.1°, confirming strategic use of steep
trajectories for offensive advantage.

======================================================================

✓ Report saved to outputs\featuretest_1_20251129_164316\recorded_data\collision_analysis\collision_report.txt

======================================================================
INITIALIZING TRAINING COMPONENTS
======================================================================

✓ Creating environment...
  Court: 160×192
  Paddle: 2×12
  CPU Difficulty: medium

✓ Creating agent (PolicyGradient)...
  Input Size: 16
  Hidden Size: 128
  Output Size: 3
  Learning Rate: 0.0015
  Discount Factor: 0.99

✓ Creating trainer (PolicyGradient)...
  Max Episodes: 200
  Batch Size: 5
  Running Reward Decay: 0.99

✓ Creating heatmap recorder...
  Grid Resolution: 20×24
  Court Size: 160×192

✓ Creating training orchestrator...
  Experiment: featuretest_1
  Orchestrator will handle:
    - Training pipeline
    - Analytics logging
    - Heatmap recording
    - Model evaluation
    - Automatic saving
✓ Analytics initialized
  Timestamp: 20251129_164913
  Output dir: outputs\featuretest_1_20251129_164913\recorded_data
  All files saved as: 20251129_164913*

✓ Found existing training data: outputs\featuretest_1_20251129_164913\recorded_data\20251129_164913.csv
  Continuing from previous run...

======================================================================
STARTING TRAINING
======================================================================

======================================================================
TRAINING ORCHESTRATOR - UNIFIED PIPELINE
======================================================================
Experiment: featuretest_1
Timestamp: 20251129_164913
Output Root Directory: outputs\featuretest_1_20251129_164913/
Output Sub-Directories:
  - Models: outputs\featuretest_1_20251129_164913\saved_models/
  - Analytics: outputs\featuretest_1_20251129_164913\recorded_data/
  - Collision Analysis: outputs\featuretest_1_20251129_164913\recorded_data\collision_analysis/
Heatmap Recording: ✗ DISABLED
Collision Analysis: ✓ ENABLED

✓ Starting trainer...

============================================================
TRAINING PONG AGENT
============================================================
Agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
Learning Rate: 0.0015
Discount Factor: 0.99
Max Episodes: 200
RMSprop Decay: 0.99
Running Reward Decay: 0.99
Reward Structure: Score=20.0, Hit=0.02, Loss=-1.0
Win Reward: 5000.0, Loss Penalty: -0.0
Heatmap Recording: DISABLED
Collision Analysis: ENABLED
Episodes per collision epoch: 200
============================================================

Episode  100 | Reward:  -20.58 | Running Avg:  -20.57 | Best:  -20.36 | Length: 2410
  ✓ Collision epoch 0 saved
Episode  200 | Reward:   -0.46 | Running Avg:  -17.51 | Best:   19.64 | Length: 2844

============================================================
TRAINING COMPLETE
Final Running Average: -17.51
Best Episode Reward: 19.64
Total collision epochs: 1
============================================================


✓ Logging training data to analytics...

✓ Evaluating...

============================================================
EVALUATING TRAINED AGENT (10 episodes)
============================================================

Eval Episode  1: Reward= -20.54, Player= 0, CPU=21, Length=2574
Eval Episode  2: Reward=  -0.40, Player= 1, CPU=21, Length=3052
Eval Episode  3: Reward=  -0.44, Player= 1, CPU=21, Length=2913
Eval Episode  4: Reward=  19.56, Player= 2, CPU=21, Length=2874
Eval Episode  5: Reward= -20.50, Player= 0, CPU=21, Length=2668
Eval Episode  6: Reward= -20.54, Player= 0, CPU=21, Length=2465
Eval Episode  7: Reward=  -0.54, Player= 1, CPU=21, Length=2574
Eval Episode  8: Reward= -20.42, Player= 0, CPU=21, Length=2910
Eval Episode  9: Reward= -20.50, Player= 0, CPU=21, Length=2696
Eval Episode 10: Reward= -20.48, Player= 0, CPU=21, Length=2694

============================================================
Mean Reward: -10.48 ± 13.44
Reward Range: [-20.54, 19.56]
Win Rate: 0.0%
Mean Episode Length: 2742 steps
============================================================


✓ Logging evaluation data to analytics...

✓ Saving current model to models\featuretest_1.npz...
✓ Agent parameters saved to 'models\featuretest_1.npz'
✓ Saving timestamped backup to outputs\featuretest_1_20251129_164913\saved_models\featuretest_1_20251129_164913.npz...
✓ Agent parameters saved to 'outputs\featuretest_1_20251129_164913\saved_models\featuretest_1_20251129_164913.npz'

✓ Saving configuration to outputs\featuretest_1_20251129_164913\saved_models\featuretest_1_20251129_164913_config.json...

✓ Saving analytics summary...

✓ Summary saved to outputs\featuretest_1_20251129_164913\recorded_data\20251129_164913_summary.txt
============================================================
TRAINING SUMMARY
============================================================
Timestamp: 20251129_164913

TRAINING RESULTS
------------------------------------------------------------
Total episodes trained: 200
Final running average reward: -11.46
Best episode reward: 19.64
Worst episode reward: -20.60
Mean episode reward: -18.76
Std episode reward: 6.41

EVALUATION METRICS
------------------------------------------------------------
Win rate: 0.0%
Total wins: 0 / 200
Mean episode length: 2472 steps
Mean player score: 0.1
Mean CPU score: 21.0

REWARD COMPONENTS (Average)
------------------------------------------------------------
Score reward: +22.50
Hit reward: +0.4364
Loss penalty: -21.00

ACTION DISTRIBUTION
------------------------------------------------------------
N/A

HYPERPARAMETERS
------------------------------------------------------------
timestamp: 20251129_164913
experiment_name: featuretest_1
continued_from_episode: 0
environment: {'width': 160, 'height': 192, 'max_score': 21, 'cpu_difficulty': 'medium'}
agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
training: {'max_episodes': 200, 'batch_size': 5, 'running_reward_decay': 0.99, 'print_frequency': 100}
rewards: {'ball_hit': 0.02, 'score': 20.0, 'opponent_score': -1.0, 'win': 5000.0, 'loss': -0.0}
training_results: {'final_running_average': -17.511729395868475, 'best_episode_reward': 19.640000000000004, 'total_episodes_trained': 200, 'total_episodes_cumulative': 200}
evaluation_results: {'mean_reward': -10.480000000000008, 'std_reward': 13.43735390618257, 'win_rate': 0.0, 'eval_episodes': 10}
heatmap_data: {'recording_enabled': False, 'heatmap_file': None, 'epochs_collected': 0}
collision_data: {'recording_enabled': True, 'epochs_collected': 1, 'total_collisions': 142}

============================================================

✓ Generating analytics visualizations...

✓ Generating plots...
Warning: Skipping action distribution plot. No action data was logged during training/evaluation.
✓ All plots saved to outputs\featuretest_1_20251129_164913\recorded_data/ with prefix 20251129_164913

✓ Saving collision analysis to outputs\featuretest_1_20251129_164913\recorded_data\collision_analysis...
======================================================================
PADDLE COLLISION ANALYSIS REPORT
======================================================================

SUMMARY STATISTICS
----------------------------------------------------------------------
Total Epochs Analyzed: 1
Total Collisions Recorded: 142

EDGE HIT PROGRESSION
----------------------------------------------------------------------
Initial Edge Hit Rate: 57.7%
Final Edge Hit Rate: 57.7%
Improvement: +0.0 percentage points

BOUNCE ANGLE PROGRESSION
----------------------------------------------------------------------
Initial Average Angle: 42.9°
Final Average Angle: 42.9°
Improvement: +0.0°

INTERPRETATION
----------------------------------------------------------------------
Edge hits increased from 57.7% to 57.7%, demonstrating the agent
learned to exploit the progressive angle system. Higher edge hit rates
produce steeper bounce angles, making returns harder to defend.

Average bounce angle increased from 42.9° to
42.9°, confirming strategic use of steep
trajectories for offensive advantage.

======================================================================

✓ Report saved to outputs\featuretest_1_20251129_164913\recorded_data\collision_analysis\collision_report.txt

✓ Generating collision analysis figures...
⚠ Not enough epochs for collision distribution plot

======================================================================
INITIALIZING TRAINING COMPONENTS
======================================================================

✓ Creating environment...
  Court: 160×192
  Paddle: 2×12
  CPU Difficulty: medium

✓ Creating agent (PolicyGradient)...
  Input Size: 16
  Hidden Size: 128
  Output Size: 3
  Learning Rate: 0.0015
  Discount Factor: 0.99

✓ Creating trainer (PolicyGradient)...
  Max Episodes: 600
  Batch Size: 5
  Running Reward Decay: 0.99

✓ Creating heatmap recorder...
  Grid Resolution: 20×24
  Court Size: 160×192

✓ Creating training orchestrator...
  Experiment: featuretest_1
  Orchestrator will handle:
    - Training pipeline
    - Analytics logging
    - Heatmap recording
    - Model evaluation
    - Automatic saving
✓ Analytics initialized
  Timestamp: 20251129_170139
  Output dir: outputs\featuretest_1_20251129_170139\recorded_data
  All files saved as: 20251129_170139*

✓ Found existing training data: outputs\featuretest_1_20251129_170139\recorded_data\20251129_170139.csv
  Continuing from previous run...

======================================================================
STARTING TRAINING
======================================================================

======================================================================
TRAINING ORCHESTRATOR - UNIFIED PIPELINE
======================================================================
Experiment: featuretest_1
Timestamp: 20251129_170139
Output Root Directory: outputs\featuretest_1_20251129_170139/
Output Sub-Directories:
  - Models: outputs\featuretest_1_20251129_170139\saved_models/
  - Analytics: outputs\featuretest_1_20251129_170139\recorded_data/
  - Collision Analysis: outputs\featuretest_1_20251129_170139\recorded_data\collision_analysis/
Heatmap Recording: ✗ DISABLED
Collision Analysis: ✓ ENABLED

✓ Starting trainer...

============================================================
TRAINING PONG AGENT
============================================================
Agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
Learning Rate: 0.0015
Discount Factor: 0.99
Max Episodes: 600
RMSprop Decay: 0.99
Running Reward Decay: 0.99
Reward Structure: Score=20.0, Hit=0.02, Loss=-1.0
Win Reward: 5000.0, Loss Penalty: -0.0
Heatmap Recording: DISABLED
Collision Analysis: ENABLED
Episodes per collision epoch: 200
============================================================

Episode  100 | Reward:  -20.48 | Running Avg:  -17.08 | Best:   19.68 | Length: 2797
  ✓ Collision epoch 0 saved
Episode  200 | Reward:  -20.26 | Running Avg:  -10.64 | Best:   39.70 | Length: 3428
Episode  300 | Reward:   19.70 | Running Avg:   -1.15 | Best:   59.82 | Length: 3391
  ✓ Collision epoch 1 saved
Episode  400 | Reward:   19.90 | Running Avg:   10.16 | Best:  119.62 | Length: 3916
Episode  500 | Reward:   -0.04 | Running Avg:   16.09 | Best:  119.62 | Length: 4299
  ✓ Collision epoch 2 saved
Episode  600 | Reward:   39.92 | Running Avg:   23.58 | Best:  119.62 | Length: 3976

============================================================
TRAINING COMPLETE
Final Running Average: 23.58
Best Episode Reward: 119.62
Total collision epochs: 3
============================================================


✓ Logging training data to analytics...

✓ Evaluating...

============================================================
EVALUATING TRAINED AGENT (10 episodes)
============================================================

Eval Episode  1: Reward=  -0.10, Player= 1, CPU=21, Length=3985
Eval Episode  2: Reward=  60.10, Player= 4, CPU=21, Length=4730
Eval Episode  3: Reward= -20.02, Player= 0, CPU=21, Length=4276
Eval Episode  4: Reward=  -0.02, Player= 1, CPU=21, Length=4214
Eval Episode  5: Reward=  19.90, Player= 2, CPU=21, Length=3967
Eval Episode  6: Reward=  39.96, Player= 3, CPU=21, Length=4282
Eval Episode  7: Reward=  40.14, Player= 3, CPU=21, Length=4696
Eval Episode  8: Reward=  79.86, Player= 5, CPU=21, Length=3858
Eval Episode  9: Reward= -19.94, Player= 0, CPU=21, Length=4545
Eval Episode 10: Reward=  39.90, Player= 3, CPU=21, Length=4110

============================================================
Mean Reward: 23.98 ± 31.99
Reward Range: [-20.02, 79.86]
Win Rate: 0.0%
Mean Episode Length: 4266 steps
============================================================


✓ Logging evaluation data to analytics...

✓ Saving current model to models\featuretest_1.npz...
✓ Agent parameters saved to 'models\featuretest_1.npz'
✓ Saving timestamped backup to outputs\featuretest_1_20251129_170139\saved_models\featuretest_1_20251129_170139.npz...
✓ Agent parameters saved to 'outputs\featuretest_1_20251129_170139\saved_models\featuretest_1_20251129_170139.npz'

✓ Saving configuration to outputs\featuretest_1_20251129_170139\saved_models\featuretest_1_20251129_170139_config.json...

✓ Saving analytics summary...

✓ Summary saved to outputs\featuretest_1_20251129_170139\recorded_data\20251129_170139_summary.txt
============================================================
TRAINING SUMMARY
============================================================
Timestamp: 20251129_170139

TRAINING RESULTS
------------------------------------------------------------
Total episodes trained: 600
Final running average reward: 31.42
Best episode reward: 119.62
Worst episode reward: -20.60
Mean episode reward: 6.76
Std episode reward: 26.29

EVALUATION METRICS
------------------------------------------------------------
Win rate: 0.0%
Total wins: 0 / 600
Mean episode length: 3532 steps
Mean player score: 1.4
Mean CPU score: 21.0

REWARD COMPONENTS (Average)
------------------------------------------------------------
Score reward: +39.80
Hit reward: +0.7554
Loss penalty: -21.00

ACTION DISTRIBUTION
------------------------------------------------------------
N/A

HYPERPARAMETERS
------------------------------------------------------------
timestamp: 20251129_170139
experiment_name: featuretest_1
continued_from_episode: 0
environment: {'width': 160, 'height': 192, 'max_score': 21, 'cpu_difficulty': 'medium'}
agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
training: {'max_episodes': 600, 'batch_size': 5, 'running_reward_decay': 0.99, 'print_frequency': 100}
rewards: {'ball_hit': 0.02, 'score': 20.0, 'opponent_score': -1.0, 'win': 5000.0, 'loss': -0.0}
training_results: {'final_running_average': 23.57852415037356, 'best_episode_reward': 119.62000000000002, 'total_episodes_trained': 600, 'total_episodes_cumulative': 600}
evaluation_results: {'mean_reward': 23.978000000000044, 'std_reward': 31.991624466413125, 'win_rate': 0.0, 'eval_episodes': 10}
heatmap_data: {'recording_enabled': False, 'heatmap_file': None, 'epochs_collected': 0}
collision_data: {'recording_enabled': True, 'epochs_collected': 3, 'total_collisions': 5756}

============================================================

✓ Generating analytics visualizations...

✓ Generating plots...
Warning: Skipping action distribution plot. No action data was logged during training/evaluation.
✓ All plots saved to outputs\featuretest_1_20251129_170139\recorded_data/ with prefix 20251129_170139

✓ Saving collision analysis to outputs\featuretest_1_20251129_170139\recorded_data\collision_analysis...
======================================================================
PADDLE COLLISION ANALYSIS REPORT
======================================================================

SUMMARY STATISTICS
----------------------------------------------------------------------
Total Epochs Analyzed: 3
Total Collisions Recorded: 5756

EDGE HIT PROGRESSION
----------------------------------------------------------------------
Initial Edge Hit Rate: 60.7%
Final Edge Hit Rate: 57.1%
Improvement: +-3.6 percentage points

BOUNCE ANGLE PROGRESSION
----------------------------------------------------------------------
Initial Average Angle: 44.9°
Final Average Angle: 42.3°
Improvement: +-2.6°

INTERPRETATION
----------------------------------------------------------------------
Edge hits increased from 60.7% to 57.1%, demonstrating the agent
learned to exploit the progressive angle system. Higher edge hit rates
produce steeper bounce angles, making returns harder to defend.

Average bounce angle increased from 44.9° to
42.3°, confirming strategic use of steep
trajectories for offensive advantage.

======================================================================

✓ Report saved to outputs\featuretest_1_20251129_170139\recorded_data\collision_analysis\collision_report.txt

✓ Generating collision analysis figures...
  ✓ Figure 1 saved: figure_1_collision_distribution.png
  ✓ Figure 2 saved: figure_2_angle_progression.png
  ✓ Figure 3 saved: figure_3_edge_hit_progression.png
✓ All figures saved to outputs\featuretest_1_20251129_170139\recorded_data\collision_analysis/

======================================================================
INITIALIZING TRAINING COMPONENTS
======================================================================

✓ Creating environment...
  Court: 160×192
  Paddle: 2×12
  CPU Difficulty: medium

✓ Creating agent (PolicyGradient)...
  Input Size: 16
  Hidden Size: 128
  Output Size: 3
  Learning Rate: 0.0015
  Discount Factor: 0.99

✓ Creating trainer (PolicyGradient)...
  Max Episodes: 600
  Batch Size: 5
  Running Reward Decay: 0.99

✓ Creating heatmap recorder...
  Grid Resolution: 20×24
  Court Size: 160×192

✓ Creating training orchestrator...
  Experiment: featuretest_1
  Orchestrator will handle:
    - Training pipeline
    - Analytics logging
    - Heatmap recording
    - Model evaluation
    - Automatic saving
✓ Analytics initialized
  Timestamp: 20251129_173228
  Output dir: outputs\featuretest_1_20251129_173228\recorded_data
  All files saved as: 20251129_173228*

✓ Found existing training data: outputs\featuretest_1_20251129_173228\recorded_data\20251129_173228.csv
  Continuing from previous run...

======================================================================
STARTING TRAINING
======================================================================

======================================================================
TRAINING ORCHESTRATOR - UNIFIED PIPELINE
======================================================================
Experiment: featuretest_1
Timestamp: 20251129_173228
Output Root Directory: outputs\featuretest_1_20251129_173228/
Output Sub-Directories:
  - Models: outputs\featuretest_1_20251129_173228\saved_models/
  - Analytics: outputs\featuretest_1_20251129_173228\recorded_data/
  - Collision Analysis: outputs\featuretest_1_20251129_173228\recorded_data\collision_analysis/
Heatmap Recording: ✗ DISABLED
Collision Analysis: ✓ ENABLED

✓ Starting trainer...

============================================================
TRAINING PONG AGENT
============================================================
Agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
Learning Rate: 0.0015
Discount Factor: 0.99
Max Episodes: 600
RMSprop Decay: 0.99
Running Reward Decay: 0.99
Reward Structure: Score=20.0, Hit=0.02, Loss=-1.0
Win Reward: 5000.0, Loss Penalty: -0.0
Heatmap Recording: DISABLED
Collision Analysis: ENABLED
Episodes per collision epoch: 200
============================================================

Episode  100 | Reward:   -0.34 | Running Avg:  -13.94 | Best:   39.88 | Length: 3259
  ✓ Collision epoch 0 saved
Episode  200 | Reward:  -20.08 | Running Avg:   -3.85 | Best:   59.84 | Length: 4047
Episode  300 | Reward:   19.78 | Running Avg:    6.41 | Best:   99.80 | Length: 3717
  ✓ Collision epoch 1 saved
Episode  400 | Reward:  -19.94 | Running Avg:   12.44 | Best:   99.80 | Length: 4351
Episode  500 | Reward:   39.98 | Running Avg:   19.84 | Best:   99.80 | Length: 4317
  ✓ Collision epoch 2 saved
Episode  600 | Reward:   40.26 | Running Avg:   23.86 | Best:  119.84 | Length: 5098

============================================================
TRAINING COMPLETE
Final Running Average: 23.86
Best Episode Reward: 119.84
Total collision epochs: 3
============================================================


✓ Logging training data to analytics...

✓ Evaluating...

============================================================
EVALUATING TRAINED AGENT (10 episodes)
============================================================

Eval Episode  1: Reward=   0.08, Player= 1, CPU=21, Length=4629
Eval Episode  2: Reward=  -0.12, Player= 1, CPU=21, Length=4002
Eval Episode  3: Reward=  20.10, Player= 2, CPU=21, Length=4611
Eval Episode  4: Reward=  60.06, Player= 4, CPU=21, Length=4599
Eval Episode  5: Reward=  60.00, Player= 4, CPU=21, Length=4461
Eval Episode  6: Reward= -19.94, Player= 0, CPU=21, Length=4486
Eval Episode  7: Reward=  -0.06, Player= 1, CPU=21, Length=4140
Eval Episode  8: Reward=   0.10, Player= 1, CPU=21, Length=4702
Eval Episode  9: Reward=  40.04, Player= 3, CPU=21, Length=4311
Eval Episode 10: Reward=  20.12, Player= 2, CPU=21, Length=4627

============================================================
Mean Reward: 18.04 ± 26.01
Reward Range: [-19.94, 60.06]
Win Rate: 0.0%
Mean Episode Length: 4457 steps
============================================================


✓ Logging evaluation data to analytics...

✓ Saving current model to models\featuretest_1.npz...
✓ Agent parameters saved to 'models\featuretest_1.npz'
✓ Saving timestamped backup to outputs\featuretest_1_20251129_173228\saved_models\featuretest_1_20251129_173228.npz...
✓ Agent parameters saved to 'outputs\featuretest_1_20251129_173228\saved_models\featuretest_1_20251129_173228.npz'

✓ Saving configuration to outputs\featuretest_1_20251129_173228\saved_models\featuretest_1_20251129_173228_config.json...

✓ Saving analytics summary...

✓ Summary saved to outputs\featuretest_1_20251129_173228\recorded_data\20251129_173228_summary.txt
============================================================
TRAINING SUMMARY
============================================================
Timestamp: 20251129_173228

TRAINING RESULTS
------------------------------------------------------------
Total episodes trained: 600
Final running average reward: 30.24
Best episode reward: 119.84
Worst episode reward: -20.60
Mean episode reward: 11.03
Std episode reward: 27.39

EVALUATION METRICS
------------------------------------------------------------
Win rate: 0.0%
Total wins: 0 / 600
Mean episode length: 3878 steps
Mean player score: 1.6
Mean CPU score: 21.0

REWARD COMPONENTS (Average)
------------------------------------------------------------
Score reward: +42.12
Hit reward: +0.8626
Loss penalty: -21.00

ACTION DISTRIBUTION
------------------------------------------------------------
N/A

HYPERPARAMETERS
------------------------------------------------------------
timestamp: 20251129_173228
experiment_name: featuretest_1
continued_from_episode: 0
environment: {'width': 160, 'height': 192, 'max_score': 21, 'cpu_difficulty': 'medium'}
agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
training: {'max_episodes': 600, 'batch_size': 5, 'running_reward_decay': 0.99, 'print_frequency': 100}
rewards: {'ball_hit': 0.02, 'score': 20.0, 'opponent_score': -1.0, 'win': 5000.0, 'loss': -0.0}
training_results: {'final_running_average': 23.8613346048679, 'best_episode_reward': 119.83999999999999, 'total_episodes_trained': 600, 'total_episodes_cumulative': 600}
evaluation_results: {'mean_reward': 18.038000000000007, 'std_reward': 26.006101514836896, 'win_rate': 0.0, 'eval_episodes': 10}
heatmap_data: {'recording_enabled': False, 'heatmap_file': None, 'epochs_collected': 0}
collision_data: {'recording_enabled': True, 'epochs_collected': 3, 'total_collisions': 7407}

============================================================

✓ Generating analytics visualizations...

✓ Generating plots...
Warning: Skipping action distribution plot. No action data was logged during training/evaluation.
✓ All plots saved to outputs\featuretest_1_20251129_173228\recorded_data/ with prefix 20251129_173228

✓ Saving collision analysis to outputs\featuretest_1_20251129_173228\recorded_data\collision_analysis...
======================================================================
PADDLE COLLISION ANALYSIS REPORT
======================================================================

SUMMARY STATISTICS
----------------------------------------------------------------------
Total Epochs Analyzed: 3
Total Collisions Recorded: 7407

EDGE HIT PROGRESSION
----------------------------------------------------------------------
Initial Edge Hit Rate: 58.6%
Final Edge Hit Rate: 56.4%
Improvement: +-2.2 percentage points

BOUNCE ANGLE PROGRESSION
----------------------------------------------------------------------
Initial Average Angle: 42.5°
Final Average Angle: 41.7°
Improvement: +-0.8°

INTERPRETATION
----------------------------------------------------------------------
Edge hits increased from 58.6% to 56.4%, demonstrating the agent
learned to exploit the progressive angle system. Higher edge hit rates
produce steeper bounce angles, making returns harder to defend.

Average bounce angle increased from 42.5° to
41.7°, confirming strategic use of steep
trajectories for offensive advantage.

======================================================================

✓ Report saved to outputs\featuretest_1_20251129_173228\recorded_data\collision_analysis\collision_report.txt

✓ Generating collision analysis figures...
  ✓ Figure 1 saved: figure_1_collision_distribution.png
  ✓ Figure 2 saved: figure_2_angle_progression.png
  ✓ Figure 3 saved: figure_3_edge_hit_progression.png
✓ All figures saved to outputs\featuretest_1_20251129_173228\recorded_data\collision_analysis/
  ✓ Summary CSV: collision_summary.csv
  ✓ Distribution CSV: collision_distribution.csv
  Total CSV files: 2
✓ Collision analysis complete!
  Location: outputs\featuretest_1_20251129_173228\recorded_data\collision_analysis/

======================================================================
TRAINING COMPLETE
Total Training Time: 0:09:55.733345
======================================================================

✓ All results saved to: outputs\featuretest_1_20251129_173228/

  Models (outputs\featuretest_1_20251129_173228\saved_models/):
    - Model: featuretest_1_20251129_173228.npz
    - Config: featuretest_1_20251129_173228_config.json
    - Log: featuretest_1_20251129_173228.log

  Analytics (outputs\featuretest_1_20251129_173228\recorded_data/):
    - Training CSV: 20251129_173228.csv
    - Evaluation CSV: 20251129_173228_eval.csv
    - Summary: 20251129_173228_summary.txt
    - Plots (10): 20251129_173228_0*.png

  Collision Analysis (outputs\featuretest_1_20251129_173228\recorded_data\collision_analysis/):
    - Report: collision_report.txt
    - Statistics: collision_statistics.json
    - Figures: figure_1_collision_distribution.png
    - Figures: figure_2_angle_progression.png
    - Figures: figure_3_edge_hit_progression.png
    - Total Collisions: 7,407
    - Edge Hit Rate: 58.6% → 56.4%
    - Avg Angle: 42.5° → 41.7°
======================================================================


======================================================================
TRAINING COMPLETE
======================================================================

✓ Results saved to: outputs\featuretest_1_20251129_173228/
  - Model: model.npz
  - Config: config_used.json
  - Metrics: training.csv, evaluation.csv
  - Heatmap: heatmap.json
  - Log: training.log

======================================================================
INITIALIZING TRAINING COMPONENTS
======================================================================

✓ Creating environment...
  Court: 160×192
  Paddle: 2×12
  CPU Difficulty: medium

✓ Creating agent (PolicyGradient)...
  Input Size: 16
  Hidden Size: 128
  Output Size: 3
  Learning Rate: 0.0015
  Discount Factor: 0.99

✓ Creating trainer (PolicyGradient)...
  Max Episodes: 20000
  Batch Size: 5
  Running Reward Decay: 0.99

✓ Creating heatmap recorder...
  Grid Resolution: 20×24
  Court Size: 160×192

✓ Creating training orchestrator...
  Experiment: featuretest_1
  Orchestrator will handle:
    - Training pipeline
    - Analytics logging
    - Heatmap recording
    - Model evaluation
    - Automatic saving
✓ Analytics initialized
  Timestamp: 20251130_192802
  Output dir: outputs\featuretest_1_20251130_192802\recorded_data
  All files saved as: 20251130_192802*

✓ Found existing training data: outputs\featuretest_1_20251130_192802\recorded_data\20251130_192802.csv
  Continuing from previous run...

======================================================================
STARTING TRAINING
======================================================================

======================================================================
TRAINING ORCHESTRATOR - UNIFIED PIPELINE
======================================================================
Experiment: featuretest_1
Timestamp: 20251130_192802
Output Root Directory: outputs\featuretest_1_20251130_192802/
Output Sub-Directories:
  - Models: outputs\featuretest_1_20251130_192802\saved_models/
  - Analytics: outputs\featuretest_1_20251130_192802\recorded_data/
  - Collision Analysis: outputs\featuretest_1_20251130_192802\recorded_data\collision_analysis/
Heatmap Recording: ✗ DISABLED
Collision Analysis: ✓ ENABLED

✓ Starting trainer...

============================================================
TRAINING PONG AGENT
============================================================
Agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
Learning Rate: 0.0015
Discount Factor: 0.99
Max Episodes: 20000
RMSprop Decay: 0.99
Running Reward Decay: 0.99
Reward Structure: Score=20.0, Hit=0.02, Loss=-1.0
Win Reward: 5000.0, Loss Penalty: -0.0
Heatmap Recording: DISABLED
Collision Analysis: ENABLED
Episodes per collision epoch: 200
============================================================


======================================================================
INITIALIZING TRAINING COMPONENTS
======================================================================

✓ Creating environment...
  Court: 160×192
  Paddle: 2×12
  CPU Difficulty: medium

✓ Creating agent (PolicyGradient)...
  Input Size: 16
  Hidden Size: 128
  Output Size: 3
  Learning Rate: 0.0015
  Discount Factor: 0.99

✓ Creating trainer (PolicyGradient)...
  Max Episodes: 20000
  Batch Size: 5
  Running Reward Decay: 0.99

✓ Creating heatmap recorder...
  Grid Resolution: 20×24
  Court Size: 160×192

✓ Creating training orchestrator...
  Experiment: exp_03
  Orchestrator will handle:
    - Training pipeline
    - Analytics logging
    - Heatmap recording
    - Model evaluation
    - Automatic saving
✓ Analytics initialized
  Timestamp: 20251130_192852
  Output dir: outputs\exp_03_20251130_192852\recorded_data
  All files saved as: 20251130_192852*

✓ Found existing training data: outputs\exp_03_20251130_192852\recorded_data\20251130_192852.csv
  Continuing from previous run...

======================================================================
STARTING TRAINING
======================================================================

======================================================================
TRAINING ORCHESTRATOR - UNIFIED PIPELINE
======================================================================
Experiment: exp_03
Timestamp: 20251130_192852
Output Root Directory: outputs\exp_03_20251130_192852/
Output Sub-Directories:
  - Models: outputs\exp_03_20251130_192852\saved_models/
  - Analytics: outputs\exp_03_20251130_192852\recorded_data/
  - Collision Analysis: outputs\exp_03_20251130_192852\recorded_data\collision_analysis/
Heatmap Recording: ✗ DISABLED
Collision Analysis: ✓ ENABLED

✓ Starting trainer...

============================================================
TRAINING PONG AGENT
============================================================
Agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
Learning Rate: 0.0015
Discount Factor: 0.99
Max Episodes: 20000
RMSprop Decay: 0.99
Running Reward Decay: 0.99
Reward Structure: Score=20.0, Hit=0.02, Loss=-1.0
Win Reward: 5000.0, Loss Penalty: -0.0
Heatmap Recording: DISABLED
Collision Analysis: ENABLED
Episodes per collision epoch: 200
============================================================

Episode  100 | Reward:   -0.44 | Running Avg:   -9.56 | Best:   19.54 | Length: 2878
  ✓ Collision epoch 0 saved
Episode  200 | Reward:   39.70 | Running Avg:   -5.76 | Best:   39.78 | Length: 3279
Episode  300 | Reward:   19.78 | Running Avg:    2.99 | Best:   59.96 | Length: 3696
  ✓ Collision epoch 1 saved
Episode  400 | Reward:   19.88 | Running Avg:   11.87 | Best:  119.88 | Length: 3920
Episode  500 | Reward:   19.98 | Running Avg:   17.68 | Best:  119.88 | Length: 4487
  ✓ Collision epoch 2 saved
Episode  600 | Reward:   60.06 | Running Avg:   31.12 | Best:  159.84 | Length: 4643
Episode  700 | Reward:    0.02 | Running Avg:   34.45 | Best:  159.84 | Length: 4444
  ✓ Collision epoch 3 saved
Episode  800 | Reward:   19.82 | Running Avg:   34.98 | Best:  159.84 | Length: 3739
Episode  900 | Reward:   79.88 | Running Avg:   55.22 | Best:  160.08 | Length: 3894
  ✓ Collision epoch 4 saved
Episode 1000 | Reward:   79.88 | Running Avg:   66.34 | Best:  160.08 | Length: 3833
Episode 1100 | Reward:   60.12 | Running Avg:   82.56 | Best:  200.02 | Length: 4604
  ✓ Collision epoch 5 saved
Episode 1200 | Reward:   99.96 | Running Avg:   87.83 | Best:  200.02 | Length: 4147
Episode 1300 | Reward:  119.98 | Running Avg:   98.77 | Best:  220.02 | Length: 4225
  ✓ Collision epoch 6 saved
Episode 1400 | Reward:   99.94 | Running Avg:  115.58 | Best:  220.02 | Length: 4099
Episode 1500 | Reward:  119.80 | Running Avg:  118.37 | Best:  239.88 | Length: 3610
  ✓ Collision epoch 7 saved
Episode 1600 | Reward:  139.90 | Running Avg:  122.38 | Best:  239.92 | Length: 3997
Episode 1700 | Reward:  159.92 | Running Avg:  128.38 | Best:  240.04 | Length: 4164
  ✓ Collision epoch 8 saved
Episode 1800 | Reward:   99.94 | Running Avg:  134.37 | Best:  260.00 | Length: 4016
Episode 1900 | Reward:   99.94 | Running Avg:  138.56 | Best:  260.00 | Length: 4238
  ✓ Collision epoch 9 saved
Episode 2000 | Reward:   99.84 | Running Avg:  146.19 | Best:  260.00 | Length: 3763
Episode 2100 | Reward:  159.84 | Running Avg:  158.89 | Best:  260.06 | Length: 3942
  ✓ Collision epoch 10 saved
Episode 2200 | Reward:  199.92 | Running Avg:  168.44 | Best:  299.92 | Length: 4209
Episode 2300 | Reward:  199.82 | Running Avg:  183.51 | Best:  300.04 | Length: 3811
  ✓ Collision epoch 11 saved
Episode 2400 | Reward:  239.96 | Running Avg:  187.60 | Best:  300.04 | Length: 4356
Episode 2500 | Reward:  119.76 | Running Avg:  194.33 | Best:  300.04 | Length: 3598
  ✓ Collision epoch 12 saved
Episode 2600 | Reward:  260.02 | Running Avg:  197.95 | Best:  320.02 | Length: 4388
Episode 2700 | Reward:  240.00 | Running Avg:  204.62 | Best:  320.02 | Length: 4488
  ✓ Collision epoch 13 saved
Episode 2800 | Reward:  240.04 | Running Avg:  209.30 | Best:  320.02 | Length: 4611
Episode 2900 | Reward:  159.94 | Running Avg:  221.28 | Best:  360.02 | Length: 4128
  ✓ Collision epoch 14 saved
Episode 3000 | Reward:  260.04 | Running Avg:  235.38 | Best:  360.02 | Length: 4392
Episode 3100 | Reward:  239.94 | Running Avg:  233.07 | Best:  360.02 | Length: 4210
  ✓ Collision epoch 15 saved
Episode 3200 | Reward:  260.08 | Running Avg:  240.91 | Best:  360.10 | Length: 4659
Episode 3300 | Reward:  259.92 | Running Avg:  246.32 | Best:  360.10 | Length: 4062
  ✓ Collision epoch 16 saved
Episode 3400 | Reward:  179.78 | Running Avg:  249.89 | Best:  360.10 | Length: 3724
Episode 3500 | Reward:  359.98 | Running Avg:  262.76 | Best:  360.10 | Length: 4313
  ✓ Collision epoch 17 saved
Episode 3600 | Reward:  220.06 | Running Avg:  263.46 | Best:  360.10 | Length: 4436
Episode 3700 | Reward:  140.06 | Running Avg:  264.97 | Best:  360.10 | Length: 4471
  ✓ Collision epoch 18 saved
Episode 3800 | Reward:  179.96 | Running Avg:  269.63 | Best:  380.02 | Length: 4301
Episode 3900 | Reward:  259.92 | Running Avg:  265.18 | Best:  380.02 | Length: 4182
  ✓ Collision epoch 19 saved
Episode 4000 | Reward:  139.72 | Running Avg:  268.79 | Best:  380.02 | Length: 3583
Episode 4100 | Reward:  299.88 | Running Avg:  278.40 | Best:  380.10 | Length: 4067
  ✓ Collision epoch 20 saved
Episode 4200 | Reward:  259.88 | Running Avg:  285.63 | Best:  380.10 | Length: 4000
Episode 4300 | Reward:  360.08 | Running Avg:  289.18 | Best:  380.10 | Length: 4514
  ✓ Collision epoch 21 saved
Episode 4400 | Reward:  339.92 | Running Avg:  289.81 | Best:  380.10 | Length: 4283
Episode 4500 | Reward:  320.02 | Running Avg:  289.57 | Best:  380.10 | Length: 4503
  ✓ Collision epoch 22 saved
Episode 4600 | Reward:  359.96 | Running Avg:  286.01 | Best:  380.10 | Length: 4314
Episode 4700 | Reward:  360.08 | Running Avg:  290.33 | Best:  380.10 | Length: 4649
  ✓ Collision epoch 23 saved
Episode 4800 | Reward:  239.88 | Running Avg:  299.04 | Best:  380.10 | Length: 3957
Episode 4900 | Reward:  299.90 | Running Avg:  361.12 | Best: 5401.10 | Length: 4140
  ✓ Collision epoch 24 saved
Episode 5000 | Reward:  319.98 | Running Avg:  325.41 | Best: 5401.10 | Length: 4446
Episode 5100 | Reward:  339.94 | Running Avg:  343.85 | Best: 5401.10 | Length: 4209
  ✓ Collision epoch 25 saved
Episode 5200 | Reward:  280.00 | Running Avg:  324.29 | Best: 5401.10 | Length: 4358
Episode 5300 | Reward:  279.98 | Running Avg:  377.65 | Best: 5401.14 | Length: 4167
  ✓ Collision epoch 26 saved
Episode 5400 | Reward:  219.80 | Running Avg:  372.98 | Best: 5401.14 | Length: 3659
Episode 5500 | Reward:  280.14 | Running Avg:  407.27 | Best: 5401.14 | Length: 4554
  ✓ Collision epoch 27 saved
Episode 5600 | Reward:  300.02 | Running Avg:  350.59 | Best: 5401.14 | Length: 4340
Episode 5700 | Reward:  320.04 | Running Avg:  376.82 | Best: 5401.14 | Length: 4698
  ✓ Collision epoch 28 saved
Episode 5800 | Reward:  320.02 | Running Avg:  336.17 | Best: 5401.14 | Length: 4368
Episode 5900 | Reward:  339.98 | Running Avg:  353.00 | Best: 5401.14 | Length: 4415
  ✓ Collision epoch 29 saved
Episode 6000 | Reward:  320.02 | Running Avg:  372.02 | Best: 5401.14 | Length: 4363
Episode 6100 | Reward:  339.92 | Running Avg:  337.40 | Best: 5401.14 | Length: 4347
  ✓ Collision epoch 30 saved
Episode 6200 | Reward:  299.92 | Running Avg:  360.94 | Best: 5401.14 | Length: 4210
Episode 6300 | Reward:  379.96 | Running Avg:  342.53 | Best: 5401.14 | Length: 4418
  ✓ Collision epoch 31 saved
Episode 6400 | Reward:  259.82 | Running Avg:  438.74 | Best: 5401.14 | Length: 3799
Episode 6500 | Reward:  340.12 | Running Avg:  360.47 | Best: 5401.14 | Length: 4663
  ✓ Collision epoch 32 saved
Episode 6600 | Reward:  340.10 | Running Avg:  365.96 | Best: 5401.14 | Length: 4532
Episode 6700 | Reward:  340.00 | Running Avg:  422.50 | Best: 5401.14 | Length: 4473
  ✓ Collision epoch 33 saved
Episode 6800 | Reward:  319.92 | Running Avg:  358.70 | Best: 5401.14 | Length: 4308
Episode 6900 | Reward:  360.04 | Running Avg:  368.45 | Best: 5401.14 | Length: 4651
  ✓ Collision epoch 34 saved
Episode 7000 | Reward:  279.98 | Running Avg:  345.08 | Best: 5401.14 | Length: 4165
Episode 7100 | Reward:  319.98 | Running Avg:  341.19 | Best: 5401.14 | Length: 4370
  ✓ Collision epoch 35 saved
Episode 7200 | Reward:  380.06 | Running Avg:  339.05 | Best: 5401.14 | Length: 4413
Episode 7300 | Reward:  260.02 | Running Avg:  411.41 | Best: 5401.14 | Length: 4537
  ✓ Collision epoch 36 saved
Episode 7400 | Reward:  279.86 | Running Avg:  406.10 | Best: 5401.14 | Length: 4242
Episode 7500 | Reward:  360.04 | Running Avg:  385.47 | Best: 5401.14 | Length: 4440
  ✓ Collision epoch 37 saved
Episode 7600 | Reward:  360.08 | Running Avg:  556.31 | Best: 5401.14 | Length: 4514
Episode 7700 | Reward:  339.86 | Running Avg:  572.76 | Best: 5401.14 | Length: 4215
  ✓ Collision epoch 38 saved
Episode 7800 | Reward:  359.92 | Running Avg:  471.67 | Best: 5401.14 | Length: 4316
Episode 7900 | Reward:  339.94 | Running Avg:  573.03 | Best: 5401.14 | Length: 4344
  ✓ Collision epoch 39 saved
Episode 8000 | Reward:  339.98 | Running Avg:  482.80 | Best: 5401.14 | Length: 4408
Episode 8100 | Reward:  380.04 | Running Avg:  637.25 | Best: 5401.14 | Length: 4620
  ✓ Collision epoch 40 saved
Episode 8200 | Reward:  339.96 | Running Avg:  564.78 | Best: 5401.14 | Length: 4206
Episode 8300 | Reward:  380.00 | Running Avg:  689.34 | Best: 5401.14 | Length: 4416
  ✓ Collision epoch 41 saved
Episode 8400 | Reward:  359.92 | Running Avg:  619.78 | Best: 5401.14 | Length: 4316
Episode 8500 | Reward:  360.02 | Running Avg:  613.67 | Best: 5401.14 | Length: 4441
  ✓ Collision epoch 42 saved
Episode 8600 | Reward:  339.96 | Running Avg:  633.97 | Best: 5401.14 | Length: 4206
Episode 8700 | Reward:  360.06 | Running Avg:  751.36 | Best: 5401.14 | Length: 4650
  ✓ Collision epoch 43 saved
Episode 8800 | Reward: 5401.00 | Running Avg:  659.06 | Best: 5401.14 | Length: 4545
Episode 8900 | Reward: 5401.00 | Running Avg:  769.90 | Best: 5401.14 | Length: 4545
  ✓ Collision epoch 44 saved
Episode 9000 | Reward: 5401.10 | Running Avg:  729.92 | Best: 5401.14 | Length: 4540
Episode 9100 | Reward: 5401.06 | Running Avg:  991.91 | Best: 5401.14 | Length: 4542
  ✓ Collision epoch 45 saved
Episode 9200 | Reward:  360.02 | Running Avg:  903.35 | Best: 5401.14 | Length: 4652
Episode 9300 | Reward:  340.06 | Running Avg:  822.06 | Best: 5401.14 | Length: 4470
  ✓ Collision epoch 46 saved
Episode 9400 | Reward:  360.04 | Running Avg: 1069.80 | Best: 5401.14 | Length: 4646
Episode 9500 | Reward:  359.90 | Running Avg: 1017.70 | Best: 5401.14 | Length: 4315
  ✓ Collision epoch 47 saved
Episode 9600 | Reward:  360.02 | Running Avg:  864.24 | Best: 5401.14 | Length: 4517
Episode 9700 | Reward:  380.02 | Running Avg:  800.51 | Best: 5401.14 | Length: 4415
  ✓ Collision epoch 48 saved
Episode 9800 | Reward:  360.10 | Running Avg:  918.52 | Best: 5401.16 | Length: 4643
Episode 9900 | Reward:  300.00 | Running Avg:  868.26 | Best: 5401.16 | Length: 4530
  ✓ Collision epoch 49 saved
Episode 10000 | Reward:  380.06 | Running Avg:  709.92 | Best: 5401.16 | Length: 4614
Episode 10100 | Reward: 5401.02 | Running Avg:  802.58 | Best: 5401.16 | Length: 4544
  ✓ Collision epoch 50 saved
Episode 10200 | Reward:  379.96 | Running Avg:  849.95 | Best: 5401.16 | Length: 4418
Episode 10300 | Reward:  380.02 | Running Avg:  759.37 | Best: 5401.16 | Length: 4415
  ✓ Collision epoch 51 saved
Episode 10400 | Reward:  360.08 | Running Avg: 1145.29 | Best: 5401.16 | Length: 4443
Episode 10500 | Reward:  380.10 | Running Avg: 1207.76 | Best: 5401.16 | Length: 4482
  ✓ Collision epoch 52 saved
Episode 10600 | Reward:  380.00 | Running Avg: 1099.29 | Best: 5401.16 | Length: 4485
Episode 10700 | Reward:  319.94 | Running Avg:  805.51 | Best: 5401.16 | Length: 4240
  ✓ Collision epoch 53 saved
Episode 10800 | Reward:  360.00 | Running Avg:  868.16 | Best: 5401.16 | Length: 4447
Episode 10900 | Reward:  340.04 | Running Avg:  730.77 | Best: 5401.16 | Length: 4466
  ✓ Collision epoch 54 saved
Episode 11000 | Reward:  379.98 | Running Avg:  996.91 | Best: 5401.16 | Length: 4417
Episode 11100 | Reward:  339.92 | Running Avg:  711.57 | Best: 5401.16 | Length: 4279
  ✓ Collision epoch 55 saved
Episode 11200 | Reward:  379.98 | Running Avg:  822.99 | Best: 5401.16 | Length: 4417
Episode 11300 | Reward:  319.88 | Running Avg:  833.88 | Best: 5401.16 | Length: 4110
  ✓ Collision epoch 56 saved
Episode 11400 | Reward:  359.94 | Running Avg:  873.85 | Best: 5401.16 | Length: 4521
Episode 11500 | Reward:  299.94 | Running Avg:  879.97 | Best: 5401.16 | Length: 3999
  ✓ Collision epoch 57 saved
Episode 11600 | Reward: 5400.98 | Running Avg:  925.83 | Best: 5401.16 | Length: 4546
Episode 11700 | Reward:  380.00 | Running Avg:  916.99 | Best: 5401.18 | Length: 4416
  ✓ Collision epoch 58 saved
Episode 11800 | Reward:  260.12 | Running Avg:  951.58 | Best: 5401.18 | Length: 4767
Episode 11900 | Reward:  359.88 | Running Avg:  666.63 | Best: 5401.18 | Length: 4389
  ✓ Collision epoch 59 saved
Episode 12000 | Reward:  359.98 | Running Avg:  808.86 | Best: 5401.18 | Length: 4313
Episode 12100 | Reward:  340.06 | Running Avg:  533.34 | Best: 5401.18 | Length: 4544
  ✓ Collision epoch 60 saved
Episode 12200 | Reward:  320.00 | Running Avg:  449.36 | Best: 5401.18 | Length: 4239
Episode 12300 | Reward:  359.98 | Running Avg:  679.09 | Best: 5401.18 | Length: 4313
  ✓ Collision epoch 61 saved
Episode 12400 | Reward:  360.06 | Running Avg:  735.42 | Best: 5401.18 | Length: 4444
Episode 12500 | Reward: 5401.04 | Running Avg: 1116.79 | Best: 5401.18 | Length: 4543
  ✓ Collision epoch 62 saved
Episode 12600 | Reward:  360.00 | Running Avg:  822.52 | Best: 5401.18 | Length: 4447
Episode 12700 | Reward:  299.94 | Running Avg:  814.38 | Best: 5401.18 | Length: 4132
  ✓ Collision epoch 63 saved
Episode 12800 | Reward:  359.94 | Running Avg:  777.05 | Best: 5401.18 | Length: 4315
Episode 12900 | Reward:  380.06 | Running Avg: 1009.18 | Best: 5401.18 | Length: 4619
  ✓ Collision epoch 64 saved
Episode 13000 | Reward:  360.02 | Running Avg:  928.38 | Best: 5401.18 | Length: 4446
Episode 13100 | Reward:  379.98 | Running Avg:  940.70 | Best: 5401.18 | Length: 4417
  ✓ Collision epoch 65 saved
Episode 13200 | Reward:  339.94 | Running Avg: 1320.94 | Best: 5401.18 | Length: 4346
Episode 13300 | Reward:  380.00 | Running Avg: 1318.03 | Best: 5401.18 | Length: 4416
  ✓ Collision epoch 66 saved
Episode 13400 | Reward:  340.00 | Running Avg: 1169.96 | Best: 5401.18 | Length: 4208
Episode 13500 | Reward:  380.04 | Running Avg: 1148.41 | Best: 5401.18 | Length: 4483
  ✓ Collision epoch 67 saved
Episode 13600 | Reward:  319.94 | Running Avg: 1397.40 | Best: 5401.18 | Length: 4242
Episode 13700 | Reward:  380.08 | Running Avg: 1217.56 | Best: 5401.18 | Length: 4481
  ✓ Collision epoch 68 saved
Episode 13800 | Reward:  380.04 | Running Avg: 1095.00 | Best: 5401.18 | Length: 4414
Episode 13900 | Reward:  380.04 | Running Avg: 1336.46 | Best: 5401.18 | Length: 4620
  ✓ Collision epoch 69 saved
Episode 14000 | Reward:  360.08 | Running Avg: 1163.34 | Best: 5401.18 | Length: 4443
Episode 14100 | Reward: 5401.12 | Running Avg: 1102.28 | Best: 5401.18 | Length: 4539
  ✓ Collision epoch 70 saved
Episode 14200 | Reward: 5401.08 | Running Avg: 1274.89 | Best: 5401.18 | Length: 4541
Episode 14300 | Reward:  340.06 | Running Avg: 1175.25 | Best: 5401.18 | Length: 4470
  ✓ Collision epoch 71 saved
Episode 14400 | Reward:  379.98 | Running Avg:  989.24 | Best: 5401.18 | Length: 4417
Episode 14500 | Reward:  379.98 | Running Avg: 1129.90 | Best: 5401.18 | Length: 4417
  ✓ Collision epoch 72 saved
Episode 14600 | Reward:  380.00 | Running Avg:  937.68 | Best: 5401.18 | Length: 4416
Episode 14700 | Reward:  379.98 | Running Avg: 1259.77 | Best: 5401.18 | Length: 4417
  ✓ Collision epoch 73 saved
Episode 14800 | Reward:  340.06 | Running Avg: 1331.06 | Best: 5401.18 | Length: 4666
Episode 14900 | Reward:  360.04 | Running Avg: 1128.48 | Best: 5401.18 | Length: 4514
  ✓ Collision epoch 74 saved
Episode 15000 | Reward:  380.04 | Running Avg:  924.36 | Best: 5401.18 | Length: 4414
Episode 15100 | Reward:  360.00 | Running Avg: 1094.42 | Best: 5401.18 | Length: 4312
  ✓ Collision epoch 75 saved
Episode 15200 | Reward: 5401.06 | Running Avg: 1290.49 | Best: 5401.18 | Length: 4542
Episode 15300 | Reward: 5401.16 | Running Avg: 1151.55 | Best: 5401.18 | Length: 4537
  ✓ Collision epoch 76 saved
Episode 15400 | Reward:  379.92 | Running Avg:  975.73 | Best: 5401.18 | Length: 4491
Episode 15500 | Reward:  380.02 | Running Avg: 1043.13 | Best: 5401.18 | Length: 4415
  ✓ Collision epoch 77 saved
Episode 15600 | Reward:  380.12 | Running Avg:  863.05 | Best: 5401.18 | Length: 4616
Episode 15700 | Reward:  340.04 | Running Avg:  869.74 | Best: 5401.18 | Length: 4403
  ✓ Collision epoch 78 saved
Episode 15800 | Reward:  380.06 | Running Avg: 1374.53 | Best: 5401.18 | Length: 4484
Episode 15900 | Reward:  360.00 | Running Avg: 1290.26 | Best: 5401.18 | Length: 4310
  ✓ Collision epoch 79 saved
Episode 16000 | Reward:  380.00 | Running Avg: 1618.88 | Best: 5401.18 | Length: 4487
Episode 16100 | Reward:  380.00 | Running Avg: 1431.07 | Best: 5401.18 | Length: 4416
  ✓ Collision epoch 80 saved
Episode 16200 | Reward:  360.06 | Running Avg: 1371.12 | Best: 5401.18 | Length: 4645
Episode 16300 | Reward:  319.96 | Running Avg: 1039.32 | Best: 5401.18 | Length: 4511
  ✓ Collision epoch 81 saved
Episode 16400 | Reward:  380.06 | Running Avg: 1253.76 | Best: 5401.18 | Length: 4413
Episode 16500 | Reward: 5400.98 | Running Avg: 1566.31 | Best: 5401.18 | Length: 4546
  ✓ Collision epoch 82 saved
Episode 16600 | Reward: 5401.10 | Running Avg: 1548.12 | Best: 5401.18 | Length: 4540
Episode 16700 | Reward:  380.08 | Running Avg: 1199.02 | Best: 5401.18 | Length: 4481
  ✓ Collision epoch 83 saved
Episode 16800 | Reward:  380.08 | Running Avg: 1262.22 | Best: 5401.18 | Length: 4412
Episode 16900 | Reward:  379.98 | Running Avg: 1159.53 | Best: 5401.18 | Length: 4417
  ✓ Collision epoch 84 saved
Episode 17000 | Reward:  339.96 | Running Avg: 1168.42 | Best: 5401.18 | Length: 4475
Episode 17100 | Reward:  379.98 | Running Avg: 1084.88 | Best: 5401.18 | Length: 4417
  ✓ Collision epoch 85 saved
Episode 17200 | Reward:  360.02 | Running Avg:  954.01 | Best: 5401.18 | Length: 4441
Episode 17300 | Reward:  359.94 | Running Avg: 1238.71 | Best: 5401.18 | Length: 4450
  ✓ Collision epoch 86 saved
Episode 17400 | Reward:  380.00 | Running Avg: 1438.63 | Best: 5401.18 | Length: 4416
Episode 17500 | Reward:  380.14 | Running Avg: 1453.60 | Best: 5401.18 | Length: 4610
  ✓ Collision epoch 87 saved
Episode 17600 | Reward:  380.04 | Running Avg: 1598.62 | Best: 5401.18 | Length: 4615
Episode 17700 | Reward: 5400.92 | Running Avg: 1563.68 | Best: 5401.18 | Length: 4549
  ✓ Collision epoch 88 saved
Episode 17800 | Reward:  380.04 | Running Avg: 1555.34 | Best: 5401.18 | Length: 4414
Episode 17900 | Reward:  360.04 | Running Avg: 1532.84 | Best: 5401.18 | Length: 4445
  ✓ Collision epoch 89 saved
Episode 18000 | Reward:  320.08 | Running Avg: 1288.58 | Best: 5401.18 | Length: 4365
Episode 18100 | Reward:  380.02 | Running Avg: 1062.96 | Best: 5401.18 | Length: 4415
  ✓ Collision epoch 90 saved
Episode 18200 | Reward:  380.10 | Running Avg: 1299.73 | Best: 5401.18 | Length: 4411
Episode 18300 | Reward:  360.00 | Running Avg:  961.92 | Best: 5401.22 | Length: 4381
  ✓ Collision epoch 91 saved
Episode 18400 | Reward:  360.00 | Running Avg: 1097.89 | Best: 5401.22 | Length: 4518
Episode 18500 | Reward:  359.92 | Running Avg: 1227.69 | Best: 5401.22 | Length: 4316
  ✓ Collision epoch 92 saved
Episode 18600 | Reward:  359.98 | Running Avg: 1233.12 | Best: 5401.22 | Length: 4313
Episode 18700 | Reward: 5401.08 | Running Avg: 1512.77 | Best: 5401.22 | Length: 4541
  ✓ Collision epoch 93 saved
Episode 18800 | Reward: 5401.04 | Running Avg: 1506.85 | Best: 5401.22 | Length: 4543
Episode 18900 | Reward:  319.94 | Running Avg: 1584.90 | Best: 5401.22 | Length: 4583
  ✓ Collision epoch 94 saved
Episode 19000 | Reward:  380.08 | Running Avg: 1229.59 | Best: 5401.22 | Length: 4618
Episode 19100 | Reward: 5401.12 | Running Avg: 1523.28 | Best: 5401.22 | Length: 4539
  ✓ Collision epoch 95 saved
Episode 19200 | Reward:  360.04 | Running Avg: 1481.35 | Best: 5401.22 | Length: 4651
Episode 19300 | Reward:  380.00 | Running Avg: 1450.82 | Best: 5401.22 | Length: 4487
  ✓ Collision epoch 96 saved
Episode 19400 | Reward:  379.94 | Running Avg: 1338.65 | Best: 5401.22 | Length: 4419
Episode 19500 | Reward: 5400.98 | Running Avg: 1702.14 | Best: 5401.22 | Length: 4546
  ✓ Collision epoch 97 saved
Episode 19600 | Reward:  360.06 | Running Avg: 1700.60 | Best: 5401.22 | Length: 4515
Episode 19700 | Reward:  380.04 | Running Avg: 1631.34 | Best: 5401.22 | Length: 4414
  ✓ Collision epoch 98 saved
Episode 19800 | Reward: 5401.08 | Running Avg: 1231.40 | Best: 5401.22 | Length: 4541
Episode 19900 | Reward: 5401.06 | Running Avg: 1369.56 | Best: 5401.22 | Length: 4542
  ✓ Collision epoch 99 saved
Episode 20000 | Reward:  340.04 | Running Avg: 1676.34 | Best: 5401.22 | Length: 4341

============================================================
TRAINING COMPLETE
Final Running Average: 1676.34
Best Episode Reward: 5401.22
Total collision epochs: 100
============================================================


✓ Logging training data to analytics...

✓ Evaluating...

============================================================
EVALUATING TRAINED AGENT (10 episodes)
============================================================

Eval Episode  1: Reward=5401.10, Player=21, CPU=20, Length=4540
Eval Episode  2: Reward= 320.00, Player=17, CPU=21, Length=4374
Eval Episode  3: Reward=5401.06, Player=21, CPU=20, Length=4542
Eval Episode  4: Reward= 379.94, Player=20, CPU=21, Length=4419
Eval Episode  5: Reward= 360.00, Player=19, CPU=21, Length=4447
Eval Episode  6: Reward= 359.96, Player=19, CPU=21, Length=4314
Eval Episode  7: Reward=5400.98, Player=21, CPU=20, Length=4546
Eval Episode  8: Reward= 360.02, Player=19, CPU=21, Length=4446
Eval Episode  9: Reward=5401.08, Player=21, CPU=20, Length=4541
Eval Episode 10: Reward= 380.08, Player=20, CPU=21, Length=4412

============================================================
Mean Reward: 2376.42 ± 2469.65
Reward Range: [320.00, 5401.10]
Win Rate: 40.0%
Mean Episode Length: 4458 steps
============================================================


✓ Logging evaluation data to analytics...

✓ Saving current model to models\exp_03.npz...
✓ Agent parameters saved to 'models\exp_03.npz'
✓ Saving timestamped backup to outputs\exp_03_20251130_192852\saved_models\exp_03_20251130_192852.npz...
✓ Agent parameters saved to 'outputs\exp_03_20251130_192852\saved_models\exp_03_20251130_192852.npz'

✓ Saving configuration to outputs\exp_03_20251130_192852\saved_models\exp_03_20251130_192852_config.json...

✓ Saving analytics summary...

✓ Summary saved to outputs\exp_03_20251130_192852\recorded_data\20251130_192852_summary.txt
============================================================
TRAINING SUMMARY
============================================================
Timestamp: 20251130_192852

TRAINING RESULTS
------------------------------------------------------------
Total episodes trained: 20000
Final running average reward: 1712.42
Best episode reward: 5401.22
Worst episode reward: -20.60
Mean episode reward: 756.64
Std episode reward: 1453.78

EVALUATION METRICS
------------------------------------------------------------
Win rate: 8.9%
Total wins: 1778 / 20000
Mean episode length: 4352 steps
Mean player score: 16.6
Mean CPU score: 20.9

REWARD COMPONENTS (Average)
------------------------------------------------------------
Score reward: +335.20
Hit reward: +0.9842
Loss penalty: -20.91

ACTION DISTRIBUTION
------------------------------------------------------------
N/A

HYPERPARAMETERS
------------------------------------------------------------
timestamp: 20251130_192852
experiment_name: exp_03
continued_from_episode: 0
environment: {'width': 160, 'height': 192, 'max_score': 21, 'cpu_difficulty': 'medium'}
agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
training: {'max_episodes': 20000, 'batch_size': 5, 'running_reward_decay': 0.99, 'print_frequency': 100}
rewards: {'ball_hit': 0.02, 'score': 20.0, 'opponent_score': -1.0, 'win': 5000.0, 'loss': -0.0}
training_results: {'final_running_average': 1676.3446770361588, 'best_episode_reward': 5401.219999999999, 'total_episodes_trained': 20000, 'total_episodes_cumulative': 20000}
evaluation_results: {'mean_reward': 2376.422, 'std_reward': 2469.6511100064313, 'win_rate': 0.4, 'eval_episodes': 10}
heatmap_data: {'recording_enabled': False, 'heatmap_file': None, 'epochs_collected': 0}
collision_data: {'recording_enabled': True, 'epochs_collected': 100, 'total_collisions': 535347}

============================================================

✓ Generating analytics visualizations...

✓ Generating plots...
Warning: Skipping action distribution plot. No action data was logged during training/evaluation.
✓ All plots saved to outputs\exp_03_20251130_192852\recorded_data/ with prefix 20251130_192852

✓ Saving collision analysis to outputs\exp_03_20251130_192852\recorded_data\collision_analysis...
======================================================================
PADDLE COLLISION ANALYSIS REPORT
======================================================================

SUMMARY STATISTICS
----------------------------------------------------------------------
Total Epochs Analyzed: 100
Total Collisions Recorded: 535347

EDGE HIT PROGRESSION
----------------------------------------------------------------------
Initial Edge Hit Rate: 61.6%
Final Edge Hit Rate: 98.9%
Improvement: +37.3 percentage points

BOUNCE ANGLE PROGRESSION
----------------------------------------------------------------------
Initial Average Angle: 45.2°
Final Average Angle: 61.9°
Improvement: +16.7°

INTERPRETATION
----------------------------------------------------------------------
Edge hits increased from 61.6% to 98.9%, demonstrating the agent
learned to exploit the progressive angle system. Higher edge hit rates
produce steeper bounce angles, making returns harder to defend.

Average bounce angle increased from 45.2° to
61.9°, confirming strategic use of steep
trajectories for offensive advantage.

======================================================================

✓ Report saved to outputs\exp_03_20251130_192852\recorded_data\collision_analysis\collision_report.txt

✓ Generating collision analysis figures...
  ✓ Figure 1 saved: figure_1_collision_distribution.png
  ✓ Figure 2 saved: figure_2_angle_progression.png
  ✓ Figure 3 saved: figure_3_edge_hit_progression.png
✓ All figures saved to outputs\exp_03_20251130_192852\recorded_data\collision_analysis/
  ✓ Summary CSV: collision_summary.csv
  ✓ Distribution CSV: collision_distribution.csv
  Total CSV files: 2
✓ Collision analysis complete!
  Location: outputs\exp_03_20251130_192852\recorded_data\collision_analysis/

======================================================================
TRAINING COMPLETE
Total Training Time: 12:22:55.161701
======================================================================

✓ All results saved to: outputs\exp_03_20251130_192852/

  Models (outputs\exp_03_20251130_192852\saved_models/):
    - Model: exp_03_20251130_192852.npz
    - Config: exp_03_20251130_192852_config.json
    - Log: exp_03_20251130_192852.log

  Analytics (outputs\exp_03_20251130_192852\recorded_data/):
    - Training CSV: 20251130_192852.csv
    - Evaluation CSV: 20251130_192852_eval.csv
    - Summary: 20251130_192852_summary.txt
    - Plots (10): 20251130_192852_0*.png

  Collision Analysis (outputs\exp_03_20251130_192852\recorded_data\collision_analysis/):
    - Report: collision_report.txt
    - Statistics: collision_statistics.json
    - Figures: figure_1_collision_distribution.png
    - Figures: figure_2_angle_progression.png
    - Figures: figure_3_edge_hit_progression.png
    - Total Collisions: 535,347
    - Edge Hit Rate: 61.6% → 98.9%
    - Avg Angle: 45.2° → 61.9°
======================================================================


======================================================================
TRAINING COMPLETE
======================================================================

✓ Results saved to: outputs\exp_03_20251130_192852/
  - Model: model.npz
  - Config: config_used.json
  - Metrics: training.csv, evaluation.csv
  - Heatmap: heatmap.json
  - Log: training.log

======================================================================
INITIALIZING TRAINING COMPONENTS
======================================================================

✓ Creating environment...
  Court: 160×192
  Paddle: 2×12
  CPU Difficulty: medium

✓ Creating agent (PolicyGradient)...
  Input Size: 16
  Hidden Size: 128
  Output Size: 3
  Learning Rate: 0.0015
  Discount Factor: 0.99

✓ Creating trainer (PolicyGradient)...
  Max Episodes: 20000
  Batch Size: 5
  Running Reward Decay: 0.99

✓ Creating heatmap recorder...
  Grid Resolution: 20×24
  Court Size: 160×192

✓ Creating training orchestrator...
  Experiment: exp_04
  Orchestrator will handle:
    - Training pipeline
    - Analytics logging
    - Heatmap recording
    - Model evaluation
    - Automatic saving
✓ Analytics initialized
  Timestamp: 20251208_055824
  Output dir: outputs\exp_04_20251208_055824\recorded_data
  All files saved as: 20251208_055824*

✓ Found existing training data: outputs\exp_04_20251208_055824\recorded_data\20251208_055824.csv
  Continuing from previous run...

======================================================================
STARTING TRAINING
======================================================================

======================================================================
TRAINING ORCHESTRATOR - UNIFIED PIPELINE
======================================================================
Experiment: exp_04
Timestamp: 20251208_055824
Output Root Directory: outputs\exp_04_20251208_055824/
Output Sub-Directories:
  - Models: outputs\exp_04_20251208_055824\saved_models/
  - Analytics: outputs\exp_04_20251208_055824\recorded_data/
  - Collision Analysis: outputs\exp_04_20251208_055824\recorded_data\collision_analysis/
Heatmap Recording: ✗ DISABLED
Collision Analysis: ✓ ENABLED

✓ Starting trainer...

============================================================
TRAINING PONG AGENT
============================================================
Agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
Learning Rate: 0.0015
Discount Factor: 0.99
Max Episodes: 20000
RMSprop Decay: 0.99
Running Reward Decay: 0.99
Reward Structure: Score=20.0, Hit=0.02, Loss=-1.0
Win Reward: 5000.0, Loss Penalty: -0.0
Heatmap Recording: DISABLED
Collision Analysis: ENABLED
Episodes per collision epoch: 200
============================================================

Episode  100 | Reward:   19.62 | Running Avg:  -13.90 | Best:   79.62 | Length: 3116
  ✓ Collision epoch 0 saved
Episode  200 | Reward:   19.92 | Running Avg:   -4.70 | Best:   79.62 | Length: 4012
Episode  300 | Reward:   19.98 | Running Avg:    1.27 | Best:   79.62 | Length: 4369
  ✓ Collision epoch 1 saved
Episode  400 | Reward:   39.72 | Running Avg:    9.47 | Best:   99.88 | Length: 3471
Episode  500 | Reward:   39.90 | Running Avg:   15.22 | Best:   99.88 | Length: 4027
  ✓ Collision epoch 2 saved
Episode  600 | Reward:   19.82 | Running Avg:   16.53 | Best:   99.88 | Length: 3797
Episode  700 | Reward:  -20.08 | Running Avg:   25.51 | Best:  100.10 | Length: 3986
  ✓ Collision epoch 3 saved
Episode  800 | Reward:   19.86 | Running Avg:   34.82 | Best:  139.92 | Length: 3919
Episode  900 | Reward:   19.90 | Running Avg:   36.28 | Best:  139.92 | Length: 3906
  ✓ Collision epoch 4 saved
Episode 1000 | Reward:   80.04 | Running Avg:   43.68 | Best:  159.86 | Length: 4527
Episode 1100 | Reward:   19.70 | Running Avg:   54.48 | Best:  160.02 | Length: 3346
  ✓ Collision epoch 5 saved
Episode 1200 | Reward:   79.72 | Running Avg:   54.72 | Best:  160.02 | Length: 3518
Episode 1300 | Reward:  119.90 | Running Avg:   67.41 | Best:  160.04 | Length: 4050
  ✓ Collision epoch 6 saved
Episode 1400 | Reward:   80.00 | Running Avg:   69.62 | Best:  160.04 | Length: 4207
Episode 1500 | Reward:   99.86 | Running Avg:   75.04 | Best:  160.04 | Length: 4102
  ✓ Collision epoch 7 saved
Episode 1600 | Reward:  119.76 | Running Avg:   83.32 | Best:  200.00 | Length: 3633
Episode 1700 | Reward:   80.00 | Running Avg:   84.63 | Best:  200.00 | Length: 4312
  ✓ Collision epoch 8 saved
Episode 1800 | Reward:   59.96 | Running Avg:   89.91 | Best:  200.20 | Length: 4241
Episode 1900 | Reward:  159.98 | Running Avg:   95.96 | Best:  200.20 | Length: 4271
  ✓ Collision epoch 9 saved
Episode 2000 | Reward:  119.90 | Running Avg:  105.84 | Best:  220.00 | Length: 4126
Episode 2100 | Reward:  119.86 | Running Avg:  108.47 | Best:  220.00 | Length: 3885
  ✓ Collision epoch 10 saved
Episode 2200 | Reward:   99.80 | Running Avg:  111.06 | Best:  220.00 | Length: 3707
Episode 2300 | Reward:  140.04 | Running Avg:  115.83 | Best:  220.00 | Length: 4524
  ✓ Collision epoch 11 saved
Episode 2400 | Reward:  219.96 | Running Avg:  118.27 | Best:  299.98 | Length: 4358
Episode 2500 | Reward:  100.22 | Running Avg:  114.51 | Best:  299.98 | Length: 4830
  ✓ Collision epoch 12 saved
Episode 2600 | Reward:  119.78 | Running Avg:  112.81 | Best:  299.98 | Length: 3733
Episode 2700 | Reward:  119.94 | Running Avg:  120.59 | Best:  299.98 | Length: 4181
  ✓ Collision epoch 13 saved
Episode 2800 | Reward:   39.96 | Running Avg:  127.02 | Best:  299.98 | Length: 4175
Episode 2900 | Reward:  119.64 | Running Avg:  130.54 | Best:  299.98 | Length: 3335
  ✓ Collision epoch 14 saved
Episode 3000 | Reward:  139.80 | Running Avg:  130.68 | Best:  299.98 | Length: 3848
Episode 3100 | Reward:  159.94 | Running Avg:  125.05 | Best:  299.98 | Length: 4213
  ✓ Collision epoch 15 saved
Episode 3200 | Reward:  119.94 | Running Avg:  132.29 | Best:  299.98 | Length: 4224
Episode 3300 | Reward:  199.98 | Running Avg:  137.33 | Best:  299.98 | Length: 4353
  ✓ Collision epoch 16 saved
Episode 3400 | Reward:  139.74 | Running Avg:  137.60 | Best:  299.98 | Length: 3652
Episode 3500 | Reward:  200.00 | Running Avg:  147.71 | Best:  299.98 | Length: 4369
  ✓ Collision epoch 17 saved
Episode 3600 | Reward:   99.82 | Running Avg:  143.74 | Best:  299.98 | Length: 3762
Episode 3700 | Reward:  199.86 | Running Avg:  157.91 | Best:  299.98 | Length: 4237
  ✓ Collision epoch 18 saved
Episode 3800 | Reward:  139.94 | Running Avg:  152.80 | Best:  299.98 | Length: 4096
Episode 3900 | Reward:  220.02 | Running Avg:  160.97 | Best:  300.10 | Length: 4266
  ✓ Collision epoch 19 saved
Episode 4000 | Reward:  159.98 | Running Avg:  175.05 | Best:  300.10 | Length: 4334
Episode 4100 | Reward:  199.96 | Running Avg:  182.03 | Best:  300.10 | Length: 4158
  ✓ Collision epoch 20 saved
Episode 4200 | Reward:  219.88 | Running Avg:  181.21 | Best:  300.10 | Length: 3975
Episode 4300 | Reward:  199.78 | Running Avg:  188.88 | Best:  300.10 | Length: 3892
  ✓ Collision epoch 21 saved
Episode 4400 | Reward:  239.94 | Running Avg:  198.45 | Best:  340.04 | Length: 4288
Episode 4500 | Reward:  239.90 | Running Avg:  203.61 | Best:  340.04 | Length: 4099
  ✓ Collision epoch 22 saved
Episode 4600 | Reward:  219.84 | Running Avg:  207.10 | Best:  340.04 | Length: 3999
Episode 4700 | Reward:  239.98 | Running Avg:  215.27 | Best:  340.04 | Length: 4144
  ✓ Collision epoch 23 saved
Episode 4800 | Reward:  320.02 | Running Avg:  222.60 | Best:  340.04 | Length: 4508
Episode 4900 | Reward:  219.90 | Running Avg:  221.28 | Best:  340.04 | Length: 4177
  ✓ Collision epoch 24 saved
Episode 5000 | Reward:  199.92 | Running Avg:  224.19 | Best:  340.04 | Length: 4138
Episode 5100 | Reward:  239.96 | Running Avg:  228.55 | Best:  359.96 | Length: 4081
  ✓ Collision epoch 25 saved
Episode 5200 | Reward:  280.04 | Running Avg:  227.82 | Best:  359.96 | Length: 4356
Episode 5300 | Reward:  239.96 | Running Avg:  234.76 | Best:  359.96 | Length: 4275
  ✓ Collision epoch 26 saved
Episode 5400 | Reward:  199.94 | Running Avg:  235.05 | Best:  359.96 | Length: 4215
Episode 5500 | Reward:  200.02 | Running Avg:  234.02 | Best:  359.96 | Length: 4483
  ✓ Collision epoch 27 saved
Episode 5600 | Reward:  259.98 | Running Avg:  243.25 | Best:  359.96 | Length: 4314
Episode 5700 | Reward:  259.94 | Running Avg:  251.35 | Best:  359.96 | Length: 4051
  ✓ Collision epoch 28 saved
Episode 5800 | Reward:  239.96 | Running Avg:  252.24 | Best:  380.10 | Length: 4155
Episode 5900 | Reward:  220.00 | Running Avg:  266.33 | Best:  380.10 | Length: 4237
  ✓ Collision epoch 29 saved
Episode 6000 | Reward:  279.94 | Running Avg:  271.58 | Best:  380.10 | Length: 4169
Episode 6100 | Reward:  279.94 | Running Avg:  277.51 | Best:  380.10 | Length: 4097
  ✓ Collision epoch 30 saved
Episode 6200 | Reward:  320.06 | Running Avg:  275.89 | Best:  380.10 | Length: 4432
Episode 6300 | Reward:  299.96 | Running Avg:  276.18 | Best:  380.10 | Length: 4137
  ✓ Collision epoch 31 saved
Episode 6400 | Reward:  259.96 | Running Avg:  282.08 | Best:  380.10 | Length: 4314
Episode 6500 | Reward:  259.82 | Running Avg:  283.83 | Best:  380.10 | Length: 3923
  ✓ Collision epoch 32 saved
Episode 6600 | Reward:  279.98 | Running Avg:  290.62 | Best:  380.10 | Length: 4302
Episode 6700 | Reward:  360.08 | Running Avg:  289.25 | Best:  380.10 | Length: 4644
  ✓ Collision epoch 33 saved
Episode 6800 | Reward:  259.86 | Running Avg:  296.41 | Best:  380.12 | Length: 3930
Episode 6900 | Reward:  280.02 | Running Avg:  325.00 | Best: 5401.02 | Length: 4290
  ✓ Collision epoch 34 saved
Episode 7000 | Reward:  259.86 | Running Avg:  310.90 | Best: 5401.02 | Length: 3921
Episode 7100 | Reward:  299.92 | Running Avg:  352.81 | Best: 5401.02 | Length: 4004
  ✓ Collision epoch 35 saved
Episode 7200 | Reward:  360.04 | Running Avg:  325.02 | Best: 5401.02 | Length: 4379
Episode 7300 | Reward:  340.04 | Running Avg:  324.42 | Best: 5401.02 | Length: 4540
  ✓ Collision epoch 36 saved
Episode 7400 | Reward:  300.02 | Running Avg:  315.22 | Best: 5401.02 | Length: 4399
Episode 7500 | Reward:  319.92 | Running Avg:  315.01 | Best: 5401.02 | Length: 4312
  ✓ Collision epoch 37 saved
Episode 7600 | Reward:  279.86 | Running Avg:  337.48 | Best: 5401.02 | Length: 3972
Episode 7700 | Reward:  240.02 | Running Avg:  323.85 | Best: 5401.02 | Length: 4358
  ✓ Collision epoch 38 saved
Episode 7800 | Reward:  339.96 | Running Avg:  314.87 | Best: 5401.02 | Length: 4206
Episode 7900 | Reward:  320.00 | Running Avg:  313.01 | Best: 5401.02 | Length: 4369
  ✓ Collision epoch 39 saved
Episode 8000 | Reward: 5401.08 | Running Avg:  444.87 | Best: 5401.08 | Length: 4541
Episode 8100 | Reward:  339.94 | Running Avg:  414.32 | Best: 5401.08 | Length: 4209
  ✓ Collision epoch 40 saved
Episode 8200 | Reward:  319.96 | Running Avg:  442.02 | Best: 5401.10 | Length: 4442
Episode 8300 | Reward:  339.96 | Running Avg:  519.21 | Best: 5401.10 | Length: 4340
  ✓ Collision epoch 41 saved
Episode 8400 | Reward:  340.02 | Running Avg:  452.10 | Best: 5401.18 | Length: 4548
Episode 8500 | Reward:  299.94 | Running Avg:  469.08 | Best: 5401.18 | Length: 4479
  ✓ Collision epoch 42 saved
Episode 8600 | Reward:  339.98 | Running Avg:  497.06 | Best: 5401.18 | Length: 4344
Episode 8700 | Reward:  359.98 | Running Avg:  386.50 | Best: 5401.18 | Length: 4311
  ✓ Collision epoch 43 saved
Episode 8800 | Reward:  319.92 | Running Avg:  416.50 | Best: 5401.18 | Length: 4314
Episode 8900 | Reward:  279.90 | Running Avg:  494.86 | Best: 5401.18 | Length: 3972
  ✓ Collision epoch 44 saved
Episode 9000 | Reward:  339.92 | Running Avg:  535.74 | Best: 5401.18 | Length: 4210
Episode 9100 | Reward:  239.76 | Running Avg:  462.25 | Best: 5401.18 | Length: 3700
  ✓ Collision epoch 45 saved
Episode 9200 | Reward:  320.04 | Running Avg:  519.59 | Best: 5401.18 | Length: 4434
Episode 9300 | Reward:  339.88 | Running Avg:  562.98 | Best: 5401.18 | Length: 4344
  ✓ Collision epoch 46 saved
Episode 9400 | Reward:  340.02 | Running Avg:  550.49 | Best: 5401.18 | Length: 4546
Episode 9500 | Reward:  280.12 | Running Avg:  519.08 | Best: 5401.18 | Length: 4771
  ✓ Collision epoch 47 saved
Episode 9600 | Reward:  360.02 | Running Avg:  585.44 | Best: 5401.18 | Length: 4311
Episode 9700 | Reward:  299.96 | Running Avg:  539.54 | Best: 5401.18 | Length: 4478
  ✓ Collision epoch 48 saved
Episode 9800 | Reward:  319.92 | Running Avg:  540.05 | Best: 5401.18 | Length: 4239
Episode 9900 | Reward:  360.10 | Running Avg:  751.83 | Best: 5401.18 | Length: 4648
  ✓ Collision epoch 49 saved
Episode 10000 | Reward:  380.00 | Running Avg:  807.54 | Best: 5401.18 | Length: 4487
Episode 10100 | Reward:  360.04 | Running Avg:  709.93 | Best: 5401.18 | Length: 4511
  ✓ Collision epoch 50 saved
Episode 10200 | Reward:  380.10 | Running Avg:  572.80 | Best: 5401.18 | Length: 4482
Episode 10300 | Reward:  359.98 | Running Avg:  625.80 | Best: 5401.18 | Length: 4313
  ✓ Collision epoch 51 saved
Episode 10400 | Reward:  360.02 | Running Avg:  639.51 | Best: 5401.18 | Length: 4517
Episode 10500 | Reward:  360.06 | Running Avg:  793.34 | Best: 5401.18 | Length: 4439
  ✓ Collision epoch 52 saved
Episode 10600 | Reward:  380.00 | Running Avg:  645.40 | Best: 5401.18 | Length: 4485
Episode 10700 | Reward:  340.04 | Running Avg:  613.27 | Best: 5401.18 | Length: 4471
  ✓ Collision epoch 53 saved
Episode 10800 | Reward:  360.00 | Running Avg:  693.68 | Best: 5401.18 | Length: 4447
Episode 10900 | Reward:  379.94 | Running Avg:  659.64 | Best: 5401.18 | Length: 4419
  ✓ Collision epoch 54 saved
Episode 11000 | Reward:  380.06 | Running Avg:  607.94 | Best: 5401.18 | Length: 4619
Episode 11100 | Reward:  360.10 | Running Avg:  709.80 | Best: 5401.18 | Length: 4511
  ✓ Collision epoch 55 saved
Episode 11200 | Reward:  360.10 | Running Avg:  670.36 | Best: 5401.18 | Length: 4638
Episode 11300 | Reward:  380.02 | Running Avg:  820.78 | Best: 5401.18 | Length: 4415
  ✓ Collision epoch 56 saved
Episode 11400 | Reward:  319.98 | Running Avg:  961.63 | Best: 5401.18 | Length: 4373
Episode 11500 | Reward:  339.98 | Running Avg: 1105.16 | Best: 5401.18 | Length: 4479
  ✓ Collision epoch 57 saved
Episode 11600 | Reward:  379.96 | Running Avg:  902.25 | Best: 5401.18 | Length: 4418
Episode 11700 | Reward:  380.04 | Running Avg:  920.75 | Best: 5401.18 | Length: 4414
  ✓ Collision epoch 58 saved
Episode 11800 | Reward:  360.00 | Running Avg:  878.50 | Best: 5401.18 | Length: 4447
Episode 11900 | Reward:  339.98 | Running Avg:  786.57 | Best: 5401.18 | Length: 4342
  ✓ Collision epoch 59 saved
Episode 12000 | Reward:  360.10 | Running Avg: 1026.35 | Best: 5401.18 | Length: 4508
Episode 12100 | Reward:  379.98 | Running Avg:  840.82 | Best: 5401.18 | Length: 4417
  ✓ Collision epoch 60 saved
Episode 12200 | Reward:  339.96 | Running Avg:  798.68 | Best: 5401.18 | Length: 4345
Episode 12300 | Reward:  380.12 | Running Avg:  691.35 | Best: 5401.18 | Length: 4616
  ✓ Collision epoch 61 saved
Episode 12400 | Reward:  360.06 | Running Avg:  847.63 | Best: 5401.18 | Length: 4515
Episode 12500 | Reward:  359.96 | Running Avg:  976.86 | Best: 5401.18 | Length: 4314
  ✓ Collision epoch 62 saved
Episode 12600 | Reward:  380.04 | Running Avg:  795.94 | Best: 5401.18 | Length: 4483
Episode 12700 | Reward:  380.04 | Running Avg:  708.46 | Best: 5401.18 | Length: 4414
  ✓ Collision epoch 63 saved
Episode 12800 | Reward:  360.00 | Running Avg:  657.29 | Best: 5401.18 | Length: 4447
Episode 12900 | Reward:  339.96 | Running Avg:  780.76 | Best: 5401.18 | Length: 4345
  ✓ Collision epoch 64 saved
Episode 13000 | Reward:  360.00 | Running Avg:  862.52 | Best: 5401.18 | Length: 4312
Episode 13100 | Reward:  320.00 | Running Avg:  620.77 | Best: 5401.18 | Length: 4570
  ✓ Collision epoch 65 saved
Episode 13200 | Reward:  320.00 | Running Avg: 1031.32 | Best: 5401.18 | Length: 4239
Episode 13300 | Reward:  320.04 | Running Avg: 1068.41 | Best: 5401.18 | Length: 4443
  ✓ Collision epoch 66 saved
Episode 13400 | Reward:  360.08 | Running Avg:  998.03 | Best: 5401.18 | Length: 4507
Episode 13500 | Reward:  340.08 | Running Avg:  674.72 | Best: 5401.18 | Length: 4405
  ✓ Collision epoch 67 saved
Episode 13600 | Reward:  359.90 | Running Avg:  665.92 | Best: 5401.18 | Length: 4317
Episode 13700 | Reward:  380.04 | Running Avg:  763.76 | Best: 5401.18 | Length: 4483
  ✓ Collision epoch 68 saved
Episode 13800 | Reward: 5401.12 | Running Avg: 1222.87 | Best: 5401.18 | Length: 4539
Episode 13900 | Reward: 5400.94 | Running Avg:  989.66 | Best: 5401.18 | Length: 4548
  ✓ Collision epoch 69 saved
Episode 14000 | Reward:  380.00 | Running Avg: 1127.84 | Best: 5401.18 | Length: 4487
Episode 14100 | Reward:  380.02 | Running Avg: 1089.98 | Best: 5401.18 | Length: 4415
  ✓ Collision epoch 70 saved
Episode 14200 | Reward:  380.02 | Running Avg: 1060.38 | Best: 5401.18 | Length: 4484
Episode 14300 | Reward:  320.00 | Running Avg: 1140.11 | Best: 5401.18 | Length: 4494
  ✓ Collision epoch 71 saved
Episode 14400 | Reward:  339.90 | Running Avg: 1054.94 | Best: 5401.18 | Length: 4209
Episode 14500 | Reward: 5401.08 | Running Avg: 1052.07 | Best: 5401.18 | Length: 4541
  ✓ Collision epoch 72 saved
Episode 14600 | Reward:  360.08 | Running Avg: 1366.38 | Best: 5401.18 | Length: 4649
Episode 14700 | Reward: 5400.98 | Running Avg: 1155.15 | Best: 5401.18 | Length: 4546
  ✓ Collision epoch 73 saved
Episode 14800 | Reward:  380.10 | Running Avg: 1158.01 | Best: 5401.18 | Length: 4612
Episode 14900 | Reward:  359.94 | Running Avg: 1358.32 | Best: 5401.18 | Length: 4315
  ✓ Collision epoch 74 saved
Episode 15000 | Reward:  359.90 | Running Avg: 1306.67 | Best: 5401.18 | Length: 4315
Episode 15100 | Reward:  359.92 | Running Avg: 1526.66 | Best: 5401.18 | Length: 4316
  ✓ Collision epoch 75 saved
Episode 15200 | Reward:  380.00 | Running Avg: 1239.89 | Best: 5401.18 | Length: 4487
Episode 15300 | Reward:  340.00 | Running Avg: 1597.30 | Best: 5401.18 | Length: 4478
  ✓ Collision epoch 76 saved
Episode 15400 | Reward:  279.92 | Running Avg: 1526.91 | Best: 5401.18 | Length: 4286
Episode 15500 | Reward: 5401.02 | Running Avg: 1248.30 | Best: 5401.18 | Length: 4544
  ✓ Collision epoch 77 saved
Episode 15600 | Reward:  360.02 | Running Avg: 1425.74 | Best: 5401.18 | Length: 4446
Episode 15700 | Reward:  380.04 | Running Avg: 1458.03 | Best: 5401.18 | Length: 4620
  ✓ Collision epoch 78 saved
Episode 15800 | Reward:  380.04 | Running Avg: 1383.17 | Best: 5401.18 | Length: 4414
Episode 15900 | Reward:  380.08 | Running Avg: 1444.84 | Best: 5401.18 | Length: 4483
  ✓ Collision epoch 79 saved
Episode 16000 | Reward:  359.90 | Running Avg: 1571.98 | Best: 5401.18 | Length: 4388
Episode 16100 | Reward:  360.02 | Running Avg: 1770.62 | Best: 5401.18 | Length: 4311
  ✓ Collision epoch 80 saved
Episode 16200 | Reward: 5401.08 | Running Avg: 1609.59 | Best: 5401.18 | Length: 4541
Episode 16300 | Reward:  380.02 | Running Avg: 1624.93 | Best: 5401.18 | Length: 4415
  ✓ Collision epoch 81 saved
Episode 16400 | Reward:  359.94 | Running Avg: 1508.38 | Best: 5401.18 | Length: 4315
Episode 16500 | Reward:  380.00 | Running Avg: 1382.37 | Best: 5401.18 | Length: 4487
  ✓ Collision epoch 82 saved
Episode 16600 | Reward:  380.02 | Running Avg: 1449.34 | Best: 5401.18 | Length: 4486
Episode 16700 | Reward:  339.98 | Running Avg: 1429.46 | Best: 5401.18 | Length: 4207
  ✓ Collision epoch 83 saved
Episode 16800 | Reward:  380.02 | Running Avg: 1364.23 | Best: 5401.18 | Length: 4415
Episode 16900 | Reward:  380.06 | Running Avg: 1329.47 | Best: 5401.18 | Length: 4484
  ✓ Collision epoch 84 saved
Episode 17000 | Reward:  379.96 | Running Avg: 1608.39 | Best: 5401.18 | Length: 4418
Episode 17100 | Reward:  380.10 | Running Avg: 1443.20 | Best: 5401.18 | Length: 4411
  ✓ Collision epoch 85 saved
Episode 17200 | Reward:  360.00 | Running Avg: 1537.74 | Best: 5401.18 | Length: 4312
Episode 17300 | Reward:  360.02 | Running Avg: 1505.95 | Best: 5401.18 | Length: 4446
  ✓ Collision epoch 86 saved
Episode 17400 | Reward: 5401.14 | Running Avg: 1805.43 | Best: 5401.18 | Length: 4538
Episode 17500 | Reward:  380.14 | Running Avg: 1613.28 | Best: 5401.18 | Length: 4610
  ✓ Collision epoch 87 saved
Episode 17600 | Reward: 5401.04 | Running Avg: 1443.01 | Best: 5401.18 | Length: 4543
Episode 17700 | Reward:  360.02 | Running Avg: 1431.13 | Best: 5401.18 | Length: 4311
  ✓ Collision epoch 88 saved
Episode 17800 | Reward:  360.00 | Running Avg: 1447.54 | Best: 5401.18 | Length: 4312
Episode 17900 | Reward:  380.00 | Running Avg: 1776.50 | Best: 5401.18 | Length: 4416
  ✓ Collision epoch 89 saved
Episode 18000 | Reward:  360.00 | Running Avg: 1589.75 | Best: 5401.18 | Length: 4312
Episode 18100 | Reward:  339.98 | Running Avg: 1609.13 | Best: 5401.18 | Length: 4209
  ✓ Collision epoch 90 saved
Episode 18200 | Reward:  360.06 | Running Avg: 1603.28 | Best: 5401.18 | Length: 4513
Episode 18300 | Reward: 5401.08 | Running Avg: 1771.07 | Best: 5401.18 | Length: 4541
  ✓ Collision epoch 91 saved
Episode 18400 | Reward: 5401.00 | Running Avg: 1610.02 | Best: 5401.18 | Length: 4545
Episode 18500 | Reward:  379.96 | Running Avg: 1371.36 | Best: 5401.18 | Length: 4418
  ✓ Collision epoch 92 saved
Episode 18600 | Reward:  379.98 | Running Avg: 1343.08 | Best: 5401.18 | Length: 4417
Episode 18700 | Reward:  360.00 | Running Avg: 1530.99 | Best: 5401.18 | Length: 4312
  ✓ Collision epoch 93 saved
Episode 18800 | Reward:  380.04 | Running Avg: 1584.57 | Best: 5401.18 | Length: 4485
Episode 18900 | Reward:  380.04 | Running Avg: 1543.84 | Best: 5401.18 | Length: 4414
  ✓ Collision epoch 94 saved
Episode 19000 | Reward:  379.96 | Running Avg: 1603.94 | Best: 5401.18 | Length: 4418
Episode 19100 | Reward:  380.02 | Running Avg: 1583.23 | Best: 5401.18 | Length: 4415
  ✓ Collision epoch 95 saved
Episode 19200 | Reward:  359.92 | Running Avg: 1745.08 | Best: 5401.18 | Length: 4316
Episode 19300 | Reward:  380.04 | Running Avg: 1536.90 | Best: 5401.18 | Length: 4485
  ✓ Collision epoch 96 saved
Episode 19400 | Reward:  359.98 | Running Avg: 1412.69 | Best: 5401.18 | Length: 4313
Episode 19500 | Reward:  379.98 | Running Avg: 1674.61 | Best: 5401.18 | Length: 4417
  ✓ Collision epoch 97 saved
Episode 19600 | Reward:  360.08 | Running Avg: 1611.81 | Best: 5401.18 | Length: 4443
Episode 19700 | Reward:  380.04 | Running Avg: 1443.08 | Best: 5401.18 | Length: 4414
  ✓ Collision epoch 98 saved
Episode 19800 | Reward:  380.04 | Running Avg: 1467.74 | Best: 5401.18 | Length: 4414
Episode 19900 | Reward: 5401.00 | Running Avg: 1443.72 | Best: 5401.18 | Length: 4545
  ✓ Collision epoch 99 saved
Episode 20000 | Reward:  380.00 | Running Avg: 1683.10 | Best: 5401.18 | Length: 4416

============================================================
TRAINING COMPLETE
Final Running Average: 1683.10
Best Episode Reward: 5401.18
Total collision epochs: 100
============================================================


✓ Logging training data to analytics...

✓ Evaluating...

============================================================
EVALUATING TRAINED AGENT (10 episodes)
============================================================

Eval Episode  1: Reward= 339.94, Player=18, CPU=21, Length=4282
Eval Episode  2: Reward= 380.06, Player=20, CPU=21, Length=4619
Eval Episode  3: Reward=5401.00, Player=21, CPU=20, Length=4545
Eval Episode  4: Reward= 359.90, Player=19, CPU=21, Length=4388
Eval Episode  5: Reward= 360.02, Player=19, CPU=21, Length=4311
Eval Episode  6: Reward= 319.94, Player=17, CPU=21, Length=4178
Eval Episode  7: Reward=5401.00, Player=21, CPU=20, Length=4545
Eval Episode  8: Reward=5401.02, Player=21, CPU=20, Length=4544
Eval Episode  9: Reward= 380.02, Player=20, CPU=21, Length=4630
Eval Episode 10: Reward= 379.96, Player=20, CPU=21, Length=4624

============================================================
Mean Reward: 1872.29 ± 2310.16
Reward Range: [319.94, 5401.02]
Win Rate: 30.0%
Mean Episode Length: 4467 steps
============================================================


✓ Logging evaluation data to analytics...

✓ Saving current model to models\exp_04.npz...
✓ Agent parameters saved to 'models\exp_04.npz'
✓ Saving timestamped backup to outputs\exp_04_20251208_055824\saved_models\exp_04_20251208_055824.npz...
✓ Agent parameters saved to 'outputs\exp_04_20251208_055824\saved_models\exp_04_20251208_055824.npz'

✓ Saving configuration to outputs\exp_04_20251208_055824\saved_models\exp_04_20251208_055824_config.json...

✓ Saving analytics summary...

✓ Summary saved to outputs\exp_04_20251208_055824\recorded_data\20251208_055824_summary.txt
============================================================
TRAINING SUMMARY
============================================================
Timestamp: 20251208_055824

TRAINING RESULTS
------------------------------------------------------------
Total episodes trained: 20000
Final running average reward: 1588.93
Best episode reward: 5401.18
Worst episode reward: -20.60
Mean episode reward: 730.38
Std episode reward: 1458.09

EVALUATION METRICS
------------------------------------------------------------
Win rate: 8.8%
Total wins: 1767 / 20000
Mean episode length: 4318 steps
Mean player score: 15.4
Mean CPU score: 20.9

REWARD COMPONENTS (Average)
------------------------------------------------------------
Score reward: +311.92
Hit reward: +0.9759
Loss penalty: -20.91

ACTION DISTRIBUTION
------------------------------------------------------------
N/A

HYPERPARAMETERS
------------------------------------------------------------
timestamp: 20251208_055824
experiment_name: exp_04
continued_from_episode: 0
environment: {'width': 160, 'height': 192, 'max_score': 21, 'cpu_difficulty': 'medium'}
agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
training: {'max_episodes': 20000, 'batch_size': 5, 'running_reward_decay': 0.99, 'print_frequency': 100}
rewards: {'ball_hit': 0.02, 'score': 20.0, 'opponent_score': -1.0, 'win': 5000.0, 'loss': -0.0}
training_results: {'final_running_average': 1683.1019917423907, 'best_episode_reward': 5401.18, 'total_episodes_trained': 20000, 'total_episodes_cumulative': 20000}
evaluation_results: {'mean_reward': 1872.2859999999996, 'std_reward': 2310.1593885626157, 'win_rate': 0.3, 'eval_episodes': 10}
heatmap_data: {'recording_enabled': False, 'heatmap_file': None, 'epochs_collected': 0}
collision_data: {'recording_enabled': True, 'epochs_collected': 100, 'total_collisions': 513881}

============================================================

✓ Generating analytics visualizations...

✓ Generating plots...
Warning: Skipping action distribution plot. No action data was logged during training/evaluation.
✓ All plots saved to outputs\exp_04_20251208_055824\recorded_data/ with prefix 20251208_055824

✓ Saving collision analysis to outputs\exp_04_20251208_055824\recorded_data\collision_analysis...
======================================================================
PADDLE COLLISION ANALYSIS REPORT
======================================================================

SUMMARY STATISTICS
----------------------------------------------------------------------
Total Epochs Analyzed: 100
Total Collisions Recorded: 513881

EDGE HIT PROGRESSION
----------------------------------------------------------------------
Initial Edge Hit Rate: 54.2%
Final Edge Hit Rate: 99.6%
Improvement: +45.5 percentage points

BOUNCE ANGLE PROGRESSION
----------------------------------------------------------------------
Initial Average Angle: 41.6°
Final Average Angle: 62.5°
Improvement: +20.8°

INTERPRETATION
----------------------------------------------------------------------
Edge hits increased from 54.2% to 99.6%, demonstrating the agent
learned to exploit the progressive angle system. Higher edge hit rates
produce steeper bounce angles, making returns harder to defend.

Average bounce angle increased from 41.6° to
62.5°, confirming strategic use of steep
trajectories for offensive advantage.

======================================================================

✓ Report saved to outputs\exp_04_20251208_055824\recorded_data\collision_analysis\collision_report.txt

✓ Generating collision analysis figures...
  ✓ Figure 1 saved: figure_1_collision_distribution.png
  ✓ Figure 2 saved: figure_2_angle_progression.png
  ✓ Figure 3 saved: figure_3_edge_hit_progression.png
✓ All figures saved to outputs\exp_04_20251208_055824\recorded_data\collision_analysis/
  ✓ Summary CSV: collision_summary.csv
  ✓ Distribution CSV: collision_distribution.csv
  Total CSV files: 2
✓ Collision analysis complete!
  Location: outputs\exp_04_20251208_055824\recorded_data\collision_analysis/

======================================================================
TRAINING COMPLETE
Total Training Time: 5:58:16.448634
======================================================================

✓ All results saved to: outputs\exp_04_20251208_055824/

  Models (outputs\exp_04_20251208_055824\saved_models/):
    - Model: exp_04_20251208_055824.npz
    - Config: exp_04_20251208_055824_config.json
    - Log: exp_04_20251208_055824.log

  Analytics (outputs\exp_04_20251208_055824\recorded_data/):
    - Training CSV: 20251208_055824.csv
    - Evaluation CSV: 20251208_055824_eval.csv
    - Summary: 20251208_055824_summary.txt
    - Plots (10): 20251208_055824_0*.png

  Collision Analysis (outputs\exp_04_20251208_055824\recorded_data\collision_analysis/):
    - Report: collision_report.txt
    - Statistics: collision_statistics.json
    - Figures: figure_1_collision_distribution.png
    - Figures: figure_2_angle_progression.png
    - Figures: figure_3_edge_hit_progression.png
    - Total Collisions: 513,881
    - Edge Hit Rate: 54.2% → 99.6%
    - Avg Angle: 41.6° → 62.5°
======================================================================


======================================================================
TRAINING COMPLETE
======================================================================

✓ Results saved to: outputs\exp_04_20251208_055824/
  - Model: model.npz
  - Config: config_used.json
  - Metrics: training.csv, evaluation.csv
  - Heatmap: heatmap.json
  - Log: training.log

======================================================================
INITIALIZING TRAINING COMPONENTS
======================================================================

✓ Creating environment...
  Court: 160×192
  Paddle: 2×12
  CPU Difficulty: medium

✓ Creating agent (PolicyGradient)...
  Input Size: 16
  Hidden Size: 128
  Output Size: 3
  Learning Rate: 0.0015
  Discount Factor: 0.99

✓ Creating trainer (PolicyGradient)...
  Max Episodes: 20000
  Batch Size: 5
  Running Reward Decay: 0.99

✓ Creating heatmap recorder...
  Grid Resolution: 20×24
  Court Size: 160×192

✓ Creating training orchestrator...
  Experiment: exp_05
  Orchestrator will handle:
    - Training pipeline
    - Analytics logging
    - Heatmap recording
    - Model evaluation
    - Automatic saving
✓ Analytics initialized
  Timestamp: 20251208_124350
  Output dir: outputs\exp_05_20251208_124350\recorded_data
  All files saved as: 20251208_124350*

✓ Found existing training data: outputs\exp_05_20251208_124350\recorded_data\20251208_124350.csv
  Continuing from previous run...

======================================================================
STARTING TRAINING
======================================================================

======================================================================
TRAINING ORCHESTRATOR - UNIFIED PIPELINE
======================================================================
Experiment: exp_05
Timestamp: 20251208_124350
Output Root Directory: outputs\exp_05_20251208_124350/
Output Sub-Directories:
  - Models: outputs\exp_05_20251208_124350\saved_models/
  - Analytics: outputs\exp_05_20251208_124350\recorded_data/
  - Collision Analysis: outputs\exp_05_20251208_124350\recorded_data\collision_analysis/
Heatmap Recording: ✗ DISABLED
Collision Analysis: ✓ ENABLED

✓ Starting trainer...

============================================================
TRAINING PONG AGENT
============================================================
Agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
Learning Rate: 0.0015
Discount Factor: 0.99
Max Episodes: 20000
RMSprop Decay: 0.99
Running Reward Decay: 0.99
Reward Structure: Score=20.0, Hit=0.02, Loss=-1.0
Win Reward: 5000.0, Loss Penalty: -0.0
Heatmap Recording: DISABLED
Collision Analysis: ENABLED
Episodes per collision epoch: 200
============================================================

Episode  100 | Reward:   19.62 | Running Avg:    3.12 | Best:   59.56 | Length: 3133
  ✓ Collision epoch 0 saved
Episode  200 | Reward:   19.76 | Running Avg:    4.50 | Best:   79.90 | Length: 3604
Episode  300 | Reward:   -0.06 | Running Avg:   11.15 | Best:   99.94 | Length: 4173
  ✓ Collision epoch 1 saved
Episode  400 | Reward:   -0.16 | Running Avg:   19.77 | Best:   99.96 | Length: 3928
Episode  500 | Reward:   39.92 | Running Avg:   27.23 | Best:  119.92 | Length: 4094
  ✓ Collision epoch 2 saved
Episode  600 | Reward:   79.84 | Running Avg:   37.40 | Best:  159.94 | Length: 3941
Episode  700 | Reward:   60.02 | Running Avg:   41.28 | Best:  159.94 | Length: 4436
  ✓ Collision epoch 3 saved
Episode  800 | Reward:   60.12 | Running Avg:   53.91 | Best:  179.96 | Length: 4714
Episode  900 | Reward:   59.74 | Running Avg:   61.05 | Best:  179.96 | Length: 3516
  ✓ Collision epoch 4 saved
Episode 1000 | Reward:  139.82 | Running Avg:   71.12 | Best:  179.98 | Length: 3733
Episode 1100 | Reward:   79.90 | Running Avg:   76.72 | Best:  199.82 | Length: 4154
  ✓ Collision epoch 5 saved
Episode 1200 | Reward:  159.88 | Running Avg:   90.24 | Best:  199.96 | Length: 4040
Episode 1300 | Reward:  139.86 | Running Avg:   95.10 | Best:  220.00 | Length: 4057
  ✓ Collision epoch 6 saved
Episode 1400 | Reward:  159.84 | Running Avg:  104.68 | Best:  240.00 | Length: 4030
Episode 1500 | Reward:  159.90 | Running Avg:  113.15 | Best:  240.00 | Length: 4066
  ✓ Collision epoch 7 saved
Episode 1600 | Reward:   79.82 | Running Avg:  121.61 | Best:  240.00 | Length: 3816
Episode 1700 | Reward:  119.82 | Running Avg:  141.76 | Best:  259.86 | Length: 3735
  ✓ Collision epoch 8 saved
Episode 1800 | Reward:  200.00 | Running Avg:  154.25 | Best:  280.02 | Length: 4488
Episode 1900 | Reward:  159.92 | Running Avg:  164.48 | Best:  299.98 | Length: 4090
  ✓ Collision epoch 9 saved
Episode 2000 | Reward:  199.98 | Running Avg:  170.07 | Best:  299.98 | Length: 4260
Episode 2100 | Reward:  240.06 | Running Avg:  174.74 | Best:  299.98 | Length: 4554
  ✓ Collision epoch 10 saved
Episode 2200 | Reward:  220.06 | Running Avg:  188.53 | Best:  299.98 | Length: 4570
Episode 2300 | Reward:  259.86 | Running Avg:  197.82 | Best:  299.98 | Length: 4122
  ✓ Collision epoch 11 saved
Episode 2400 | Reward:  300.00 | Running Avg:  198.13 | Best:  300.06 | Length: 4327
Episode 2500 | Reward:  280.00 | Running Avg:  205.20 | Best:  340.04 | Length: 4221
  ✓ Collision epoch 12 saved
Episode 2600 | Reward:  219.84 | Running Avg:  207.99 | Best:  340.08 | Length: 3849
Episode 2700 | Reward:  279.98 | Running Avg:  213.14 | Best:  340.08 | Length: 4231
  ✓ Collision epoch 13 saved
Episode 2800 | Reward:  239.84 | Running Avg:  222.54 | Best:  340.08 | Length: 3690
Episode 2900 | Reward:  219.92 | Running Avg:  230.25 | Best:  360.12 | Length: 4319
  ✓ Collision epoch 14 saved
Episode 3000 | Reward:  259.96 | Running Avg:  229.77 | Best:  360.12 | Length: 4185
Episode 3100 | Reward:  199.94 | Running Avg:  239.30 | Best:  360.12 | Length: 3877
  ✓ Collision epoch 15 saved
Episode 3200 | Reward:  260.06 | Running Avg:  234.00 | Best:  360.12 | Length: 4522
Episode 3300 | Reward:  239.90 | Running Avg:  237.83 | Best:  360.12 | Length: 4089
  ✓ Collision epoch 16 saved
Episode 3400 | Reward:  280.04 | Running Avg:  248.24 | Best:  360.12 | Length: 4490
Episode 3500 | Reward:  279.96 | Running Avg:  255.65 | Best:  360.12 | Length: 4357
  ✓ Collision epoch 17 saved
Episode 3600 | Reward:  259.98 | Running Avg:  256.21 | Best:  360.12 | Length: 4456
Episode 3700 | Reward:  340.04 | Running Avg:  262.39 | Best:  360.12 | Length: 4476
  ✓ Collision epoch 18 saved
Episode 3800 | Reward:  299.90 | Running Avg:  266.24 | Best:  360.12 | Length: 4273
Episode 3900 | Reward:  319.96 | Running Avg:  267.50 | Best:  360.12 | Length: 4230
  ✓ Collision epoch 19 saved
Episode 4000 | Reward:  280.04 | Running Avg:  304.26 | Best: 5401.06 | Length: 4282
Episode 4100 | Reward:  280.06 | Running Avg:  294.73 | Best: 5401.06 | Length: 4433
  ✓ Collision epoch 20 saved
Episode 4200 | Reward:  340.00 | Running Avg:  293.75 | Best: 5401.06 | Length: 4343
Episode 4300 | Reward:  259.92 | Running Avg:  292.64 | Best: 5401.06 | Length: 4066
  ✓ Collision epoch 21 saved
Episode 4400 | Reward:  279.94 | Running Avg:  322.54 | Best: 5401.06 | Length: 4163
Episode 4500 | Reward:  279.92 | Running Avg:  313.19 | Best: 5401.06 | Length: 4305
  ✓ Collision epoch 22 saved
Episode 4600 | Reward:  360.04 | Running Avg:  309.99 | Best: 5401.06 | Length: 4509
Episode 4700 | Reward:  319.98 | Running Avg:  372.11 | Best: 5401.06 | Length: 4300
  ✓ Collision epoch 23 saved
Episode 4800 | Reward:  320.08 | Running Avg:  374.51 | Best: 5401.06 | Length: 4500
Episode 4900 | Reward:  360.00 | Running Avg:  381.24 | Best: 5401.08 | Length: 4381
  ✓ Collision epoch 24 saved
Episode 5000 | Reward:  359.98 | Running Avg:  362.50 | Best: 5401.08 | Length: 4443
Episode 5100 | Reward:  359.98 | Running Avg:  334.93 | Best: 5401.08 | Length: 4313
  ✓ Collision epoch 25 saved
Episode 5200 | Reward:  339.98 | Running Avg:  379.92 | Best: 5401.08 | Length: 4344
Episode 5300 | Reward:  340.06 | Running Avg:  437.23 | Best: 5401.10 | Length: 4541
  ✓ Collision epoch 26 saved
Episode 5400 | Reward:  300.12 | Running Avg:  392.86 | Best: 5401.10 | Length: 4595
Episode 5500 | Reward:  300.08 | Running Avg:  379.56 | Best: 5401.10 | Length: 4391
  ✓ Collision epoch 27 saved
Episode 5600 | Reward:  260.12 | Running Avg:  457.14 | Best: 5401.10 | Length: 4782
Episode 5700 | Reward:  259.96 | Running Avg:  465.45 | Best: 5401.10 | Length: 4199
  ✓ Collision epoch 28 saved
Episode 5800 | Reward:  380.00 | Running Avg:  514.64 | Best: 5401.10 | Length: 4487
Episode 5900 | Reward:  359.98 | Running Avg:  602.19 | Best: 5401.12 | Length: 4448
  ✓ Collision epoch 29 saved
Episode 6000 | Reward:  380.10 | Running Avg:  662.71 | Best: 5401.14 | Length: 4617
Episode 6100 | Reward:  360.02 | Running Avg:  507.11 | Best: 5401.14 | Length: 4382
  ✓ Collision epoch 30 saved
Episode 6200 | Reward:  339.96 | Running Avg:  598.66 | Best: 5401.16 | Length: 4345
Episode 6300 | Reward:  359.98 | Running Avg:  577.31 | Best: 5401.16 | Length: 4448
  ✓ Collision epoch 31 saved
Episode 6400 | Reward:  360.00 | Running Avg:  705.81 | Best: 5401.16 | Length: 4447
Episode 6500 | Reward:  320.08 | Running Avg:  477.88 | Best: 5401.16 | Length: 4429
  ✓ Collision epoch 32 saved
Episode 6600 | Reward:  380.00 | Running Avg:  608.72 | Best: 5401.16 | Length: 4416
Episode 6700 | Reward:  359.94 | Running Avg:  661.26 | Best: 5401.16 | Length: 4521
  ✓ Collision epoch 33 saved
Episode 6800 | Reward:  339.88 | Running Avg:  935.65 | Best: 5401.16 | Length: 4214
Episode 6900 | Reward:  380.06 | Running Avg:  806.10 | Best: 5401.16 | Length: 4619
  ✓ Collision epoch 34 saved
Episode 7000 | Reward:  339.98 | Running Avg:  764.33 | Best: 5401.16 | Length: 4550
Episode 7100 | Reward:  359.96 | Running Avg:  654.51 | Best: 5401.16 | Length: 4312
  ✓ Collision epoch 35 saved
Episode 7200 | Reward: 5401.08 | Running Avg:  972.19 | Best: 5401.16 | Length: 4541
Episode 7300 | Reward:  360.00 | Running Avg:  901.94 | Best: 5401.16 | Length: 4312
  ✓ Collision epoch 36 saved
Episode 7400 | Reward:  339.96 | Running Avg:  911.52 | Best: 5401.16 | Length: 4480
Episode 7500 | Reward:  359.96 | Running Avg:  850.94 | Best: 5401.16 | Length: 4314
  ✓ Collision epoch 37 saved
Episode 7600 | Reward:  359.94 | Running Avg:  879.79 | Best: 5401.18 | Length: 4315
Episode 7700 | Reward:  360.04 | Running Avg:  852.99 | Best: 5401.18 | Length: 4646
  ✓ Collision epoch 38 saved
Episode 7800 | Reward:  320.04 | Running Avg:  704.31 | Best: 5401.18 | Length: 4237
Episode 7900 | Reward:  340.04 | Running Avg:  797.90 | Best: 5401.18 | Length: 4403
  ✓ Collision epoch 39 saved
Episode 8000 | Reward:  380.04 | Running Avg:  993.96 | Best: 5401.18 | Length: 4485
Episode 8100 | Reward:  380.08 | Running Avg: 1015.73 | Best: 5401.18 | Length: 4412
  ✓ Collision epoch 40 saved
Episode 8200 | Reward:  319.92 | Running Avg:  952.22 | Best: 5401.18 | Length: 4243
Episode 8300 | Reward:  339.96 | Running Avg: 1051.54 | Best: 5401.18 | Length: 4208
  ✓ Collision epoch 41 saved
Episode 8400 | Reward:  360.04 | Running Avg:  969.72 | Best: 5401.18 | Length: 4445
Episode 8500 | Reward:  319.98 | Running Avg: 1061.71 | Best: 5401.18 | Length: 4240
  ✓ Collision epoch 42 saved
Episode 8600 | Reward: 5401.00 | Running Avg:  963.36 | Best: 5401.18 | Length: 4545
Episode 8700 | Reward:  380.08 | Running Avg:  851.72 | Best: 5401.18 | Length: 4483
  ✓ Collision epoch 43 saved
Episode 8800 | Reward:  380.02 | Running Avg:  961.97 | Best: 5401.18 | Length: 4415
Episode 8900 | Reward:  360.08 | Running Avg:  858.11 | Best: 5401.18 | Length: 4452
  ✓ Collision epoch 44 saved
Episode 9000 | Reward:  320.02 | Running Avg:  948.25 | Best: 5401.18 | Length: 4238
Episode 9100 | Reward:  339.98 | Running Avg:  896.66 | Best: 5401.18 | Length: 4280
  ✓ Collision epoch 45 saved
Episode 9200 | Reward:  380.06 | Running Avg:  950.85 | Best: 5401.18 | Length: 4619
Episode 9300 | Reward:  319.92 | Running Avg: 1042.59 | Best: 5401.18 | Length: 4108
  ✓ Collision epoch 46 saved
Episode 9400 | Reward:  359.96 | Running Avg: 1171.54 | Best: 5401.18 | Length: 4444
Episode 9500 | Reward:  380.06 | Running Avg: 1122.78 | Best: 5401.18 | Length: 4619
  ✓ Collision epoch 47 saved
Episode 9600 | Reward:  339.96 | Running Avg: 1589.96 | Best: 5401.18 | Length: 4480
Episode 9700 | Reward:  359.94 | Running Avg: 1300.86 | Best: 5401.18 | Length: 4315
  ✓ Collision epoch 48 saved
Episode 9800 | Reward:  360.06 | Running Avg: 1281.65 | Best: 5401.18 | Length: 4444
Episode 9900 | Reward:  380.04 | Running Avg: 1355.22 | Best: 5401.18 | Length: 4414
  ✓ Collision epoch 49 saved
Episode 10000 | Reward:  359.96 | Running Avg: 1467.73 | Best: 5401.18 | Length: 4314
Episode 10100 | Reward:  379.94 | Running Avg: 1476.18 | Best: 5401.18 | Length: 4419
  ✓ Collision epoch 50 saved
Episode 10200 | Reward:  339.96 | Running Avg: 1235.04 | Best: 5401.18 | Length: 4208
Episode 10300 | Reward:  299.94 | Running Avg: 1290.85 | Best: 5401.18 | Length: 4003
  ✓ Collision epoch 51 saved
Episode 10400 | Reward:  360.06 | Running Avg: 1424.99 | Best: 5401.18 | Length: 4444
Episode 10500 | Reward:  360.10 | Running Avg: 1432.27 | Best: 5401.18 | Length: 4442
  ✓ Collision epoch 52 saved
Episode 10600 | Reward:  379.98 | Running Avg: 1330.19 | Best: 5401.18 | Length: 4486
Episode 10700 | Reward:  380.00 | Running Avg: 1413.68 | Best: 5401.18 | Length: 4416
  ✓ Collision epoch 53 saved
Episode 10800 | Reward:  360.02 | Running Avg: 1343.73 | Best: 5401.18 | Length: 4311
Episode 10900 | Reward:  380.04 | Running Avg: 1377.42 | Best: 5401.18 | Length: 4620
  ✓ Collision epoch 54 saved
Episode 11000 | Reward:  380.08 | Running Avg: 1746.94 | Best: 5401.18 | Length: 4412
Episode 11100 | Reward: 5401.04 | Running Avg: 1327.58 | Best: 5401.18 | Length: 4543
  ✓ Collision epoch 55 saved
Episode 11200 | Reward:  380.02 | Running Avg: 1088.49 | Best: 5401.18 | Length: 4415
Episode 11300 | Reward:  380.06 | Running Avg: 1106.58 | Best: 5401.18 | Length: 4484
  ✓ Collision epoch 56 saved
Episode 11400 | Reward:  379.98 | Running Avg: 1128.17 | Best: 5401.18 | Length: 4417
Episode 11500 | Reward:  379.98 | Running Avg: 1209.31 | Best: 5401.18 | Length: 4417
  ✓ Collision epoch 57 saved
Episode 11600 | Reward:  340.04 | Running Avg: 1158.85 | Best: 5401.18 | Length: 4412
Episode 11700 | Reward:  380.08 | Running Avg: 1482.56 | Best: 5401.18 | Length: 4618
  ✓ Collision epoch 58 saved
Episode 11800 | Reward:  360.00 | Running Avg: 1351.41 | Best: 5401.18 | Length: 4447
Episode 11900 | Reward:  339.98 | Running Avg: 1522.62 | Best: 5401.18 | Length: 4342
  ✓ Collision epoch 59 saved
Episode 12000 | Reward: 5401.08 | Running Avg: 1479.19 | Best: 5401.18 | Length: 4541
Episode 12100 | Reward:  360.08 | Running Avg: 1407.95 | Best: 5401.18 | Length: 4438
  ✓ Collision epoch 60 saved
Episode 12200 | Reward: 5401.08 | Running Avg: 1288.52 | Best: 5401.18 | Length: 4541
Episode 12300 | Reward:  359.96 | Running Avg: 1577.87 | Best: 5401.18 | Length: 4449
  ✓ Collision epoch 61 saved
Episode 12400 | Reward: 5401.04 | Running Avg: 1552.68 | Best: 5401.18 | Length: 4543
Episode 12500 | Reward: 5401.06 | Running Avg: 1809.23 | Best: 5401.18 | Length: 4542
  ✓ Collision epoch 62 saved
Episode 12600 | Reward: 5401.08 | Running Avg: 1765.10 | Best: 5401.18 | Length: 4541
Episode 12700 | Reward:  380.02 | Running Avg: 1481.83 | Best: 5401.18 | Length: 4415
  ✓ Collision epoch 63 saved
Episode 12800 | Reward: 5401.02 | Running Avg: 1495.00 | Best: 5401.18 | Length: 4544
Episode 12900 | Reward: 5401.02 | Running Avg: 1750.55 | Best: 5401.18 | Length: 4544
  ✓ Collision epoch 64 saved
Episode 13000 | Reward:  380.10 | Running Avg: 1856.06 | Best: 5401.18 | Length: 4617
Episode 13100 | Reward:  380.06 | Running Avg: 1805.36 | Best: 5401.18 | Length: 4482
  ✓ Collision epoch 65 saved
Episode 13200 | Reward:  339.92 | Running Avg: 1537.73 | Best: 5401.18 | Length: 4281
Episode 13300 | Reward:  339.94 | Running Avg: 1423.37 | Best: 5401.18 | Length: 4417
  ✓ Collision epoch 66 saved
Episode 13400 | Reward: 5401.00 | Running Avg:  998.78 | Best: 5401.18 | Length: 4545
Episode 13500 | Reward:  359.88 | Running Avg:  778.15 | Best: 5401.18 | Length: 4318
  ✓ Collision epoch 67 saved
Episode 13600 | Reward:  340.00 | Running Avg:  969.83 | Best: 5401.18 | Length: 4343
Episode 13700 | Reward:  380.00 | Running Avg: 1111.49 | Best: 5401.20 | Length: 4622
  ✓ Collision epoch 68 saved
Episode 13800 | Reward:  380.00 | Running Avg:  883.88 | Best: 5401.20 | Length: 4622
Episode 13900 | Reward:  300.06 | Running Avg:  947.64 | Best: 5401.20 | Length: 4532
  ✓ Collision epoch 69 saved
Episode 14000 | Reward:  339.96 | Running Avg:  847.83 | Best: 5401.20 | Length: 4416
Episode 14100 | Reward:  359.94 | Running Avg:  879.90 | Best: 5401.20 | Length: 4313
  ✓ Collision epoch 70 saved
Episode 14200 | Reward: 5401.02 | Running Avg:  861.53 | Best: 5401.20 | Length: 4544
Episode 14300 | Reward:  380.00 | Running Avg: 1101.07 | Best: 5401.20 | Length: 4416
  ✓ Collision epoch 71 saved
Episode 14400 | Reward:  380.00 | Running Avg: 1221.16 | Best: 5401.20 | Length: 4416
Episode 14500 | Reward: 5401.02 | Running Avg: 1183.40 | Best: 5401.20 | Length: 4544
  ✓ Collision epoch 72 saved
Episode 14600 | Reward:  360.14 | Running Avg: 1252.68 | Best: 5401.20 | Length: 4641
Episode 14700 | Reward:  360.12 | Running Avg: 1238.95 | Best: 5401.20 | Length: 4436
  ✓ Collision epoch 73 saved
Episode 14800 | Reward: 5401.08 | Running Avg: 1272.20 | Best: 5401.20 | Length: 4541
Episode 14900 | Reward: 5401.12 | Running Avg: 1197.33 | Best: 5401.20 | Length: 4539
  ✓ Collision epoch 74 saved
Episode 15000 | Reward:  380.04 | Running Avg: 1191.96 | Best: 5401.20 | Length: 4414
Episode 15100 | Reward:  320.04 | Running Avg: 1216.83 | Best: 5401.20 | Length: 4502
  ✓ Collision epoch 75 saved
Episode 15200 | Reward:  380.00 | Running Avg: 1324.09 | Best: 5401.20 | Length: 4416
Episode 15300 | Reward:  319.96 | Running Avg: 1037.03 | Best: 5401.20 | Length: 4236
  ✓ Collision epoch 76 saved
Episode 15400 | Reward:  339.98 | Running Avg: 1299.29 | Best: 5401.20 | Length: 4538
Episode 15500 | Reward:  380.06 | Running Avg: 1214.91 | Best: 5401.20 | Length: 4619
  ✓ Collision epoch 77 saved
Episode 15600 | Reward:  379.96 | Running Avg: 1373.12 | Best: 5401.20 | Length: 4418
Episode 15700 | Reward:  360.02 | Running Avg: 1359.85 | Best: 5401.20 | Length: 4382
  ✓ Collision epoch 78 saved
Episode 15800 | Reward:  360.04 | Running Avg: 1259.91 | Best: 5401.20 | Length: 4435
Episode 15900 | Reward:  360.06 | Running Avg: 1628.89 | Best: 5401.20 | Length: 4444
  ✓ Collision epoch 79 saved
Episode 16000 | Reward:  380.00 | Running Avg: 1445.98 | Best: 5401.20 | Length: 4487
Episode 16100 | Reward:  359.98 | Running Avg: 1424.47 | Best: 5401.20 | Length: 4514
  ✓ Collision epoch 80 saved
Episode 16200 | Reward:  380.00 | Running Avg: 1305.77 | Best: 5401.20 | Length: 4416
Episode 16300 | Reward:  379.92 | Running Avg: 1563.07 | Best: 5401.20 | Length: 4420
  ✓ Collision epoch 81 saved
Episode 16400 | Reward:  380.10 | Running Avg: 1461.51 | Best: 5401.20 | Length: 4411
Episode 16500 | Reward:  340.16 | Running Avg: 1475.05 | Best: 5401.20 | Length: 4676
  ✓ Collision epoch 82 saved
Episode 16600 | Reward:  359.94 | Running Avg: 1516.40 | Best: 5401.20 | Length: 4450
Episode 16700 | Reward:  379.92 | Running Avg: 1293.18 | Best: 5401.20 | Length: 4420
  ✓ Collision epoch 83 saved
Episode 16800 | Reward: 5401.04 | Running Avg: 1699.00 | Best: 5401.20 | Length: 4543
Episode 16900 | Reward:  380.06 | Running Avg: 1385.75 | Best: 5401.20 | Length: 4413
  ✓ Collision epoch 84 saved
Episode 17000 | Reward:  380.02 | Running Avg: 1725.08 | Best: 5401.20 | Length: 4621
Episode 17100 | Reward: 5401.10 | Running Avg: 1532.78 | Best: 5401.20 | Length: 4540
  ✓ Collision epoch 85 saved
Episode 17200 | Reward: 5401.02 | Running Avg: 1835.62 | Best: 5401.20 | Length: 4544
Episode 17300 | Reward:  379.98 | Running Avg: 1585.33 | Best: 5401.20 | Length: 4417
  ✓ Collision epoch 86 saved
Episode 17400 | Reward: 5401.04 | Running Avg: 1662.57 | Best: 5401.20 | Length: 4543
Episode 17500 | Reward:  360.04 | Running Avg: 1884.36 | Best: 5401.20 | Length: 4511
  ✓ Collision epoch 87 saved
Episode 17600 | Reward:  379.94 | Running Avg: 1908.13 | Best: 5401.20 | Length: 4419
Episode 17700 | Reward:  380.02 | Running Avg: 1694.37 | Best: 5401.20 | Length: 4621
  ✓ Collision epoch 88 saved
Episode 17800 | Reward:  340.00 | Running Avg: 1433.47 | Best: 5401.20 | Length: 4414
Episode 17900 | Reward: 5401.04 | Running Avg: 1895.92 | Best: 5401.20 | Length: 4543
  ✓ Collision epoch 89 saved
Episode 18000 | Reward:  360.04 | Running Avg: 1836.89 | Best: 5401.20 | Length: 4445
Episode 18100 | Reward:  360.06 | Running Avg: 1508.57 | Best: 5401.20 | Length: 4439
  ✓ Collision epoch 90 saved
Episode 18200 | Reward: 5401.02 | Running Avg: 1438.63 | Best: 5401.20 | Length: 4544
Episode 18300 | Reward:  360.00 | Running Avg: 1669.74 | Best: 5401.20 | Length: 4312
  ✓ Collision epoch 91 saved
Episode 18400 | Reward: 5401.06 | Running Avg: 1747.01 | Best: 5401.20 | Length: 4542
Episode 18500 | Reward: 5400.98 | Running Avg: 1829.31 | Best: 5401.20 | Length: 4546
  ✓ Collision epoch 92 saved
Episode 18600 | Reward: 5401.10 | Running Avg: 2083.49 | Best: 5401.20 | Length: 4540
Episode 18700 | Reward:  379.96 | Running Avg: 1696.23 | Best: 5401.20 | Length: 4489
  ✓ Collision epoch 93 saved
Episode 18800 | Reward:  340.04 | Running Avg: 1495.49 | Best: 5401.20 | Length: 4476
Episode 18900 | Reward:  360.04 | Running Avg: 1416.07 | Best: 5401.20 | Length: 4308
  ✓ Collision epoch 94 saved
Episode 19000 | Reward:  379.92 | Running Avg: 1587.05 | Best: 5401.20 | Length: 4420
Episode 19100 | Reward:  340.04 | Running Avg: 1690.80 | Best: 5401.20 | Length: 4204
  ✓ Collision epoch 95 saved
Episode 19200 | Reward:  380.00 | Running Avg: 1433.57 | Best: 5401.20 | Length: 4622
Episode 19300 | Reward:  379.94 | Running Avg: 1552.84 | Best: 5401.20 | Length: 4419
  ✓ Collision epoch 96 saved
Episode 19400 | Reward:  360.02 | Running Avg: 1879.59 | Best: 5401.20 | Length: 4441
Episode 19500 | Reward:  379.98 | Running Avg: 2021.40 | Best: 5401.22 | Length: 4417
  ✓ Collision epoch 97 saved
Episode 19600 | Reward:  380.00 | Running Avg: 1972.95 | Best: 5401.22 | Length: 4416
Episode 19700 | Reward: 5401.10 | Running Avg: 1914.63 | Best: 5401.22 | Length: 4540
  ✓ Collision epoch 98 saved
Episode 19800 | Reward: 5400.96 | Running Avg: 1994.70 | Best: 5401.22 | Length: 4547
Episode 19900 | Reward: 5401.14 | Running Avg: 1843.41 | Best: 5401.22 | Length: 4538
  ✓ Collision epoch 99 saved
Episode 20000 | Reward: 5401.04 | Running Avg: 2124.66 | Best: 5401.22 | Length: 4543

============================================================
TRAINING COMPLETE
Final Running Average: 2124.66
Best Episode Reward: 5401.22
Total collision epochs: 100
============================================================


✓ Logging training data to analytics...

✓ Evaluating...

============================================================
EVALUATING TRAINED AGENT (10 episodes)
============================================================

Eval Episode  1: Reward= 380.00, Player=20, CPU=21, Length=4416
Eval Episode  2: Reward= 380.10, Player=20, CPU=21, Length=4612
Eval Episode  3: Reward=5400.98, Player=21, CPU=20, Length=4546
Eval Episode  4: Reward=5401.02, Player=21, CPU=20, Length=4544
Eval Episode  5: Reward=5401.12, Player=21, CPU=20, Length=4539
Eval Episode  6: Reward=5401.02, Player=21, CPU=20, Length=4544
Eval Episode  7: Reward=5401.12, Player=21, CPU=20, Length=4539
Eval Episode  8: Reward= 380.02, Player=20, CPU=21, Length=4415
Eval Episode  9: Reward= 379.96, Player=20, CPU=21, Length=4487
Eval Episode 10: Reward=5401.04, Player=21, CPU=20, Length=4543

============================================================
Mean Reward: 3392.64 ± 2459.79
Reward Range: [379.96, 5401.12]
Win Rate: 60.0%
Mean Episode Length: 4518 steps
============================================================


✓ Logging evaluation data to analytics...

✓ Saving current model to models\exp_05.npz...
✓ Agent parameters saved to 'models\exp_05.npz'
✓ Saving timestamped backup to outputs\exp_05_20251208_124350\saved_models\exp_05_20251208_124350.npz...
✓ Agent parameters saved to 'outputs\exp_05_20251208_124350\saved_models\exp_05_20251208_124350.npz'

✓ Saving configuration to outputs\exp_05_20251208_124350\saved_models\exp_05_20251208_124350_config.json...

✓ Saving analytics summary...

✓ Summary saved to outputs\exp_05_20251208_124350\recorded_data\20251208_124350_summary.txt
============================================================
TRAINING SUMMARY
============================================================
Timestamp: 20251208_124350

TRAINING RESULTS
------------------------------------------------------------
Total episodes trained: 20000
Final running average reward: 2720.69
Best episode reward: 5401.22
Worst episode reward: -20.60
Mean episode reward: 989.07
Std episode reward: 1734.22

EVALUATION METRICS
------------------------------------------------------------
Win rate: 13.4%
Total wins: 2670 / 20000
Mean episode length: 4375 steps
Mean player score: 17.1
Mean CPU score: 20.9

REWARD COMPONENTS (Average)
------------------------------------------------------------
Score reward: +343.85
Hit reward: +0.9930
Loss penalty: -20.87

ACTION DISTRIBUTION
------------------------------------------------------------
N/A

HYPERPARAMETERS
------------------------------------------------------------
timestamp: 20251208_124350
experiment_name: exp_05
continued_from_episode: 0
environment: {'width': 160, 'height': 192, 'max_score': 21, 'cpu_difficulty': 'medium'}
agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
training: {'max_episodes': 20000, 'batch_size': 5, 'running_reward_decay': 0.99, 'print_frequency': 100}
rewards: {'ball_hit': 0.02, 'score': 20.0, 'opponent_score': -1.0, 'win': 5000.0, 'loss': -0.0}
training_results: {'final_running_average': 2124.658101585911, 'best_episode_reward': 5401.219999999999, 'total_episodes_trained': 20000, 'total_episodes_cumulative': 20000}
evaluation_results: {'mean_reward': 3392.638, 'std_reward': 2459.7922971901507, 'win_rate': 0.6, 'eval_episodes': 10}
heatmap_data: {'recording_enabled': False, 'heatmap_file': None, 'epochs_collected': 0}
collision_data: {'recording_enabled': True, 'epochs_collected': 100, 'total_collisions': 547671}

============================================================

✓ Generating analytics visualizations...

✓ Generating plots...
Warning: Skipping action distribution plot. No action data was logged during training/evaluation.
✓ All plots saved to outputs\exp_05_20251208_124350\recorded_data/ with prefix 20251208_124350

✓ Saving collision analysis to outputs\exp_05_20251208_124350\recorded_data\collision_analysis...
======================================================================
PADDLE COLLISION ANALYSIS REPORT
======================================================================

SUMMARY STATISTICS
----------------------------------------------------------------------
Total Epochs Analyzed: 100
Total Collisions Recorded: 547671

EDGE HIT PROGRESSION
----------------------------------------------------------------------
Initial Edge Hit Rate: 60.9%
Final Edge Hit Rate: 99.5%
Improvement: +38.6 percentage points

BOUNCE ANGLE PROGRESSION
----------------------------------------------------------------------
Initial Average Angle: 44.8°
Final Average Angle: 62.2°
Improvement: +17.4°

INTERPRETATION
----------------------------------------------------------------------
Edge hits increased from 60.9% to 99.5%, demonstrating the agent
learned to exploit the progressive angle system. Higher edge hit rates
produce steeper bounce angles, making returns harder to defend.

Average bounce angle increased from 44.8° to
62.2°, confirming strategic use of steep
trajectories for offensive advantage.

======================================================================

✓ Report saved to outputs\exp_05_20251208_124350\recorded_data\collision_analysis\collision_report.txt

✓ Generating collision analysis figures...
  ✓ Figure 1 saved: figure_1_collision_distribution.png
  ✓ Figure 2 saved: figure_2_angle_progression.png
  ✓ Figure 3 saved: figure_3_edge_hit_progression.png
✓ All figures saved to outputs\exp_05_20251208_124350\recorded_data\collision_analysis/
  ✓ Summary CSV: collision_summary.csv
  ✓ Distribution CSV: collision_distribution.csv
  Total CSV files: 2
✓ Collision analysis complete!
  Location: outputs\exp_05_20251208_124350\recorded_data\collision_analysis/

======================================================================
TRAINING COMPLETE
Total Training Time: 6:03:48.402250
======================================================================

✓ All results saved to: outputs\exp_05_20251208_124350/

  Models (outputs\exp_05_20251208_124350\saved_models/):
    - Model: exp_05_20251208_124350.npz
    - Config: exp_05_20251208_124350_config.json
    - Log: exp_05_20251208_124350.log

  Analytics (outputs\exp_05_20251208_124350\recorded_data/):
    - Training CSV: 20251208_124350.csv
    - Evaluation CSV: 20251208_124350_eval.csv
    - Summary: 20251208_124350_summary.txt
    - Plots (10): 20251208_124350_0*.png

  Collision Analysis (outputs\exp_05_20251208_124350\recorded_data\collision_analysis/):
    - Report: collision_report.txt
    - Statistics: collision_statistics.json
    - Figures: figure_1_collision_distribution.png
    - Figures: figure_2_angle_progression.png
    - Figures: figure_3_edge_hit_progression.png
    - Total Collisions: 547,671
    - Edge Hit Rate: 60.9% → 99.5%
    - Avg Angle: 44.8° → 62.2°
======================================================================


======================================================================
TRAINING COMPLETE
======================================================================

✓ Results saved to: outputs\exp_05_20251208_124350/
  - Model: model.npz
  - Config: config_used.json
  - Metrics: training.csv, evaluation.csv
  - Heatmap: heatmap.json
  - Log: training.log

======================================================================
INITIALIZING TRAINING COMPONENTS
======================================================================

✓ Creating environment...
  Court: 160×192
  Paddle: 2×12
  CPU Difficulty: medium

✓ Creating agent (PolicyGradient)...
  Input Size: 16
  Hidden Size: 128
  Output Size: 3
  Learning Rate: 0.0015
  Discount Factor: 0.99

✓ Creating trainer (PolicyGradient)...
  Max Episodes: 20000
  Batch Size: 5
  Running Reward Decay: 0.99

✓ Creating heatmap recorder...
  Grid Resolution: 20×24
  Court Size: 160×192

✓ Creating training orchestrator...
  Experiment: exp_06
  Orchestrator will handle:
    - Training pipeline
    - Analytics logging
    - Heatmap recording
    - Model evaluation
    - Automatic saving
✓ Analytics initialized
  Timestamp: 20251209_184533
  Output dir: outputs\exp_06_20251209_184533\recorded_data
  All files saved as: 20251209_184533*

✓ Found existing training data: outputs\exp_06_20251209_184533\recorded_data\20251209_184533.csv
  Continuing from previous run...

======================================================================
STARTING TRAINING
======================================================================

======================================================================
TRAINING ORCHESTRATOR - UNIFIED PIPELINE
======================================================================
Experiment: exp_06
Timestamp: 20251209_184533
Output Root Directory: outputs\exp_06_20251209_184533/
Output Sub-Directories:
  - Models: outputs\exp_06_20251209_184533\saved_models/
  - Analytics: outputs\exp_06_20251209_184533\recorded_data/
  - Collision Analysis: outputs\exp_06_20251209_184533\recorded_data\collision_analysis/
Heatmap Recording: ✗ DISABLED
Collision Analysis: ✓ ENABLED

✓ Starting trainer...

============================================================
TRAINING PONG AGENT
============================================================
Agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
Learning Rate: 0.0015
Discount Factor: 0.99
Max Episodes: 20000
RMSprop Decay: 0.99
Running Reward Decay: 0.99
Reward Structure: Score=20.0, Hit=0.02, Loss=-1.0
Win Reward: 5000.0, Loss Penalty: -0.0
Heatmap Recording: DISABLED
Collision Analysis: ENABLED
Episodes per collision epoch: 200
============================================================

Episode  100 | Reward:  -20.40 | Running Avg:   -7.77 | Best:   39.62 | Length: 3006
  ✓ Collision epoch 0 saved
Episode  200 | Reward:  -20.22 | Running Avg:   -6.58 | Best:   59.68 | Length: 3615
Episode  300 | Reward:  -20.32 | Running Avg:   -1.48 | Best:   79.78 | Length: 3187
  ✓ Collision epoch 1 saved
Episode  400 | Reward:   19.88 | Running Avg:    7.83 | Best:  119.96 | Length: 3929
Episode  500 | Reward:   39.88 | Running Avg:   11.27 | Best:  119.96 | Length: 3836
  ✓ Collision epoch 2 saved
Episode  600 | Reward:    0.20 | Running Avg:   14.75 | Best:  119.96 | Length: 4887
Episode  700 | Reward:   39.96 | Running Avg:   15.77 | Best:  119.96 | Length: 4168
  ✓ Collision epoch 3 saved
Episode  800 | Reward:   19.86 | Running Avg:   23.18 | Best:  120.04 | Length: 3855
Episode  900 | Reward:   40.00 | Running Avg:   24.41 | Best:  120.04 | Length: 4431
  ✓ Collision epoch 4 saved
Episode 1000 | Reward:   20.16 | Running Avg:   26.72 | Best:  139.74 | Length: 4945
Episode 1100 | Reward:   -0.04 | Running Avg:   35.65 | Best:  139.74 | Length: 4182
  ✓ Collision epoch 5 saved
Episode 1200 | Reward:   -0.02 | Running Avg:   33.34 | Best:  139.98 | Length: 4230
Episode 1300 | Reward:   19.70 | Running Avg:   43.31 | Best:  140.06 | Length: 3362
  ✓ Collision epoch 6 saved
Episode 1400 | Reward:   99.92 | Running Avg:   53.88 | Best:  179.94 | Length: 4260
Episode 1500 | Reward:   99.98 | Running Avg:   55.77 | Best:  179.94 | Length: 4252
  ✓ Collision epoch 7 saved
Episode 1600 | Reward:   19.56 | Running Avg:   57.80 | Best:  179.94 | Length: 2888
Episode 1700 | Reward:   39.86 | Running Avg:   60.32 | Best:  179.94 | Length: 3784
  ✓ Collision epoch 8 saved
Episode 1800 | Reward:   39.82 | Running Avg:   67.34 | Best:  179.94 | Length: 3715
Episode 1900 | Reward:   19.92 | Running Avg:   66.26 | Best:  179.94 | Length: 4030
  ✓ Collision epoch 9 saved
Episode 2000 | Reward:   59.80 | Running Avg:   71.73 | Best:  179.94 | Length: 3729
Episode 2100 | Reward:   79.88 | Running Avg:   73.52 | Best:  179.94 | Length: 3927
  ✓ Collision epoch 10 saved
Episode 2200 | Reward:   20.06 | Running Avg:   80.59 | Best:  179.94 | Length: 4598
Episode 2300 | Reward:  119.90 | Running Avg:   82.77 | Best:  179.94 | Length: 4055
  ✓ Collision epoch 11 saved
Episode 2400 | Reward:   99.94 | Running Avg:   88.85 | Best:  179.94 | Length: 4100
Episode 2500 | Reward:   40.06 | Running Avg:   98.90 | Best:  199.90 | Length: 4534
  ✓ Collision epoch 12 saved
Episode 2600 | Reward:  200.02 | Running Avg:   97.98 | Best:  200.02 | Length: 4284
Episode 2700 | Reward:   19.90 | Running Avg:  101.58 | Best:  200.02 | Length: 4042
  ✓ Collision epoch 13 saved
Episode 2800 | Reward:  119.96 | Running Avg:  103.51 | Best:  200.02 | Length: 4221
Episode 2900 | Reward:   99.82 | Running Avg:  103.34 | Best:  200.02 | Length: 3916
  ✓ Collision epoch 14 saved
Episode 3000 | Reward:  119.96 | Running Avg:  102.58 | Best:  200.02 | Length: 4195
Episode 3100 | Reward:  119.84 | Running Avg:  101.76 | Best:  200.02 | Length: 3866
  ✓ Collision epoch 15 saved
Episode 3200 | Reward:  140.20 | Running Avg:  103.35 | Best:  200.06 | Length: 4923
Episode 3300 | Reward:   59.78 | Running Avg:  105.31 | Best:  200.06 | Length: 3554
  ✓ Collision epoch 16 saved
Episode 3400 | Reward:  120.00 | Running Avg:  113.74 | Best:  240.08 | Length: 4362
Episode 3500 | Reward:   59.86 | Running Avg:  122.59 | Best:  240.08 | Length: 3914
  ✓ Collision epoch 17 saved
Episode 3600 | Reward:  139.72 | Running Avg:  128.80 | Best:  259.90 | Length: 3435
Episode 3700 | Reward:   59.84 | Running Avg:  127.03 | Best:  259.90 | Length: 3821
  ✓ Collision epoch 18 saved
Episode 3800 | Reward:   80.00 | Running Avg:  127.10 | Best:  259.90 | Length: 4445
Episode 3900 | Reward:   99.90 | Running Avg:  131.56 | Best:  259.90 | Length: 3972
  ✓ Collision epoch 19 saved
Episode 4000 | Reward:   79.98 | Running Avg:  137.09 | Best:  259.90 | Length: 4193
Episode 4100 | Reward:  159.96 | Running Avg:  141.07 | Best:  260.00 | Length: 4070
  ✓ Collision epoch 20 saved
Episode 4200 | Reward:  159.92 | Running Avg:  145.39 | Best:  299.94 | Length: 4107
Episode 4300 | Reward:  139.94 | Running Avg:  143.31 | Best:  299.94 | Length: 4300
  ✓ Collision epoch 21 saved
Episode 4400 | Reward:  179.92 | Running Avg:  141.21 | Best:  300.00 | Length: 4166
Episode 4500 | Reward:  119.84 | Running Avg:  146.13 | Best:  300.00 | Length: 3891
  ✓ Collision epoch 22 saved
Episode 4600 | Reward:  120.06 | Running Avg:  147.12 | Best:  300.00 | Length: 4540
Episode 4700 | Reward:  199.92 | Running Avg:  159.94 | Best:  300.00 | Length: 4209
  ✓ Collision epoch 23 saved
Episode 4800 | Reward:  239.82 | Running Avg:  168.33 | Best:  300.00 | Length: 3958
Episode 4900 | Reward:  199.94 | Running Avg:  166.41 | Best:  300.00 | Length: 4139
  ✓ Collision epoch 24 saved
Episode 5000 | Reward:  219.84 | Running Avg:  172.47 | Best:  300.00 | Length: 3920
Episode 5100 | Reward:  199.88 | Running Avg:  175.00 | Best:  319.90 | Length: 4086
  ✓ Collision epoch 25 saved
Episode 5200 | Reward:  159.90 | Running Avg:  182.34 | Best:  319.90 | Length: 4053
Episode 5300 | Reward:  119.72 | Running Avg:  180.57 | Best:  319.90 | Length: 3471
  ✓ Collision epoch 26 saved
Episode 5400 | Reward:  240.06 | Running Avg:  193.34 | Best:  319.90 | Length: 4676
Episode 5500 | Reward:  180.04 | Running Avg:  200.44 | Best:  340.02 | Length: 4502
  ✓ Collision epoch 27 saved
Episode 5600 | Reward:  220.00 | Running Avg:  193.64 | Best:  340.02 | Length: 4180
Episode 5700 | Reward:  119.82 | Running Avg:  194.13 | Best:  340.08 | Length: 3648
  ✓ Collision epoch 28 saved
Episode 5800 | Reward:  259.90 | Running Avg:  208.54 | Best:  340.08 | Length: 4183
Episode 5900 | Reward:  139.84 | Running Avg:  205.74 | Best:  340.08 | Length: 3906
  ✓ Collision epoch 29 saved
Episode 6000 | Reward:  139.86 | Running Avg:  202.01 | Best:  340.08 | Length: 3957
Episode 6100 | Reward:  199.86 | Running Avg:  209.07 | Best:  340.08 | Length: 3888
  ✓ Collision epoch 30 saved
Episode 6200 | Reward:  199.78 | Running Avg:  210.82 | Best:  340.08 | Length: 3615
Episode 6300 | Reward:  239.88 | Running Avg:  219.59 | Best:  340.08 | Length: 4015
  ✓ Collision epoch 31 saved
Episode 6400 | Reward:  159.92 | Running Avg:  214.05 | Best:  340.08 | Length: 3922
Episode 6500 | Reward:  100.02 | Running Avg:  217.80 | Best:  340.08 | Length: 4349
  ✓ Collision epoch 32 saved
Episode 6600 | Reward:  239.94 | Running Avg:  227.10 | Best:  340.08 | Length: 4207
Episode 6700 | Reward:  239.86 | Running Avg:  249.39 | Best: 5401.08 | Length: 4020
  ✓ Collision epoch 33 saved
Episode 6800 | Reward:  179.92 | Running Avg:  235.21 | Best: 5401.08 | Length: 4108
Episode 6900 | Reward:  219.90 | Running Avg:  236.28 | Best: 5401.08 | Length: 3917
  ✓ Collision epoch 34 saved
Episode 7000 | Reward:  239.94 | Running Avg:  240.02 | Best: 5401.08 | Length: 4154
Episode 7100 | Reward:  259.96 | Running Avg:  236.34 | Best: 5401.08 | Length: 4194
  ✓ Collision epoch 35 saved
Episode 7200 | Reward:  279.98 | Running Avg:  239.26 | Best: 5401.08 | Length: 4163
Episode 7300 | Reward:  299.96 | Running Avg:  244.99 | Best: 5401.08 | Length: 4201
  ✓ Collision epoch 36 saved
Episode 7400 | Reward:  219.90 | Running Avg:  246.87 | Best: 5401.08 | Length: 4044
Episode 7500 | Reward:  239.90 | Running Avg:  244.15 | Best: 5401.08 | Length: 4091
  ✓ Collision epoch 37 saved
Episode 7600 | Reward:  279.94 | Running Avg:  244.72 | Best: 5401.08 | Length: 4229
Episode 7700 | Reward:  179.76 | Running Avg:  244.83 | Best: 5401.08 | Length: 3639
  ✓ Collision epoch 38 saved
Episode 7800 | Reward:  239.92 | Running Avg:  240.58 | Best: 5401.08 | Length: 3890
Episode 7900 | Reward:  199.98 | Running Avg:  251.59 | Best: 5401.08 | Length: 4352
  ✓ Collision epoch 39 saved
Episode 8000 | Reward:  180.00 | Running Avg:  255.37 | Best: 5401.08 | Length: 4240
Episode 8100 | Reward:  220.00 | Running Avg:  258.45 | Best: 5401.08 | Length: 4188
  ✓ Collision epoch 40 saved
Episode 8200 | Reward:  319.94 | Running Avg:  264.12 | Best: 5401.08 | Length: 4372
Episode 8300 | Reward:  279.88 | Running Avg:  266.06 | Best: 5401.08 | Length: 4028
  ✓ Collision epoch 41 saved
Episode 8400 | Reward:  240.00 | Running Avg:  266.34 | Best: 5401.08 | Length: 4351
Episode 8500 | Reward:  280.00 | Running Avg:  277.80 | Best: 5401.08 | Length: 4159
  ✓ Collision epoch 42 saved
Episode 8600 | Reward:  239.92 | Running Avg:  284.99 | Best: 5401.08 | Length: 4366
Episode 8700 | Reward:  259.88 | Running Avg:  283.95 | Best: 5401.08 | Length: 3794
  ✓ Collision epoch 43 saved
Episode 8800 | Reward:  300.00 | Running Avg:  292.93 | Best: 5401.08 | Length: 4256
Episode 8900 | Reward:  319.98 | Running Avg:  302.31 | Best: 5401.08 | Length: 4446
  ✓ Collision epoch 44 saved
Episode 9000 | Reward:  379.96 | Running Avg:  297.26 | Best: 5401.08 | Length: 4418
Episode 9100 | Reward:  299.92 | Running Avg:  301.66 | Best: 5401.08 | Length: 4137
  ✓ Collision epoch 45 saved
Episode 9200 | Reward:  299.98 | Running Avg:  307.35 | Best: 5401.08 | Length: 4477
Episode 9300 | Reward:  339.90 | Running Avg:  336.00 | Best: 5401.08 | Length: 4213
  ✓ Collision epoch 46 saved
Episode 9400 | Reward:  360.00 | Running Avg:  362.90 | Best: 5401.08 | Length: 4447
Episode 9500 | Reward:  320.02 | Running Avg:  333.64 | Best: 5401.08 | Length: 4439
  ✓ Collision epoch 47 saved
Episode 9600 | Reward:  260.00 | Running Avg:  321.27 | Best: 5401.08 | Length: 4327
Episode 9700 | Reward:  360.00 | Running Avg:  312.18 | Best: 5401.08 | Length: 4381
  ✓ Collision epoch 48 saved
Episode 9800 | Reward:  319.94 | Running Avg:  309.43 | Best: 5401.08 | Length: 4101
Episode 9900 | Reward:  300.02 | Running Avg:  304.99 | Best: 5401.08 | Length: 4260
  ✓ Collision epoch 49 saved
Episode 10000 | Reward:  360.02 | Running Avg:  304.19 | Best: 5401.08 | Length: 4446
Episode 10100 | Reward:  259.94 | Running Avg:  307.12 | Best: 5401.08 | Length: 4134
  ✓ Collision epoch 50 saved
Episode 10200 | Reward:  360.10 | Running Avg:  351.47 | Best: 5401.10 | Length: 4638
Episode 10300 | Reward:  360.08 | Running Avg:  329.20 | Best: 5401.10 | Length: 4640
  ✓ Collision epoch 51 saved
Episode 10400 | Reward:  380.00 | Running Avg:  349.31 | Best: 5401.10 | Length: 4487
Episode 10500 | Reward:  360.02 | Running Avg:  332.37 | Best: 5401.10 | Length: 4515
  ✓ Collision epoch 52 saved
Episode 10600 | Reward:  339.92 | Running Avg:  350.41 | Best: 5401.10 | Length: 4279
Episode 10700 | Reward:  320.00 | Running Avg:  421.82 | Best: 5401.12 | Length: 4578
  ✓ Collision epoch 53 saved
Episode 10800 | Reward:  319.90 | Running Avg:  476.11 | Best: 5401.12 | Length: 4178
Episode 10900 | Reward:  340.00 | Running Avg:  381.19 | Best: 5401.12 | Length: 4343
  ✓ Collision epoch 54 saved
Episode 11000 | Reward:  279.90 | Running Avg:  391.33 | Best: 5401.12 | Length: 4034
Episode 11100 | Reward:  340.00 | Running Avg:  439.39 | Best: 5401.12 | Length: 4468
  ✓ Collision epoch 55 saved
Episode 11200 | Reward:  339.94 | Running Avg:  507.55 | Best: 5401.14 | Length: 4344
Episode 11300 | Reward:  339.94 | Running Avg:  425.42 | Best: 5401.14 | Length: 4209
  ✓ Collision epoch 56 saved
Episode 11400 | Reward:  319.80 | Running Avg:  584.02 | Best: 5401.14 | Length: 4242
Episode 11500 | Reward:  359.96 | Running Avg:  537.50 | Best: 5401.14 | Length: 4312
  ✓ Collision epoch 57 saved
Episode 11600 | Reward:  340.02 | Running Avg:  558.75 | Best: 5401.14 | Length: 4472
Episode 11700 | Reward:  360.04 | Running Avg:  497.48 | Best: 5401.14 | Length: 4514
  ✓ Collision epoch 58 saved
Episode 11800 | Reward:  339.98 | Running Avg:  545.98 | Best: 5401.14 | Length: 4474
Episode 11900 | Reward:  340.00 | Running Avg:  480.04 | Best: 5401.14 | Length: 4336
  ✓ Collision epoch 59 saved
Episode 12000 | Reward:  320.04 | Running Avg:  467.14 | Best: 5401.14 | Length: 4365
Episode 12100 | Reward:  299.92 | Running Avg:  510.24 | Best: 5401.14 | Length: 4069
  ✓ Collision epoch 60 saved
Episode 12200 | Reward:  360.04 | Running Avg:  508.17 | Best: 5401.14 | Length: 4445
Episode 12300 | Reward:  360.08 | Running Avg:  433.42 | Best: 5401.14 | Length: 4649
  ✓ Collision epoch 61 saved
Episode 12400 | Reward:  299.90 | Running Avg:  460.50 | Best: 5401.14 | Length: 4068
Episode 12500 | Reward:  359.94 | Running Avg:  451.85 | Best: 5401.14 | Length: 4313
  ✓ Collision epoch 62 saved
Episode 12600 | Reward:  359.96 | Running Avg:  425.29 | Best: 5401.14 | Length: 4520
Episode 12700 | Reward:  380.04 | Running Avg:  402.23 | Best: 5401.14 | Length: 4615
  ✓ Collision epoch 63 saved
Episode 12800 | Reward:  339.86 | Running Avg:  523.13 | Best: 5401.14 | Length: 4211
Episode 12900 | Reward:  319.90 | Running Avg:  579.84 | Best: 5401.14 | Length: 4372
  ✓ Collision epoch 64 saved
Episode 13000 | Reward:  319.98 | Running Avg:  650.50 | Best: 5401.14 | Length: 4307
Episode 13100 | Reward:  339.96 | Running Avg:  680.96 | Best: 5401.14 | Length: 4480
  ✓ Collision epoch 65 saved
Episode 13200 | Reward:  379.98 | Running Avg:  664.02 | Best: 5401.14 | Length: 4618
Episode 13300 | Reward:  339.92 | Running Avg:  630.45 | Best: 5401.14 | Length: 4212
  ✓ Collision epoch 66 saved
Episode 13400 | Reward:  319.92 | Running Avg:  676.32 | Best: 5401.14 | Length: 4366
Episode 13500 | Reward:  299.94 | Running Avg:  635.21 | Best: 5401.14 | Length: 3997
  ✓ Collision epoch 67 saved
Episode 13600 | Reward:  360.00 | Running Avg:  905.24 | Best: 5401.16 | Length: 4312
Episode 13700 | Reward:  339.92 | Running Avg:  655.59 | Best: 5401.16 | Length: 4208
  ✓ Collision epoch 68 saved
Episode 13800 | Reward:  320.00 | Running Avg:  539.69 | Best: 5401.16 | Length: 4491
Episode 13900 | Reward:  380.10 | Running Avg:  525.80 | Best: 5401.16 | Length: 4608
  ✓ Collision epoch 69 saved
Episode 14000 | Reward:  340.00 | Running Avg:  620.49 | Best: 5401.16 | Length: 4334
Episode 14100 | Reward:  339.88 | Running Avg:  517.33 | Best: 5401.16 | Length: 4214
  ✓ Collision epoch 70 saved
Episode 14200 | Reward:  299.90 | Running Avg:  432.27 | Best: 5401.16 | Length: 4129
Episode 14300 | Reward:  279.94 | Running Avg:  580.59 | Best: 5401.16 | Length: 4094
  ✓ Collision epoch 71 saved
Episode 14400 | Reward:  320.06 | Running Avg:  573.59 | Best: 5401.16 | Length: 4501
Episode 14500 | Reward:  279.90 | Running Avg:  509.36 | Best: 5401.16 | Length: 3964
  ✓ Collision epoch 72 saved
Episode 14600 | Reward:  300.06 | Running Avg:  484.43 | Best: 5401.16 | Length: 4589
Episode 14700 | Reward:  359.94 | Running Avg:  477.90 | Best: 5401.16 | Length: 4313
  ✓ Collision epoch 73 saved
Episode 14800 | Reward:  379.96 | Running Avg:  548.60 | Best: 5401.16 | Length: 4418
Episode 14900 | Reward:  299.98 | Running Avg:  456.87 | Best: 5401.16 | Length: 4064
  ✓ Collision epoch 74 saved
Episode 15000 | Reward:  319.92 | Running Avg:  510.20 | Best: 5401.16 | Length: 4106
Episode 15100 | Reward:  319.92 | Running Avg:  529.48 | Best: 5401.16 | Length: 4234
  ✓ Collision epoch 75 saved
Episode 15200 | Reward:  340.00 | Running Avg:  824.07 | Best: 5401.16 | Length: 4336
Episode 15300 | Reward:  339.98 | Running Avg:  596.45 | Best: 5401.16 | Length: 4479
  ✓ Collision epoch 76 saved
Episode 15400 | Reward:  300.12 | Running Avg:  559.30 | Best: 5401.16 | Length: 4730
Episode 15500 | Reward:  320.00 | Running Avg:  749.02 | Best: 5401.16 | Length: 4237
  ✓ Collision epoch 77 saved
Episode 15600 | Reward:  320.06 | Running Avg:  751.46 | Best: 5401.16 | Length: 4697
Episode 15700 | Reward:  380.00 | Running Avg: 1027.62 | Best: 5401.16 | Length: 4485
  ✓ Collision epoch 78 saved
Episode 15800 | Reward:  379.94 | Running Avg:  863.85 | Best: 5401.16 | Length: 4419
Episode 15900 | Reward: 5401.10 | Running Avg: 1096.96 | Best: 5401.16 | Length: 4540
  ✓ Collision epoch 79 saved
Episode 16000 | Reward:  380.04 | Running Avg:  972.85 | Best: 5401.16 | Length: 4620
Episode 16100 | Reward:  380.00 | Running Avg:  774.58 | Best: 5401.16 | Length: 4622
  ✓ Collision epoch 80 saved
Episode 16200 | Reward:  380.06 | Running Avg:  970.43 | Best: 5401.16 | Length: 4619
Episode 16300 | Reward:  320.10 | Running Avg:  966.90 | Best: 5401.16 | Length: 4438
  ✓ Collision epoch 81 saved
Episode 16400 | Reward:  359.98 | Running Avg:  735.29 | Best: 5401.16 | Length: 4443
Episode 16500 | Reward:  359.98 | Running Avg:  844.40 | Best: 5401.18 | Length: 4512
  ✓ Collision epoch 82 saved
Episode 16600 | Reward:  340.00 | Running Avg:  870.97 | Best: 5401.18 | Length: 4478
Episode 16700 | Reward:  359.98 | Running Avg:  866.24 | Best: 5401.18 | Length: 4439
  ✓ Collision epoch 83 saved
Episode 16800 | Reward:  380.00 | Running Avg:  817.80 | Best: 5401.18 | Length: 4416
Episode 16900 | Reward: 5401.00 | Running Avg:  741.63 | Best: 5401.18 | Length: 4545
  ✓ Collision epoch 84 saved
Episode 17000 | Reward:  380.08 | Running Avg:  802.29 | Best: 5401.20 | Length: 4481
Episode 17100 | Reward:  360.04 | Running Avg:  709.82 | Best: 5401.20 | Length: 4516
  ✓ Collision epoch 85 saved
Episode 17200 | Reward:  380.06 | Running Avg:  813.12 | Best: 5401.20 | Length: 4482
Episode 17300 | Reward:  339.98 | Running Avg:  949.24 | Best: 5401.20 | Length: 4278
  ✓ Collision epoch 86 saved
Episode 17400 | Reward:  380.00 | Running Avg:  947.66 | Best: 5401.20 | Length: 4487
Episode 17500 | Reward:  380.10 | Running Avg: 1255.50 | Best: 5401.20 | Length: 4411
  ✓ Collision epoch 87 saved
Episode 17600 | Reward:  380.10 | Running Avg:  957.90 | Best: 5401.20 | Length: 4411
Episode 17700 | Reward:  380.02 | Running Avg: 1049.10 | Best: 5401.20 | Length: 4415
  ✓ Collision epoch 88 saved
Episode 17800 | Reward:  339.98 | Running Avg: 1186.36 | Best: 5401.20 | Length: 4344
Episode 17900 | Reward:  380.10 | Running Avg: 1012.34 | Best: 5401.20 | Length: 4617
  ✓ Collision epoch 89 saved
Episode 18000 | Reward:  379.98 | Running Avg:  945.71 | Best: 5401.20 | Length: 4623
Episode 18100 | Reward:  339.96 | Running Avg: 1217.80 | Best: 5401.20 | Length: 4480
  ✓ Collision epoch 90 saved
Episode 18200 | Reward:  380.04 | Running Avg:  931.04 | Best: 5401.20 | Length: 4414
Episode 18300 | Reward:  379.98 | Running Avg:  952.01 | Best: 5401.20 | Length: 4417
  ✓ Collision epoch 91 saved
Episode 18400 | Reward:  360.00 | Running Avg:  872.10 | Best: 5401.20 | Length: 4447
Episode 18500 | Reward:  379.92 | Running Avg:  833.63 | Best: 5401.20 | Length: 4420
  ✓ Collision epoch 92 saved
Episode 18600 | Reward:  380.16 | Running Avg: 1142.42 | Best: 5401.20 | Length: 4609
Episode 18700 | Reward:  380.02 | Running Avg: 1064.97 | Best: 5401.20 | Length: 4621
  ✓ Collision epoch 93 saved
Episode 18800 | Reward:  380.04 | Running Avg:  947.29 | Best: 5401.20 | Length: 4414
Episode 18900 | Reward:  360.04 | Running Avg:  842.55 | Best: 5401.20 | Length: 4445
  ✓ Collision epoch 94 saved
Episode 19000 | Reward:  359.98 | Running Avg: 1047.98 | Best: 5401.20 | Length: 4382
Episode 19100 | Reward: 5401.02 | Running Avg:  907.36 | Best: 5401.20 | Length: 4544
  ✓ Collision epoch 95 saved
Episode 19200 | Reward:  380.06 | Running Avg: 1040.06 | Best: 5401.20 | Length: 4482
Episode 19300 | Reward:  339.96 | Running Avg: 1255.10 | Best: 5401.20 | Length: 4338
  ✓ Collision epoch 96 saved
Episode 19400 | Reward:  379.98 | Running Avg:  945.27 | Best: 5401.20 | Length: 4417
Episode 19500 | Reward:  380.00 | Running Avg:  945.42 | Best: 5401.20 | Length: 4416
  ✓ Collision epoch 97 saved
Episode 19600 | Reward:  360.00 | Running Avg:  891.43 | Best: 5401.20 | Length: 4310
Episode 19700 | Reward:  340.02 | Running Avg:  840.19 | Best: 5401.20 | Length: 4467
  ✓ Collision epoch 98 saved
Episode 19800 | Reward:  380.06 | Running Avg:  941.84 | Best: 5401.20 | Length: 4614
Episode 19900 | Reward:  359.98 | Running Avg:  876.58 | Best: 5401.20 | Length: 4443
  ✓ Collision epoch 99 saved
Episode 20000 | Reward:  279.78 | Running Avg:  736.81 | Best: 5401.20 | Length: 4042

============================================================
TRAINING COMPLETE
Final Running Average: 736.81
Best Episode Reward: 5401.20
Total collision epochs: 100
============================================================


✓ Logging training data to analytics...

✓ Evaluating...

============================================================
EVALUATING TRAINED AGENT (10 episodes)
============================================================

Eval Episode  1: Reward= 379.98, Player=20, CPU=21, Length=4488
Eval Episode  2: Reward= 380.08, Player=20, CPU=21, Length=4483
Eval Episode  3: Reward= 340.02, Player=18, CPU=21, Length=4413
Eval Episode  4: Reward= 319.96, Player=17, CPU=21, Length=4310
Eval Episode  5: Reward= 339.94, Player=18, CPU=21, Length=4209
Eval Episode  6: Reward= 339.98, Player=18, CPU=21, Length=4280
Eval Episode  7: Reward= 380.10, Player=20, CPU=21, Length=4617
Eval Episode  8: Reward= 360.00, Player=19, CPU=21, Length=4509
Eval Episode  9: Reward= 279.90, Player=15, CPU=21, Length=4036
Eval Episode 10: Reward= 380.02, Player=20, CPU=21, Length=4486

============================================================
Mean Reward: 350.00 ± 31.35
Reward Range: [279.90, 380.10]
Win Rate: 0.0%
Mean Episode Length: 4383 steps
============================================================


✓ Logging evaluation data to analytics...

✓ Saving current model to models\exp_06.npz...
✓ Agent parameters saved to 'models\exp_06.npz'
✓ Saving timestamped backup to outputs\exp_06_20251209_184533\saved_models\exp_06_20251209_184533.npz...
✓ Agent parameters saved to 'outputs\exp_06_20251209_184533\saved_models\exp_06_20251209_184533.npz'

✓ Saving configuration to outputs\exp_06_20251209_184533\saved_models\exp_06_20251209_184533_config.json...

✓ Saving analytics summary...

✓ Summary saved to outputs\exp_06_20251209_184533\recorded_data\20251209_184533_summary.txt
============================================================
TRAINING SUMMARY
============================================================
Timestamp: 20251209_184533

TRAINING RESULTS
------------------------------------------------------------
Total episodes trained: 20000
Final running average reward: 619.35
Best episode reward: 5401.20
Worst episode reward: -20.60
Mean episode reward: 438.09
Std episode reward: 963.09

EVALUATION METRICS
------------------------------------------------------------
Win rate: 3.6%
Total wins: 716 / 20000
Mean episode length: 4267 steps
Mean player score: 14.0
Mean CPU score: 21.0

REWARD COMPONENTS (Average)
------------------------------------------------------------
Score reward: +282.99
Hit reward: +0.9652
Loss penalty: -20.96

ACTION DISTRIBUTION
------------------------------------------------------------
N/A

HYPERPARAMETERS
------------------------------------------------------------
timestamp: 20251209_184533
experiment_name: exp_06
continued_from_episode: 0
environment: {'width': 160, 'height': 192, 'max_score': 21, 'cpu_difficulty': 'medium'}
agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
training: {'max_episodes': 20000, 'batch_size': 5, 'running_reward_decay': 0.99, 'print_frequency': 100}
rewards: {'ball_hit': 0.02, 'score': 20.0, 'opponent_score': -1.0, 'win': 5000.0, 'loss': -0.0}
training_results: {'final_running_average': 736.809310880247, 'best_episode_reward': 5401.2, 'total_episodes_trained': 20000, 'total_episodes_cumulative': 20000}
evaluation_results: {'mean_reward': 349.99799999999993, 'std_reward': 31.350331991862443, 'win_rate': 0.0, 'eval_episodes': 10}
heatmap_data: {'recording_enabled': False, 'heatmap_file': None, 'epochs_collected': 0}
collision_data: {'recording_enabled': True, 'epochs_collected': 100, 'total_collisions': 488071}

============================================================

✓ Generating analytics visualizations...

✓ Generating plots...
Warning: Skipping action distribution plot. No action data was logged during training/evaluation.
✓ All plots saved to outputs\exp_06_20251209_184533\recorded_data/ with prefix 20251209_184533

✓ Saving collision analysis to outputs\exp_06_20251209_184533\recorded_data\collision_analysis...
======================================================================
PADDLE COLLISION ANALYSIS REPORT
======================================================================

SUMMARY STATISTICS
----------------------------------------------------------------------
Total Epochs Analyzed: 100
Total Collisions Recorded: 488071

EDGE HIT PROGRESSION
----------------------------------------------------------------------
Initial Edge Hit Rate: 61.1%
Final Edge Hit Rate: 98.3%
Improvement: +37.2 percentage points

BOUNCE ANGLE PROGRESSION
----------------------------------------------------------------------
Initial Average Angle: 45.5°
Final Average Angle: 61.8°
Improvement: +16.3°

INTERPRETATION
----------------------------------------------------------------------
Edge hits increased from 61.1% to 98.3%, demonstrating the agent
learned to exploit the progressive angle system. Higher edge hit rates
produce steeper bounce angles, making returns harder to defend.

Average bounce angle increased from 45.5° to
61.8°, confirming strategic use of steep
trajectories for offensive advantage.

======================================================================

✓ Report saved to outputs\exp_06_20251209_184533\recorded_data\collision_analysis\collision_report.txt

✓ Generating collision analysis figures...
  ✓ Figure 1 saved: figure_1_collision_distribution.png
  ✓ Figure 2 saved: figure_2_angle_progression.png
  ✓ Figure 3 saved: figure_3_edge_hit_progression.png
✓ All figures saved to outputs\exp_06_20251209_184533\recorded_data\collision_analysis/
  ✓ Summary CSV: collision_summary.csv
  ✓ Distribution CSV: collision_distribution.csv
  Total CSV files: 2
✓ Collision analysis complete!
  Location: outputs\exp_06_20251209_184533\recorded_data\collision_analysis/

======================================================================
TRAINING COMPLETE
Total Training Time: 12:53:45.630517
======================================================================

✓ All results saved to: outputs\exp_06_20251209_184533/

  Models (outputs\exp_06_20251209_184533\saved_models/):
    - Model: exp_06_20251209_184533.npz
    - Config: exp_06_20251209_184533_config.json
    - Log: exp_06_20251209_184533.log

  Analytics (outputs\exp_06_20251209_184533\recorded_data/):
    - Training CSV: 20251209_184533.csv
    - Evaluation CSV: 20251209_184533_eval.csv
    - Summary: 20251209_184533_summary.txt
    - Plots (10): 20251209_184533_0*.png

  Collision Analysis (outputs\exp_06_20251209_184533\recorded_data\collision_analysis/):
    - Report: collision_report.txt
    - Statistics: collision_statistics.json
    - Figures: figure_1_collision_distribution.png
    - Figures: figure_2_angle_progression.png
    - Figures: figure_3_edge_hit_progression.png
    - Total Collisions: 488,071
    - Edge Hit Rate: 61.1% → 98.3%
    - Avg Angle: 45.5° → 61.8°
======================================================================


======================================================================
TRAINING COMPLETE
======================================================================

✓ Results saved to: outputs\exp_06_20251209_184533/
  - Model: model.npz
  - Config: config_used.json
  - Metrics: training.csv, evaluation.csv
  - Heatmap: heatmap.json
  - Log: training.log

======================================================================
INITIALIZING TRAINING COMPONENTS
======================================================================

✓ Creating environment...
  Court: 160×192
  Paddle: 2×12
  CPU Difficulty: medium

✓ Creating agent (PolicyGradient)...
  Input Size: 16
  Hidden Size: 128
  Output Size: 3
  Learning Rate: 0.0015
  Discount Factor: 0.99

✓ Creating trainer (PolicyGradient)...
  Max Episodes: 20000
  Batch Size: 5
  Running Reward Decay: 0.99

✓ Creating heatmap recorder...
  Grid Resolution: 20×24
  Court Size: 160×192

✓ Creating training orchestrator...
  Experiment: exp_07
  Orchestrator will handle:
    - Training pipeline
    - Analytics logging
    - Heatmap recording
    - Model evaluation
    - Automatic saving
✓ Analytics initialized
  Timestamp: 20251213_141554
  Output dir: outputs\exp_07_20251213_141554\recorded_data
  All files saved as: 20251213_141554*

✓ Found existing training data: outputs\exp_07_20251213_141554\recorded_data\20251213_141554.csv
  Continuing from previous run...

======================================================================
STARTING TRAINING
======================================================================

======================================================================
TRAINING ORCHESTRATOR - UNIFIED PIPELINE
======================================================================
Experiment: exp_07
Timestamp: 20251213_141554
Output Root Directory: outputs\exp_07_20251213_141554/
Output Sub-Directories:
  - Models: outputs\exp_07_20251213_141554\saved_models/
  - Analytics: outputs\exp_07_20251213_141554\recorded_data/
  - Collision Analysis: outputs\exp_07_20251213_141554\recorded_data\collision_analysis/
Heatmap Recording: ✗ DISABLED
Collision Analysis: ✓ ENABLED

✓ Starting trainer...

============================================================
TRAINING PONG AGENT
============================================================
Agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
Learning Rate: 0.0015
Discount Factor: 0.99
Max Episodes: 20000
RMSprop Decay: 0.99
Running Reward Decay: 0.99
Reward Structure: Score=20.0, Hit=0.02, Loss=-1.0
Win Reward: 5000.0, Loss Penalty: -0.0
Heatmap Recording: DISABLED
Collision Analysis: ENABLED
Episodes per collision epoch: 200
============================================================

Episode  100 | Reward:   19.58 | Running Avg:  -12.59 | Best:   39.74 | Length: 2999
  ✓ Collision epoch 0 saved
Episode  200 | Reward:  -20.04 | Running Avg:   -0.12 | Best:   79.70 | Length: 4091
Episode  300 | Reward:  -20.10 | Running Avg:   10.92 | Best:  119.90 | Length: 4086
  ✓ Collision epoch 1 saved
Episode  400 | Reward:   39.82 | Running Avg:   28.15 | Best:  119.90 | Length: 3757
Episode  500 | Reward:   39.96 | Running Avg:   31.92 | Best:  120.14 | Length: 4317
  ✓ Collision epoch 2 saved
Episode  600 | Reward:   39.90 | Running Avg:   37.30 | Best:  120.14 | Length: 3993
Episode  700 | Reward:   59.98 | Running Avg:   38.21 | Best:  120.14 | Length: 4329
  ✓ Collision epoch 3 saved
Episode  800 | Reward:   -0.14 | Running Avg:   39.38 | Best:  120.14 | Length: 3940
Episode  900 | Reward:   60.02 | Running Avg:   41.81 | Best:  139.92 | Length: 4424
  ✓ Collision epoch 4 saved
Episode 1000 | Reward:   79.82 | Running Avg:   48.74 | Best:  159.98 | Length: 3721
Episode 1100 | Reward:   99.98 | Running Avg:   62.02 | Best:  160.02 | Length: 4216
  ✓ Collision epoch 5 saved
Episode 1200 | Reward:   39.84 | Running Avg:   71.60 | Best:  219.92 | Length: 3909
Episode 1300 | Reward:   99.84 | Running Avg:   74.73 | Best:  219.92 | Length: 4060
  ✓ Collision epoch 6 saved
Episode 1400 | Reward:   59.64 | Running Avg:   74.59 | Best:  219.92 | Length: 3157
Episode 1500 | Reward:   99.88 | Running Avg:   83.46 | Best:  219.92 | Length: 3994
  ✓ Collision epoch 7 saved
Episode 1600 | Reward:  119.98 | Running Avg:   91.17 | Best:  219.92 | Length: 4338
Episode 1700 | Reward:  140.04 | Running Avg:   95.47 | Best:  219.92 | Length: 4474
  ✓ Collision epoch 8 saved
Episode 1800 | Reward:  140.12 | Running Avg:  102.37 | Best:  219.92 | Length: 4760
Episode 1900 | Reward:  119.94 | Running Avg:  104.51 | Best:  220.04 | Length: 4121
  ✓ Collision epoch 9 saved
Episode 2000 | Reward:  159.86 | Running Avg:  111.98 | Best:  239.98 | Length: 4049
Episode 2100 | Reward:   59.78 | Running Avg:  116.37 | Best:  239.98 | Length: 3669
  ✓ Collision epoch 10 saved
Episode 2200 | Reward:  139.78 | Running Avg:  118.56 | Best:  239.98 | Length: 3708
Episode 2300 | Reward:  160.08 | Running Avg:  115.94 | Best:  259.96 | Length: 4614
  ✓ Collision epoch 11 saved
Episode 2400 | Reward:  160.08 | Running Avg:  119.20 | Best:  259.96 | Length: 4551
Episode 2500 | Reward:   99.88 | Running Avg:  129.40 | Best:  259.96 | Length: 3885
  ✓ Collision epoch 12 saved
Episode 2600 | Reward:  119.80 | Running Avg:  133.97 | Best:  260.02 | Length: 3758
Episode 2700 | Reward:  139.86 | Running Avg:  130.74 | Best:  260.02 | Length: 3911
  ✓ Collision epoch 13 saved
Episode 2800 | Reward:   99.90 | Running Avg:  135.88 | Best:  260.02 | Length: 4078
Episode 2900 | Reward:   99.82 | Running Avg:  139.45 | Best:  260.02 | Length: 3713
  ✓ Collision epoch 14 saved
Episode 3000 | Reward:  140.00 | Running Avg:  137.69 | Best:  260.02 | Length: 4323
Episode 3100 | Reward:  100.20 | Running Avg:  145.57 | Best:  279.90 | Length: 4746
  ✓ Collision epoch 15 saved
Episode 3200 | Reward:  240.00 | Running Avg:  152.84 | Best:  279.98 | Length: 4412
Episode 3300 | Reward:  179.84 | Running Avg:  160.28 | Best:  279.98 | Length: 3781
  ✓ Collision epoch 16 saved
Episode 3400 | Reward:  159.86 | Running Avg:  161.82 | Best:  279.98 | Length: 3881
Episode 3500 | Reward:  160.00 | Running Avg:  165.04 | Best:  279.98 | Length: 4392
  ✓ Collision epoch 17 saved
Episode 3600 | Reward:   19.68 | Running Avg:  163.59 | Best:  279.98 | Length: 3186
Episode 3700 | Reward:  199.88 | Running Avg:  169.13 | Best:  280.00 | Length: 4001
  ✓ Collision epoch 18 saved
Episode 3800 | Reward:  220.02 | Running Avg:  168.38 | Best:  299.88 | Length: 4312
Episode 3900 | Reward:  200.00 | Running Avg:  176.38 | Best:  299.88 | Length: 4411
  ✓ Collision epoch 19 saved
Episode 4000 | Reward:  240.08 | Running Avg:  180.58 | Best:  299.88 | Length: 4689
Episode 4100 | Reward:  199.86 | Running Avg:  181.54 | Best:  299.88 | Length: 4089
  ✓ Collision epoch 20 saved
Episode 4200 | Reward:  199.90 | Running Avg:  180.81 | Best:  299.88 | Length: 4253
Episode 4300 | Reward:  239.98 | Running Avg:  182.34 | Best:  299.98 | Length: 4272
  ✓ Collision epoch 21 saved
Episode 4400 | Reward:  200.04 | Running Avg:  195.75 | Best:  320.06 | Length: 4470
Episode 4500 | Reward:  259.98 | Running Avg:  196.54 | Best:  320.06 | Length: 4323

======================================================================
INITIALIZING TRAINING COMPONENTS
======================================================================

✓ Creating environment...
  Court: 160×192
  Paddle: 2×12
  CPU Difficulty: medium

✓ Creating agent (PolicyGradient)...
  Input Size: 16
  Hidden Size: 128
  Output Size: 3
  Learning Rate: 0.0015
  Discount Factor: 0.99

✓ Creating trainer (PolicyGradient)...
  Max Episodes: 20000
  Batch Size: 5
  Running Reward Decay: 0.99

✓ Creating heatmap recorder...
  Grid Resolution: 20×24
  Court Size: 160×192

✓ Creating training orchestrator...
  Experiment: exp_07
  Orchestrator will handle:
    - Training pipeline
    - Analytics logging
    - Heatmap recording
    - Model evaluation
    - Automatic saving
✓ Analytics initialized
  Timestamp: 20251214_061202
  Output dir: outputs\exp_07_20251214_061202\recorded_data
  All files saved as: 20251214_061202*

✓ Found existing training data: outputs\exp_07_20251214_061202\recorded_data\20251214_061202.csv
  Continuing from previous run...

======================================================================
STARTING TRAINING
======================================================================

======================================================================
TRAINING ORCHESTRATOR - UNIFIED PIPELINE
======================================================================
Experiment: exp_07
Timestamp: 20251214_061202
Output Root Directory: outputs\exp_07_20251214_061202/
Output Sub-Directories:
  - Models: outputs\exp_07_20251214_061202\saved_models/
  - Analytics: outputs\exp_07_20251214_061202\recorded_data/
  - Collision Analysis: outputs\exp_07_20251214_061202\recorded_data\collision_analysis/
Heatmap Recording: ✗ DISABLED
Collision Analysis: ✓ ENABLED

✓ Starting trainer...

============================================================
TRAINING PONG AGENT
============================================================
Agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
Learning Rate: 0.0015
Discount Factor: 0.99
Max Episodes: 20000
RMSprop Decay: 0.99
Running Reward Decay: 0.99
Reward Structure: Score=20.0, Hit=0.02, Loss=-1.0
Win Reward: 5000.0, Loss Penalty: -0.0
Heatmap Recording: DISABLED
Collision Analysis: ENABLED
Episodes per collision epoch: 200
============================================================

Episode  100 | Reward:  -20.60 | Running Avg:  -14.98 | Best:  139.72 | Length: 2334

======================================================================
INITIALIZING TRAINING COMPONENTS
======================================================================

✓ Creating environment...
  Court: 160×192
  Paddle: 2×12
  CPU Difficulty: medium

✓ Creating agent (PolicyGradient)...
  Input Size: 16
  Hidden Size: 128
  Output Size: 3
  Learning Rate: 0.0015
  Discount Factor: 0.99

✓ Creating trainer (PolicyGradient)...
  Max Episodes: 20000
  Batch Size: 5
  Running Reward Decay: 0.99

✓ Creating heatmap recorder...
  Grid Resolution: 20×24
  Court Size: 160×192

✓ Creating training orchestrator...
  Experiment: exp_07
  Orchestrator will handle:
    - Training pipeline
    - Analytics logging
    - Heatmap recording
    - Model evaluation
    - Automatic saving
✓ Analytics initialized
  Timestamp: 20251214_061358
  Output dir: outputs\exp_07_20251214_061358\recorded_data
  All files saved as: 20251214_061358*

✓ Found existing training data: outputs\exp_07_20251214_061358\recorded_data\20251214_061358.csv
  Continuing from previous run...

======================================================================
STARTING TRAINING
======================================================================

======================================================================
TRAINING ORCHESTRATOR - UNIFIED PIPELINE
======================================================================
Experiment: exp_07
Timestamp: 20251214_061358
Output Root Directory: outputs\exp_07_20251214_061358/
Output Sub-Directories:
  - Models: outputs\exp_07_20251214_061358\saved_models/
  - Analytics: outputs\exp_07_20251214_061358\recorded_data/
  - Collision Analysis: outputs\exp_07_20251214_061358\recorded_data\collision_analysis/
Heatmap Recording: ✗ DISABLED
Collision Analysis: ✓ ENABLED

✓ Starting trainer...

============================================================
TRAINING PONG AGENT
============================================================
Agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
Learning Rate: 0.0015
Discount Factor: 0.99
Max Episodes: 20000
RMSprop Decay: 0.99
Running Reward Decay: 0.99
Reward Structure: Score=20.0, Hit=0.02, Loss=-1.0
Win Reward: 5000.0, Loss Penalty: -0.0
Heatmap Recording: DISABLED
Collision Analysis: ENABLED
Episodes per collision epoch: 200
============================================================

Episode  100 | Reward:   -0.44 | Running Avg:  -14.73 | Best:   19.96 | Length: 2947
  ✓ Collision epoch 0 saved
Episode  200 | Reward:   19.90 | Running Avg:   -6.91 | Best:  119.66 | Length: 4064
Episode  300 | Reward:   -0.10 | Running Avg:    5.63 | Best:  119.66 | Length: 4030
  ✓ Collision epoch 1 saved
Episode  400 | Reward:   40.00 | Running Avg:   17.43 | Best:  119.82 | Length: 4375
Episode  500 | Reward:   -0.10 | Running Avg:   22.64 | Best:  120.04 | Length: 3880
  ✓ Collision epoch 2 saved
Episode  600 | Reward:   -0.04 | Running Avg:   25.62 | Best:  120.04 | Length: 4110
Episode  700 | Reward:   19.80 | Running Avg:   25.77 | Best:  139.88 | Length: 3770
  ✓ Collision epoch 3 saved
Episode  800 | Reward:   40.10 | Running Avg:   26.55 | Best:  139.88 | Length: 4632
Episode  900 | Reward:   19.70 | Running Avg:   29.37 | Best:  139.88 | Length: 3356
  ✓ Collision epoch 4 saved
Episode 1000 | Reward:   59.84 | Running Avg:   31.31 | Best:  139.88 | Length: 3859
Episode 1100 | Reward:   60.04 | Running Avg:   40.52 | Best:  139.88 | Length: 4424
  ✓ Collision epoch 5 saved
Episode 1200 | Reward:   60.06 | Running Avg:   40.10 | Best:  139.88 | Length: 4434
Episode 1300 | Reward:   59.76 | Running Avg:   52.96 | Best:  140.02 | Length: 3628
  ✓ Collision epoch 6 saved
Episode 1400 | Reward:  179.86 | Running Avg:   65.92 | Best:  179.88 | Length: 3779
Episode 1500 | Reward:   19.86 | Running Avg:   75.39 | Best:  179.88 | Length: 3824
  ✓ Collision epoch 7 saved
Episode 1600 | Reward:   99.90 | Running Avg:   77.32 | Best:  179.88 | Length: 3974
Episode 1700 | Reward:   59.98 | Running Avg:   78.78 | Best:  179.94 | Length: 4184
  ✓ Collision epoch 8 saved
Episode 1800 | Reward:  119.98 | Running Avg:   80.32 | Best:  179.94 | Length: 4110
Episode 1900 | Reward:   99.86 | Running Avg:   85.73 | Best:  179.98 | Length: 3973
  ✓ Collision epoch 9 saved
Episode 2000 | Reward:   79.94 | Running Avg:   84.65 | Best:  179.98 | Length: 4107
Episode 2100 | Reward:   99.88 | Running Avg:   84.88 | Best:  179.98 | Length: 4044
  ✓ Collision epoch 10 saved
Episode 2200 | Reward:   59.90 | Running Avg:   90.76 | Best:  179.98 | Length: 4040
Episode 2300 | Reward:   80.02 | Running Avg:  105.97 | Best:  199.96 | Length: 4395
  ✓ Collision epoch 11 saved
Episode 2400 | Reward:  179.96 | Running Avg:  118.59 | Best:  200.00 | Length: 4169
Episode 2500 | Reward:  179.92 | Running Avg:  115.94 | Best:  220.02 | Length: 4260
  ✓ Collision epoch 12 saved
Episode 2600 | Reward:  119.78 | Running Avg:  126.02 | Best:  240.02 | Length: 3678
Episode 2700 | Reward:  119.94 | Running Avg:  125.33 | Best:  280.00 | Length: 4035
  ✓ Collision epoch 13 saved
Episode 2800 | Reward:  179.76 | Running Avg:  133.28 | Best:  280.00 | Length: 3515
Episode 2900 | Reward:  179.98 | Running Avg:  134.68 | Best:  280.00 | Length: 4283
  ✓ Collision epoch 14 saved
Episode 3000 | Reward:  120.08 | Running Avg:  138.87 | Best:  280.00 | Length: 4600
Episode 3100 | Reward:  180.00 | Running Avg:  150.57 | Best:  280.00 | Length: 4373
  ✓ Collision epoch 15 saved
Episode 3200 | Reward:  119.90 | Running Avg:  147.48 | Best:  280.00 | Length: 4064
Episode 3300 | Reward:  119.90 | Running Avg:  157.45 | Best:  280.00 | Length: 3991
  ✓ Collision epoch 16 saved
Episode 3400 | Reward:  219.92 | Running Avg:  161.80 | Best:  280.00 | Length: 4272
Episode 3500 | Reward:  179.86 | Running Avg:  165.20 | Best:  280.04 | Length: 3914
  ✓ Collision epoch 17 saved
Episode 3600 | Reward:  159.88 | Running Avg:  167.26 | Best:  280.04 | Length: 4079
Episode 3700 | Reward:  219.90 | Running Avg:  173.28 | Best:  280.04 | Length: 4191
  ✓ Collision epoch 18 saved
Episode 3800 | Reward:  219.98 | Running Avg:  178.96 | Best:  280.04 | Length: 4321
Episode 3900 | Reward:  179.80 | Running Avg:  186.50 | Best:  300.04 | Length: 3851
  ✓ Collision epoch 19 saved
Episode 4000 | Reward:  299.92 | Running Avg:  196.25 | Best:  339.88 | Length: 4412
Episode 4100 | Reward:  100.02 | Running Avg:  202.63 | Best:  339.88 | Length: 4437
  ✓ Collision epoch 20 saved
Episode 4200 | Reward:  179.92 | Running Avg:  197.72 | Best:  339.88 | Length: 4102
Episode 4300 | Reward:  219.88 | Running Avg:  202.65 | Best:  339.88 | Length: 4240
  ✓ Collision epoch 21 saved
Episode 4400 | Reward:  280.04 | Running Avg:  216.37 | Best:  339.88 | Length: 4294
Episode 4500 | Reward:  219.88 | Running Avg:  217.88 | Best:  339.88 | Length: 3979
  ✓ Collision epoch 22 saved
Episode 4600 | Reward:  199.96 | Running Avg:  224.63 | Best:  339.88 | Length: 4332
Episode 4700 | Reward:  179.94 | Running Avg:  232.80 | Best:  339.92 | Length: 4288
  ✓ Collision epoch 23 saved
Episode 4800 | Reward:  180.06 | Running Avg:  232.11 | Best:  339.92 | Length: 4433
Episode 4900 | Reward:  160.00 | Running Avg:  237.95 | Best:  360.06 | Length: 4474
  ✓ Collision epoch 24 saved
Episode 5000 | Reward:  219.94 | Running Avg:  232.86 | Best:  360.06 | Length: 4329
Episode 5100 | Reward:  159.82 | Running Avg:  235.90 | Best:  360.06 | Length: 3596
  ✓ Collision epoch 25 saved
Episode 5200 | Reward:  299.80 | Running Avg:  240.29 | Best:  360.06 | Length: 4004
Episode 5300 | Reward:  219.94 | Running Avg:  249.87 | Best:  360.06 | Length: 4115
  ✓ Collision epoch 26 saved
Episode 5400 | Reward:  259.98 | Running Avg:  258.56 | Best:  360.12 | Length: 4123
Episode 5500 | Reward:  259.92 | Running Avg:  263.41 | Best:  360.12 | Length: 4331
  ✓ Collision epoch 27 saved
Episode 5600 | Reward:  259.98 | Running Avg:  264.23 | Best:  360.12 | Length: 4387
Episode 5700 | Reward:  259.90 | Running Avg:  263.12 | Best:  379.96 | Length: 4183
  ✓ Collision epoch 28 saved
Episode 5800 | Reward:  300.00 | Running Avg:  270.40 | Best:  379.96 | Length: 4325
Episode 5900 | Reward:  340.02 | Running Avg:  283.56 | Best:  380.08 | Length: 4551
  ✓ Collision epoch 29 saved
Episode 6000 | Reward:  240.10 | Running Avg:  281.39 | Best:  380.08 | Length: 4549
Episode 6100 | Reward:  299.94 | Running Avg:  285.90 | Best:  380.08 | Length: 4129
  ✓ Collision epoch 30 saved
Episode 6200 | Reward:  239.76 | Running Avg:  287.95 | Best:  380.08 | Length: 3692
Episode 6300 | Reward:  360.10 | Running Avg:  315.45 | Best: 5401.10 | Length: 4643
  ✓ Collision epoch 31 saved
Episode 6400 | Reward:  320.04 | Running Avg:  306.89 | Best: 5401.10 | Length: 4502
Episode 6500 | Reward:  360.00 | Running Avg:  307.86 | Best: 5401.10 | Length: 4516
  ✓ Collision epoch 32 saved
Episode 6600 | Reward:  299.92 | Running Avg:  337.52 | Best: 5401.10 | Length: 4132
Episode 6700 | Reward:  319.96 | Running Avg:  356.89 | Best: 5401.10 | Length: 4435
  ✓ Collision epoch 33 saved
Episode 6800 | Reward:  339.98 | Running Avg:  330.74 | Best: 5401.10 | Length: 4339
Episode 6900 | Reward:  379.94 | Running Avg:  318.22 | Best: 5401.10 | Length: 4419
  ✓ Collision epoch 34 saved
Episode 7000 | Reward:  380.06 | Running Avg:  320.96 | Best: 5401.10 | Length: 4614
Episode 7100 | Reward:  340.04 | Running Avg:  372.56 | Best: 5401.10 | Length: 4336
  ✓ Collision epoch 35 saved
Episode 7200 | Reward:  380.02 | Running Avg:  390.46 | Best: 5401.10 | Length: 4415
Episode 7300 | Reward:  360.08 | Running Avg:  399.79 | Best: 5401.10 | Length: 4644
  ✓ Collision epoch 36 saved
Episode 7400 | Reward:  300.00 | Running Avg:  457.56 | Best: 5401.10 | Length: 4337
Episode 7500 | Reward:  280.08 | Running Avg:  413.35 | Best: 5401.10 | Length: 4410
  ✓ Collision epoch 37 saved
Episode 7600 | Reward:  339.94 | Running Avg:  357.71 | Best: 5401.10 | Length: 4209
Episode 7700 | Reward:  360.00 | Running Avg:  368.72 | Best: 5401.10 | Length: 4310
  ✓ Collision epoch 38 saved
Episode 7800 | Reward:  320.02 | Running Avg:  413.96 | Best: 5401.10 | Length: 4363
Episode 7900 | Reward:  320.08 | Running Avg:  426.81 | Best: 5401.10 | Length: 4429
  ✓ Collision epoch 39 saved
Episode 8000 | Reward:  360.04 | Running Avg:  424.99 | Best: 5401.10 | Length: 4377
Episode 8100 | Reward: 5401.08 | Running Avg:  453.45 | Best: 5401.10 | Length: 4541
  ✓ Collision epoch 40 saved
Episode 8200 | Reward:  340.10 | Running Avg:  380.06 | Best: 5401.10 | Length: 4669
Episode 8300 | Reward:  340.02 | Running Avg:  453.25 | Best: 5401.12 | Length: 4335
  ✓ Collision epoch 41 saved
Episode 8400 | Reward:  319.92 | Running Avg:  615.45 | Best: 5401.12 | Length: 4106
Episode 8500 | Reward:  360.08 | Running Avg:  489.57 | Best: 5401.12 | Length: 4635
  ✓ Collision epoch 42 saved
Episode 8600 | Reward:  320.02 | Running Avg:  661.35 | Best: 5401.14 | Length: 4503
Episode 8700 | Reward:  339.92 | Running Avg:  629.40 | Best: 5401.14 | Length: 4210
  ✓ Collision epoch 43 saved
Episode 8800 | Reward:  360.08 | Running Avg:  639.45 | Best: 5401.14 | Length: 4644
Episode 8900 | Reward:  340.00 | Running Avg:  448.52 | Best: 5401.14 | Length: 4473
  ✓ Collision epoch 44 saved
Episode 9000 | Reward:  300.06 | Running Avg:  529.81 | Best: 5401.14 | Length: 4596
Episode 9100 | Reward:  339.98 | Running Avg:  616.92 | Best: 5401.14 | Length: 4205
  ✓ Collision epoch 45 saved
Episode 9200 | Reward:  319.96 | Running Avg:  466.40 | Best: 5401.14 | Length: 4239
Episode 9300 | Reward:  259.78 | Running Avg:  457.37 | Best: 5401.14 | Length: 3799
  ✓ Collision epoch 46 saved
Episode 9400 | Reward:  360.00 | Running Avg:  473.02 | Best: 5401.14 | Length: 4381
Episode 9500 | Reward:  380.00 | Running Avg:  438.64 | Best: 5401.14 | Length: 4487
  ✓ Collision epoch 47 saved
Episode 9600 | Reward:  360.02 | Running Avg:  391.64 | Best: 5401.14 | Length: 4517
Episode 9700 | Reward:  359.92 | Running Avg:  353.76 | Best: 5401.14 | Length: 4316
  ✓ Collision epoch 48 saved
Episode 9800 | Reward:  340.00 | Running Avg:  363.07 | Best: 5401.14 | Length: 4336
Episode 9900 | Reward:  320.06 | Running Avg:  389.19 | Best: 5401.14 | Length: 4371
  ✓ Collision epoch 49 saved
Episode 10000 | Reward:  380.06 | Running Avg:  620.54 | Best: 5401.14 | Length: 4619
Episode 10100 | Reward:  339.98 | Running Avg:  436.66 | Best: 5401.14 | Length: 4335
  ✓ Collision epoch 50 saved
Episode 10200 | Reward:  340.02 | Running Avg:  366.63 | Best: 5401.14 | Length: 4678
Episode 10300 | Reward: 5401.10 | Running Avg:  515.82 | Best: 5401.14 | Length: 4540
  ✓ Collision epoch 51 saved
Episode 10400 | Reward:  340.02 | Running Avg:  425.15 | Best: 5401.14 | Length: 4477
Episode 10500 | Reward:  359.94 | Running Avg:  456.13 | Best: 5401.14 | Length: 4516
  ✓ Collision epoch 52 saved
Episode 10600 | Reward:  320.02 | Running Avg:  465.06 | Best: 5401.14 | Length: 4359
Episode 10700 | Reward:  360.04 | Running Avg:  431.66 | Best: 5401.14 | Length: 4379
  ✓ Collision epoch 53 saved
Episode 10800 | Reward:  299.92 | Running Avg:  555.23 | Best: 5401.14 | Length: 4132
Episode 10900 | Reward:  319.88 | Running Avg:  508.84 | Best: 5401.14 | Length: 4104
  ✓ Collision epoch 54 saved
Episode 11000 | Reward:  279.88 | Running Avg:  493.76 | Best: 5401.14 | Length: 4160
Episode 11100 | Reward:  360.04 | Running Avg:  719.20 | Best: 5401.16 | Length: 4377
  ✓ Collision epoch 55 saved
Episode 11200 | Reward:  360.06 | Running Avg:  799.37 | Best: 5401.16 | Length: 4520
Episode 11300 | Reward:  339.96 | Running Avg:  814.38 | Best: 5401.20 | Length: 4279
  ✓ Collision epoch 56 saved
Episode 11400 | Reward:  340.08 | Running Avg:  724.71 | Best: 5401.20 | Length: 4469
Episode 11500 | Reward:  319.92 | Running Avg:  731.06 | Best: 5401.20 | Length: 4243
  ✓ Collision epoch 57 saved
Episode 11600 | Reward:  339.98 | Running Avg:  860.17 | Best: 5401.20 | Length: 4349
Episode 11700 | Reward:  360.02 | Running Avg:  725.19 | Best: 5401.20 | Length: 4517
  ✓ Collision epoch 58 saved
Episode 11800 | Reward:  380.02 | Running Avg:  892.29 | Best: 5401.20 | Length: 4415
Episode 11900 | Reward:  339.90 | Running Avg:  893.56 | Best: 5401.20 | Length: 4211
  ✓ Collision epoch 59 saved
Episode 12000 | Reward:  360.04 | Running Avg:  895.61 | Best: 5401.20 | Length: 4445
Episode 12100 | Reward:  339.92 | Running Avg:  754.93 | Best: 5401.20 | Length: 4208
  ✓ Collision epoch 60 saved
Episode 12200 | Reward:  339.94 | Running Avg:  746.25 | Best: 5401.20 | Length: 4207
Episode 12300 | Reward:  259.90 | Running Avg:  636.03 | Best: 5401.20 | Length: 4049
  ✓ Collision epoch 61 saved
Episode 12400 | Reward: 5401.06 | Running Avg:  751.20 | Best: 5401.20 | Length: 4542
Episode 12500 | Reward:  359.90 | Running Avg:  610.65 | Best: 5401.20 | Length: 4317
  ✓ Collision epoch 62 saved
Episode 12600 | Reward:  339.98 | Running Avg:  661.77 | Best: 5401.20 | Length: 4333
Episode 12700 | Reward:  319.94 | Running Avg:  526.03 | Best: 5401.20 | Length: 4240
  ✓ Collision epoch 63 saved
Episode 12800 | Reward:  380.04 | Running Avg:  730.39 | Best: 5401.20 | Length: 4615
Episode 12900 | Reward:  379.98 | Running Avg:  827.36 | Best: 5401.20 | Length: 4417
  ✓ Collision epoch 64 saved
Episode 13000 | Reward:  359.92 | Running Avg:  691.11 | Best: 5401.20 | Length: 4383
Episode 13100 | Reward:  319.94 | Running Avg:  912.98 | Best: 5401.20 | Length: 4174
  ✓ Collision epoch 65 saved
Episode 13200 | Reward:  360.02 | Running Avg:  780.66 | Best: 5401.20 | Length: 4380
Episode 13300 | Reward:  379.96 | Running Avg:  754.63 | Best: 5401.20 | Length: 4418
  ✓ Collision epoch 66 saved
Episode 13400 | Reward:  359.94 | Running Avg:  829.05 | Best: 5401.20 | Length: 4450
Episode 13500 | Reward:  340.00 | Running Avg:  719.52 | Best: 5401.20 | Length: 4480
  ✓ Collision epoch 67 saved
Episode 13600 | Reward:  379.94 | Running Avg:  687.37 | Best: 5401.20 | Length: 4419
Episode 13700 | Reward:  359.96 | Running Avg:  562.09 | Best: 5401.20 | Length: 4444
  ✓ Collision epoch 68 saved
Episode 13800 | Reward: 5401.08 | Running Avg:  685.03 | Best: 5401.20 | Length: 4541
Episode 13900 | Reward:  340.06 | Running Avg:  751.61 | Best: 5401.20 | Length: 4404
  ✓ Collision epoch 69 saved
Episode 14000 | Reward:  360.00 | Running Avg:  825.70 | Best: 5401.20 | Length: 4442
Episode 14100 | Reward: 5401.04 | Running Avg:  807.10 | Best: 5401.20 | Length: 4543
  ✓ Collision epoch 70 saved
Episode 14200 | Reward: 5401.06 | Running Avg:  852.81 | Best: 5401.20 | Length: 4542
Episode 14300 | Reward:  380.10 | Running Avg:  799.76 | Best: 5401.20 | Length: 4480
  ✓ Collision epoch 71 saved
Episode 14400 | Reward:  380.04 | Running Avg:  774.88 | Best: 5401.20 | Length: 4620
Episode 14500 | Reward:  279.90 | Running Avg:  524.82 | Best: 5401.20 | Length: 4155
  ✓ Collision epoch 72 saved
Episode 14600 | Reward:  379.98 | Running Avg:  655.04 | Best: 5401.20 | Length: 4417
Episode 14700 | Reward:  340.04 | Running Avg:  708.39 | Best: 5401.20 | Length: 4466
  ✓ Collision epoch 73 saved
Episode 14800 | Reward:  340.00 | Running Avg:  716.34 | Best: 5401.20 | Length: 4669
Episode 14900 | Reward:  379.98 | Running Avg:  839.35 | Best: 5401.20 | Length: 4417
  ✓ Collision epoch 74 saved
Episode 15000 | Reward:  379.98 | Running Avg:  930.66 | Best: 5401.20 | Length: 4417
Episode 15100 | Reward:  300.00 | Running Avg:  872.57 | Best: 5401.20 | Length: 4390
  ✓ Collision epoch 75 saved
Episode 15200 | Reward:  319.92 | Running Avg:  940.73 | Best: 5401.20 | Length: 4106
Episode 15300 | Reward:  340.00 | Running Avg: 1059.11 | Best: 5401.20 | Length: 4547
  ✓ Collision epoch 76 saved
Episode 15400 | Reward:  380.02 | Running Avg: 1124.40 | Best: 5401.20 | Length: 4484
Episode 15500 | Reward:  380.02 | Running Avg:  949.42 | Best: 5401.20 | Length: 4484
  ✓ Collision epoch 77 saved
Episode 15600 | Reward: 5401.10 | Running Avg:  998.72 | Best: 5401.20 | Length: 4540
Episode 15700 | Reward:  380.06 | Running Avg: 1079.42 | Best: 5401.20 | Length: 4413
  ✓ Collision epoch 78 saved
Episode 15800 | Reward:  380.04 | Running Avg: 1029.80 | Best: 5401.20 | Length: 4615
Episode 15900 | Reward:  379.98 | Running Avg:  922.98 | Best: 5401.20 | Length: 4488
  ✓ Collision epoch 79 saved
Episode 16000 | Reward:  340.02 | Running Avg: 1067.21 | Best: 5401.20 | Length: 4546
Episode 16100 | Reward:  360.02 | Running Avg:  919.64 | Best: 5401.20 | Length: 4311
  ✓ Collision epoch 80 saved
Episode 16200 | Reward:  340.02 | Running Avg:  965.72 | Best: 5401.20 | Length: 4472
Episode 16300 | Reward:  340.12 | Running Avg:  761.18 | Best: 5401.20 | Length: 4543
  ✓ Collision epoch 81 saved
Episode 16400 | Reward:  339.98 | Running Avg:  855.80 | Best: 5401.20 | Length: 4276
Episode 16500 | Reward:  379.92 | Running Avg: 1052.07 | Best: 5401.20 | Length: 4420
  ✓ Collision epoch 82 saved
Episode 16600 | Reward:  380.02 | Running Avg: 1027.10 | Best: 5401.20 | Length: 4415
Episode 16700 | Reward:  279.96 | Running Avg:  923.61 | Best: 5401.20 | Length: 4284
  ✓ Collision epoch 83 saved
Episode 16800 | Reward:  380.04 | Running Avg: 1049.45 | Best: 5401.20 | Length: 4414
Episode 16900 | Reward:  380.06 | Running Avg: 1031.90 | Best: 5401.20 | Length: 4484
  ✓ Collision epoch 84 saved
Episode 17000 | Reward:  339.98 | Running Avg:  847.92 | Best: 5401.20 | Length: 4337
Episode 17100 | Reward: 5401.04 | Running Avg: 1216.42 | Best: 5401.20 | Length: 4543
  ✓ Collision epoch 85 saved
Episode 17200 | Reward:  340.04 | Running Avg: 1234.63 | Best: 5401.20 | Length: 4672
Episode 17300 | Reward:  360.02 | Running Avg: 1269.09 | Best: 5401.20 | Length: 4441
  ✓ Collision epoch 86 saved
Episode 17400 | Reward:  299.86 | Running Avg: 1278.36 | Best: 5401.20 | Length: 4007
Episode 17500 | Reward:  300.08 | Running Avg: 1160.33 | Best: 5401.20 | Length: 4392
  ✓ Collision epoch 87 saved
Episode 17600 | Reward:  380.04 | Running Avg: 1043.69 | Best: 5401.20 | Length: 4483
Episode 17700 | Reward: 5401.00 | Running Avg: 1185.35 | Best: 5401.20 | Length: 4545
  ✓ Collision epoch 88 saved
Episode 17800 | Reward:  360.02 | Running Avg:  648.34 | Best: 5401.20 | Length: 4446
Episode 17900 | Reward:  339.96 | Running Avg:  538.69 | Best: 5401.20 | Length: 4275
  ✓ Collision epoch 89 saved
Episode 18000 | Reward:  360.12 | Running Avg:  776.87 | Best: 5401.20 | Length: 4637
Episode 18100 | Reward:  379.98 | Running Avg:  954.97 | Best: 5401.20 | Length: 4417
  ✓ Collision epoch 90 saved
Episode 18200 | Reward:  380.00 | Running Avg:  873.05 | Best: 5401.20 | Length: 4416
Episode 18300 | Reward:  380.06 | Running Avg:  697.23 | Best: 5401.20 | Length: 4484
  ✓ Collision epoch 91 saved
Episode 18400 | Reward:  340.10 | Running Avg:  701.91 | Best: 5401.20 | Length: 4681
Episode 18500 | Reward:  360.02 | Running Avg:  817.98 | Best: 5401.20 | Length: 4309
  ✓ Collision epoch 92 saved
Episode 18600 | Reward:  340.04 | Running Avg: 1007.36 | Best: 5401.20 | Length: 4466
Episode 18700 | Reward:  360.06 | Running Avg:  819.26 | Best: 5401.20 | Length: 4645
  ✓ Collision epoch 93 saved
Episode 18800 | Reward: 5401.02 | Running Avg: 1002.07 | Best: 5401.20 | Length: 4544
Episode 18900 | Reward:  360.06 | Running Avg:  895.21 | Best: 5401.20 | Length: 4439
  ✓ Collision epoch 94 saved
Episode 19000 | Reward:  380.00 | Running Avg: 1053.26 | Best: 5401.20 | Length: 4416
Episode 19100 | Reward: 5401.02 | Running Avg: 1141.97 | Best: 5401.20 | Length: 4544
  ✓ Collision epoch 95 saved
Episode 19200 | Reward:  379.98 | Running Avg: 1200.90 | Best: 5401.20 | Length: 4417
Episode 19300 | Reward:  360.00 | Running Avg: 1481.91 | Best: 5401.20 | Length: 4442
  ✓ Collision epoch 96 saved
Episode 19400 | Reward:  340.02 | Running Avg: 1347.06 | Best: 5401.20 | Length: 4479
Episode 19500 | Reward:  360.04 | Running Avg: 1203.41 | Best: 5401.20 | Length: 4641
  ✓ Collision epoch 97 saved
Episode 19600 | Reward:  379.98 | Running Avg: 1335.57 | Best: 5401.20 | Length: 4417
Episode 19700 | Reward: 5401.02 | Running Avg: 1354.16 | Best: 5401.20 | Length: 4544
  ✓ Collision epoch 98 saved
Episode 19800 | Reward: 5401.06 | Running Avg: 1159.84 | Best: 5401.20 | Length: 4542
Episode 19900 | Reward:  380.08 | Running Avg: 1058.45 | Best: 5401.20 | Length: 4481
  ✓ Collision epoch 99 saved
Episode 20000 | Reward:  360.00 | Running Avg:  950.87 | Best: 5401.20 | Length: 4442

============================================================
TRAINING COMPLETE
Final Running Average: 950.87
Best Episode Reward: 5401.20
Total collision epochs: 100
============================================================


✓ Logging training data to analytics...

✓ Evaluating...

============================================================
EVALUATING TRAINED AGENT (10 episodes)
============================================================

Eval Episode  1: Reward= 340.10, Player=18, CPU=21, Length=4686
Eval Episode  2: Reward= 379.94, Player=20, CPU=21, Length=4419
Eval Episode  3: Reward= 360.04, Player=19, CPU=21, Length=4516
Eval Episode  4: Reward= 380.02, Player=20, CPU=21, Length=4484
Eval Episode  5: Reward= 379.98, Player=20, CPU=21, Length=4417
Eval Episode  6: Reward= 340.02, Player=18, CPU=21, Length=4472
Eval Episode  7: Reward= 380.06, Player=20, CPU=21, Length=4413
Eval Episode  8: Reward= 300.08, Player=16, CPU=21, Length=4543
Eval Episode  9: Reward= 380.10, Player=20, CPU=21, Length=4617
Eval Episode 10: Reward= 320.04, Player=17, CPU=21, Length=4509

============================================================
Mean Reward: 356.04 ± 27.98
Reward Range: [300.08, 380.10]
Win Rate: 0.0%
Mean Episode Length: 4508 steps
============================================================


✓ Logging evaluation data to analytics...

✓ Saving current model to models\exp_07.npz...
✓ Agent parameters saved to 'models\exp_07.npz'
✓ Saving timestamped backup to outputs\exp_07_20251214_061358\saved_models\exp_07_20251214_061358.npz...
✓ Agent parameters saved to 'outputs\exp_07_20251214_061358\saved_models\exp_07_20251214_061358.npz'

✓ Saving configuration to outputs\exp_07_20251214_061358\saved_models\exp_07_20251214_061358_config.json...

✓ Saving analytics summary...

✓ Summary saved to outputs\exp_07_20251214_061358\recorded_data\20251214_061358_summary.txt
============================================================
TRAINING SUMMARY
============================================================
Timestamp: 20251214_061358

TRAINING RESULTS
------------------------------------------------------------
Total episodes trained: 20000
Final running average reward: 658.86
Best episode reward: 5401.20
Worst episode reward: -20.60
Mean episode reward: 558.48
Std episode reward: 1163.67

EVALUATION METRICS
------------------------------------------------------------
Win rate: 5.4%
Total wins: 1083 / 20000
Mean episode length: 4332 steps
Mean player score: 15.4
Mean CPU score: 20.9

REWARD COMPONENTS (Average)
------------------------------------------------------------
Score reward: +310.93
Hit reward: +0.9806
Loss penalty: -20.95

ACTION DISTRIBUTION
------------------------------------------------------------
N/A

HYPERPARAMETERS
------------------------------------------------------------
timestamp: 20251214_061358
experiment_name: exp_07
continued_from_episode: 0
environment: {'width': 160, 'height': 192, 'max_score': 21, 'cpu_difficulty': 'medium'}
agent: {'input_size': 16, 'hidden_size': 128, 'output_size': 3, 'total_params': 2563}
training: {'max_episodes': 20000, 'batch_size': 5, 'running_reward_decay': 0.99, 'print_frequency': 100}
rewards: {'ball_hit': 0.02, 'score': 20.0, 'opponent_score': -1.0, 'win': 5000.0, 'loss': -0.0}
training_results: {'final_running_average': 950.8728289834211, 'best_episode_reward': 5401.2, 'total_episodes_trained': 20000, 'total_episodes_cumulative': 20000}
evaluation_results: {'mean_reward': 356.0379999999999, 'std_reward': 27.981178602767898, 'win_rate': 0.0, 'eval_episodes': 10}
heatmap_data: {'recording_enabled': False, 'heatmap_file': None, 'epochs_collected': 0}
collision_data: {'recording_enabled': True, 'epochs_collected': 100, 'total_collisions': 515587}

============================================================

✓ Generating analytics visualizations...

✓ Generating plots...
Warning: Skipping action distribution plot. No action data was logged during training/evaluation.
✓ All plots saved to outputs\exp_07_20251214_061358\recorded_data/ with prefix 20251214_061358

✓ Saving collision analysis to outputs\exp_07_20251214_061358\recorded_data\collision_analysis...
======================================================================
PADDLE COLLISION ANALYSIS REPORT
======================================================================

SUMMARY STATISTICS
----------------------------------------------------------------------
Total Epochs Analyzed: 100
Total Collisions Recorded: 515587

EDGE HIT PROGRESSION
----------------------------------------------------------------------
Initial Edge Hit Rate: 60.8%
Final Edge Hit Rate: 98.3%
Improvement: +37.5 percentage points

BOUNCE ANGLE PROGRESSION
----------------------------------------------------------------------
Initial Average Angle: 45.1°
Final Average Angle: 61.5°
Improvement: +16.4°

INTERPRETATION
----------------------------------------------------------------------
Edge hits increased from 60.8% to 98.3%, demonstrating the agent
learned to exploit the progressive angle system. Higher edge hit rates
produce steeper bounce angles, making returns harder to defend.

Average bounce angle increased from 45.1° to
61.5°, confirming strategic use of steep
trajectories for offensive advantage.

======================================================================

✓ Report saved to outputs\exp_07_20251214_061358\recorded_data\collision_analysis\collision_report.txt

✓ Generating collision analysis figures...
  ✓ Figure 1 saved: figure_1_collision_distribution.png
  ✓ Figure 2 saved: figure_2_angle_progression.png
  ✓ Figure 3 saved: figure_3_edge_hit_progression.png
✓ All figures saved to outputs\exp_07_20251214_061358\recorded_data\collision_analysis/
  ✓ Summary CSV: collision_summary.csv
  ✓ Distribution CSV: collision_distribution.csv
  Total CSV files: 2
✓ Collision analysis complete!
  Location: outputs\exp_07_20251214_061358\recorded_data\collision_analysis/

======================================================================
TRAINING COMPLETE
Total Training Time: 5:40:21.211301
======================================================================

✓ All results saved to: outputs\exp_07_20251214_061358/

  Models (outputs\exp_07_20251214_061358\saved_models/):
    - Model: exp_07_20251214_061358.npz
    - Config: exp_07_20251214_061358_config.json
    - Log: exp_07_20251214_061358.log

  Analytics (outputs\exp_07_20251214_061358\recorded_data/):
    - Training CSV: 20251214_061358.csv
    - Evaluation CSV: 20251214_061358_eval.csv
    - Summary: 20251214_061358_summary.txt
    - Plots (10): 20251214_061358_0*.png

  Collision Analysis (outputs\exp_07_20251214_061358\recorded_data\collision_analysis/):
    - Report: collision_report.txt
    - Statistics: collision_statistics.json
    - Figures: figure_1_collision_distribution.png
    - Figures: figure_2_angle_progression.png
    - Figures: figure_3_edge_hit_progression.png
    - Total Collisions: 515,587
    - Edge Hit Rate: 60.8% → 98.3%
    - Avg Angle: 45.1° → 61.5°
======================================================================


======================================================================
TRAINING COMPLETE
======================================================================

✓ Results saved to: outputs\exp_07_20251214_061358/
  - Model: model.npz
  - Config: config_used.json
  - Metrics: training.csv, evaluation.csv
  - Heatmap: heatmap.json
  - Log: training.log
